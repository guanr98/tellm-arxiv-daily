---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.16
> Usage instructions: [here](./docs/README.md#usage)

## agent

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主性、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练在使模型具备执行动态场景（如网络导航）中复杂决策制定所需的自主代理能力方面存在不足。以往尝试通过在专家演示的监督微调来弥合这一差距，往往会因累积错误和有限的探索数据而受限，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式的蒙特卡洛树搜索（MCTS）与自我评判机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能够从成功和不成功的轨迹中有效学习，从而提高了它们在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和增强微调基线，并在配备在线搜索功能时超过了人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升至81.7%（相对增长340%），仅经过一天的数据收集后，进一步提升至95.4%，配合在线搜索。我们认为，这代表了自主代理能力的显著飞跃，为现实世界设置中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的能力各异，有的任务表现优异，而在其他任务上则表现不佳。为了充分利用这些代理的独特专长，我们提出了DEI（多样性赋能智能）这一框架，它能利用它们各自的专业知识。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上最大个体解决率为27.3%，而通过DEI可达到34.3%的解决率，实现了25%的提升，并超过了大多数闭源解决方案。我们表现最好的群体以55%的解决率脱颖而出，在SWE-Bench Lite上占据榜首位置。我们的研究发现为协作AI系统解决复杂软件工程挑战的潜力提供了重要贡献。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到分层强化学习（HRL）的启发，我们提出了一种新颖的框架——分层上下文强化学习（HCRL），该框架利用基于LLM的高层策略将复杂任务分解为子任务，即在运行时由高层策略将复杂任务分解成以目标定义的子任务，并交由低层策略完成。一旦LLM代理判断目标达成，便会提出新的目标。为了提升代理在多回合执行中的表现，我们提出了“事后模块化反思”（HMR）方法，与反思整个轨迹不同，该方法通过用中间目标替换任务目标，让代理对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果显示，在5轮执行中，HCRL相比于强大的基于上下文学习的基线，性能提升了9%、42%和10%。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工智能通用（AGI）。然而，在这些基于LLM的代理在实际世界中的行为表现、潜在失败原因及改进方法，特别是在要求苛刻的真实规划任务中的研究还较为匮乏。为此，我们通过本论文尝试填补这一空白，借助一个现实主义基准测试——TravelPlanner，来评估代理在需要满足多重约束条件下生成准确计划的能力。我们利用此基准测试来探讨四个关键研究问题：(1) LLM代理在面对冗长和嘈杂的上下文环境时，其推理和规划能力是否足够稳健？(2) 少样本提示在涉及长上下文的场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化策略来改进计划质量？以及(4) 通过结合正面和负面反馈对LLM进行微调能否带来进一步的性能提升？  我们的综合实验结果显示，首先，尽管LLMs能够处理大量的参考信息和少样本示例，但在处理长上下文时，它们往往未能关注到关键部分；其次，它们在分析长篇计划时仍面临挑战，难以提供精确的反馈以指导计划的细化；最后，我们提出了一种名为“反馈感知微调”（Feedback-Aware Fine-Tuning, FAFT）的方法，该方法利用正负反馈结合的方式，相比仅使用监督微调（Supervised Fine-Tuning, SFT），实现了显著的性能提升。我们的发现为涉及真实世界规划应用的多个方面提供了深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大的表达洞察力的方法，它结合了叙述技巧与可视化和文本。这些故事融入了视觉辅助元素，如图表中突出显示的柱状图和线图，并伴有解释性注释来阐述见解。然而，创建这样的故事需要对数据有深刻的理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种自然语言处理任务上表现出色，但它们生成连贯且全面的数据故事的能力尚未得到充分探索。在本工作中，我们引入了一项新颖的数据故事生成任务及一个包含1,449个来自不同来源的故事的基准数据集。为了应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体来模拟人类讲故事的过程：一个负责理解并描述数据（反思）、生成大纲及叙述，另一个则负责在每个中间步骤进行验证。尽管我们的智能体框架在基于模型和人类评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成中的一些独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收到关于目标位置相对于知名地标语言描述的信息；仅依据对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间并无具体指引。该问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，其中地标往往不可见。在缺乏导航指示的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs根据每次观察“做出反应”并相应地做出决策。然而，该基线性能较差，代理常重复访问同一位置，并做出短视、不连贯的决策。为解决这些问题，本文引入了一种新颖的代理工作流程，其特点是具备感知、反思与规划的能力。具体而言，我们发现LLaVA-7B模型可通过微调以足够精度感知地标的方向和距离，满足城市导航需求。此外，通过记忆机制实现反思，过往经验得以存储，并能与当前感知结合，以便进行有效的决策论证。规划阶段利用反思结果来制定长期计划，从而避免在远距离导航中的短视决策。研究结果显示，设计的这一工作流程显著提升了基于LLM的代理的导航能力，相比现有最先进基线有明显优势。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，各有显著缺点。基于相似性的检索在复杂任务中往往召回率低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的泛用性。为了缓解这些限制，我们引入了CodexGraph系统，该系统将LLM代理与从代码仓库中提取的图数据库接口相结合。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索及代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个现实世界的编程应用。借助统一的图数据库模式，CodexGraph在学术和现实世界环境中均展现出竞争力和潜力，彰显其在软件工程中的多用途性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法既费力又需要在通信、网络和优化领域具有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程方面，网络优化将迎来革新性途径。这一途径通过精心设计的提示来注入人类经验和知识到这些复杂的LLMs中，并部署自主智能体作为通信桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合体现了人工智能（AI）作为服务的未来范式，以及让AI操作更加简便的趋势。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa）以及协作式多LLM基自主BSS智能体（CLaBa）。通过对真实世界数据的评估，实验表明，辅助提示的LLMs和基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提升了BSS优化的效率并减少了人工参与的琐碎程度。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|大型语言模型（LLMs）在处理具有不完美信息的简单游戏及促进多智能体协作方面已展示出成效，但它们在复杂、非英语环境下的不完美信息环境中，尤其是在与其他智能体进行实际合作的能力尚待探索。本研究旨在考察开源与API驱动的LLMs将所学知识应用于需要在不完美信息下进行智能体协作的复杂文本游戏的适用性，并将其性能与采用其他类型智能体的现有基线进行对比。我们提出了一种基于心理理论（Theory of Mind, ToM）的规划技术，使LLM智能体仅根据游戏规则、当前状态和历史背景输入，就能针对不同对手调整策略。为应对该卡牌游戏中动态且庞大的行动空间挑战，我们整合了一个外部工具。结果显示，尽管当前LLMs与最先进的强化学习（RL）模型之间存在性能差距，但LLMs在该游戏设定中展现了ToM能力。它们在对抗对手智能体时持续表现改进，表明其能够理解盟友与对手的行为并能与盟友建立协作。为了促进进一步的研究和理解，我们已公开了代码库。|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|随着大型语言模型（LLMs）的兴起，研究人员正日益探索其在多个垂直领域的应用，软件工程便是其中之一。LLMs在代码生成和漏洞检测等领域取得了显著成就。然而，它们也表现出许多局限性和缺点。基于LLM的智能体作为一种新颖技术，具有实现人工智能通用（AGI）的潜力，通过将LLMs作为决策与行动的核心，缓解了LLMs固有的某些局限，如缺乏自主性和自我改进能力。尽管有大量的研究和调查探讨了在软件工程中使用LLMs的可能性，但目前在LLMs与基于LLM的智能体之间缺乏清晰的区分。对于统一标准及基准测试来界定一个LLM解决方案是否能成为其领域内的基于LLM的智能体，这一领域仍处于初级阶段。  本调研广泛探究了软件工程中LLMs及其基于LLM的智能体的当前实践与解决方案。具体而言，我们总结了六个关键主题：需求工程、代码生成、自主决策、软件设计、测试生成及软件维护。我们从这六个方面回顾并区分了LLMs与基于LLM的智能体的工作，考察了它们在任务、基准及评估指标上的异同。最终，我们讨论了所采用的模型与基准，全面分析了它们在软件工程中的应用效果及有效性。我们期待，这项工作能为推动基于LLM的智能体在软件工程领域的边界拓展提供有益启示，指导未来的科研方向。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## llm

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL查询。模式链接的目标是从数据库模式中检索出与查询相关的表和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常会导致遗漏生成准确查询所必需的列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能自发识别出相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够跳过模式链接步骤，直接将完整的数据库模式传递给LLM，从而避免了遗漏重要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保关键模式信息不被遗漏。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的技术综述存在较大空白。本调查旨在提供对模型融合方法及理论、其在多种领域与场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，强调了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset数据集，专门用于评估SLLMs中的社会偏见。通过考察不同模型如何回应来自不同人口群体的语音，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐性能。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并时常生成“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。增强LLMs的一种有效途径是结合外部数据库和信息检索机制。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，它将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过将知识图谱的结构化表示与密集向量检索的灵活性相结合，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，增强了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解和应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者最终的数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一种多智能体CDSS，利用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫度量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型采用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划制定及资源分配等关键领域表现出强劲性能。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能缓解ED拥挤并改善患者预后。此项工作为急诊医学中AI应用的不断增长领域做出了贡献，并为未来研究和临床实施指出了一个有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，即时学习（ICL）展现出了重要的能力。通过采用少量示例的演示方式来指导LLMs，ICL使这些模型能够在无需更新数百万参数的情况下，执行各种任务。本论文提出了一种针对LLMs的统一框架，使它们能够自我选择有影响力的即时示例来构建上下文；对不同演示组合的候选进行自排名；并通过强化学习来自我优化演示的选择及排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于LLM自身偏好的奖励训练后，生成优化的演示。实验结果验证了所提方法在提升ICL性能方面的有效性。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中纳入更多多样性。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## Wireless Network

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所必需的列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的需求问题。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程可以完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不涉及昂贵的计算成本。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在不同领域与环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们的目标是识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。尽管先前的防御措施通过扰动或检查输入来缓解这些风险，但它们忽略了竞争目标，这是对齐失败的根本原因。在本文中，我们提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根源。首先，我们定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈来计算后对齐概率。随后，AED自适应地结合AED与后对齐概率以及原始概率，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时增强了安全对齐。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库与信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进一步利用领域特定知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，增强了事实信息处理和复杂推理任务的性能，优化了信息检索的效率与准确性。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|无人驾驶航空器（UAV）已成为下一代无线网络的关键组成部分，特别是在灾难恢复场景下，因其灵活性、机动性和快速部署能力而显得尤为重要。本文聚焦于利用太赫兹（THz）链路优化UAV轨迹，以确保灾区通信的有效性。我们面对的挑战包括能量消耗、用户优先级划分，以及在复杂的三维障碍环境中维持视线（LoS）连接以进行有效导航。我们的贡献在于开发了一种详细的建模方法，该方法利用在线三维地图数据，构建了最优轨迹优化问题的数学模型，并提出了一种基于遗传算法（GA）的方法及一种增强型启发式算法以加快收敛速度。通过三维仿真，我们展示了在最小化总服务时间和优先保障高权重节点之间的权衡，揭示了不同优先级权重因子对轨迹时间的影响。提出的算法采用卡塔尔多哈West Bay区域的真实世界数据进行了评估，证明了其在紧急响应中优化UAV轨迹的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别出诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和发展的潜在途径。|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在通过分类层次方法评估基于照片的数学问题场景，以此来评估MLLMs的理论理解及应用能力。  我们对11个先进的MLLMs进行了多维度的评估，发现即使是最复杂的模型也面临着我们的基准测试带来的挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏“完成定义”，导致已识别的威胁需要验证，从而减缓了分析速度。现有文献主要关注威胁分析的整体效能，却未曾探讨分析师在何种深度挖掘材料后，能有效验证所识别的安全威胁。我们提出一项对照实验，与从业者合作研究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（系统数据流图及LLM生成的建议）是否优于少量材料。此外，我们分享了41名硕士研究生参与先导研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据最终的从业者数据收集活动扩展其内容（例如，增加预筛选问题）。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划制定及资源分配等关键领域表现出色。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为AI在急诊医学领域的应用做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

## Wireless Communications

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保关键模式信息不被遗漏。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在不同领域与环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多种机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在包括涉及多模态数据（如语音）在内的各种任务中取得了显著的性能，但这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们的目标是识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，虽然大多数模型展现出的偏见最小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。尽管之前的防御方法通过扰动或检查输入来缓解这些风险，但它们忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新型防御方法，该方法利用自适应解码技术来解决越狱问题的根本原因。我们首先定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈来计算后对齐概率分布。随后，AED通过自适应结合AED产生的概率分布、后对齐概率与原始概率分布，以获得无害且有助益的输出分布。因此，我们的方法在保持有用性的同时增强了安全对齐性能。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。相关代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库与信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM回答的准确性和可靠性。接着，WeKnow-RAG利用领域特定知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评价其所生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大规模语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在网络威胁检测能力增强方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏一个明确的完成定义，这意味着已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项对照实验，与从业人员合作，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们还分享了通过对41名理学硕士学生的先导研究获得的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含了实验材料和数据分析脚本，并计划根据与从业人员进行的最终数据收集活动（例如，预先筛选问题）来扩展该包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助急诊科医生和护士进行患者分诊、治疗规划及整体应急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面的准确性表现出色。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强大的性能。   我们的多智能体CDSS显示了在支持全面应急护理管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能缓解ED拥堵并改善患者预后。此项工作对急诊医学中AI应用领域的拓展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，即时学习（ICL）展现了显著的能力。通过采用少量示例作为演示，ICL使LLMs能够在无需更新数百万参数的情况下执行各种任务。本文提出了一种针对LLMs的统一框架，使它们能够自选有影响力的即时示例来构建上下文；对不同演示组合的候选进行自排名；并通过强化学习来自我优化演示的选择与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过由LLM自身偏好产生的奖励训练后，生成优化的演示。实验结果验证了所提方法在提升ICL性能方面的有效性。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|

## Wireless Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL查询。模式链接的目标是从数据库模式中检索出与查询相关的表和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常会导致遗漏生成准确查询所必需的列。在本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需显式的模式链接。这一发现使得文本到SQL的处理流程能够跳过模式链接环节，直接将完整的数据库模式传递给语言模型，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保不会遗漏重要的模式信息。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然匮乏。本调查旨在提供对模型融合方法及理论、其在多种领域及场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，强调了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型如何回应来自不同人口群体的语音，我们旨在识别这些偏见。实验揭示了关于它们的性能和偏见程度的重要见解。研究结果表明，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。接着，AED通过自适应结合AED与后对齐概率值以及原始概率值，以获得无害且有益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐性能。我们在五个模型和四种常见的越狱攻击中进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提高LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，提升了事实信息处理和复杂推理任务的表现。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大规模语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时指出了进一步研究和开发的潜在途径。|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次化方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过分析评估结果，我们识别了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏明确的完成标准，这意味着已识别的威胁需要经过验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项对照实验，旨在与从业者合作，探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们还分享了对41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含了实验材料和数据分析脚本，并计划根据与从业者进行的最终数据收集活动（例如，预先筛选问题）来扩展该复制包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划制定及资源分配等关键领域展现了强劲性能。   我们的多智能体CDSS显示了在支持全面紧急医疗服务管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在语言模型领域，基于上下文的学习（In-context Learning, ICL）随着大型语言模型（Large Language Models, LLM）的发展展现出重要能力。通过采用少量示例进行演示教学，ICL使LLMs能够在无需调整数百万参数的情况下，完成多样化的任务。本论文介绍了一个统一框架，使LLMs能够自主选择对其构成上下文有影响力的示例、对不同演示组合的候选进行自排名，并通过强化学习自我优化示例的选择及排序过程。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在LLM自身偏好的奖励训练后生成优化的演示示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，同时在检索中融入更多多样性。|

## Communication Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力常常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，如果直接查看相应的图形内容，人类能轻松作答，我们通过实验对此进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染出的视觉内容。  我们利用这一任务创建了一个针对符号图形程序语义理解的大规模基准测试。该基准通过程序-图形对应关系构建，因此需要最少的人力投入。我们在这一基准上评估当前的LLMs，以初步了解它们根据程序推理视觉场景的能力。我们发现，这一任务能区分现有的LLMs，并且在推理方面表现较好的模型在此任务上的表现更佳。  最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们向GPT4-o提出问题，并使用符号程序生成的图像，这些数据随后被用于微调LLM。我们还发现，SIT数据能提升LLMs的一般指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于已知的高质量数据集作为参考，这可能会引入潜在偏差并损害多样性。本文提出了一种名为ScalingFilter的新方法，该方法根据在相同数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而在过滤过程中消除参考数据集的影响。理论分析表明，ScalingFilter等价于对规模法则的逆向利用。通过使用13亿参数的模型在同一数据源上，经不同质量过滤器处理后的数据进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型进行语义表示。广泛实验揭示，语义多样性是数据集多样性的可靠指标，而ScalingFilter在下游性能与语义多样性之间实现了最优平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样例，涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLMs的性能，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度及某些未预期的一致性问题。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战这一激动人心的初步尝试。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的日志解析工作，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中面临三大问题：首先，基于传统启发式的方法需要手工特征和领域知识，这很难大规模泛化。其次，依赖大型语言模型的现有解析器采用定期离线处理方式，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会引发大量误报，掩盖真实的异常情况。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs（大型语言模型）进行高性能、成本效益高的在线语义解析器。我们通过一个创新的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而将查询成本降低数个数量级。为了应对日志漂移问题，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著优于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，进一步证实了其在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析任务既有效又高效。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话提供了用户现实世界场景、行为和需求的窗口，因此是模型开发和研究的宝贵资源。尽管营利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，但开源和研究社区在这方面进展较慢。我们推出了ShareLM集合，这是一组统一的人类与大型语言模型的对话数据集，以及配套的插件——一个允许自愿贡献用户-模型对话的网络扩展。鉴于少数平台分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台分享对话。该插件允许用户在对话及回复层面进行评级，并可在对话离开用户本地存储之前删除他们希望保密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人机数据领域投入更多社区力量。代码、插件和数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并且在针对多模态输入进行分析性判断与决策方面展现出可用性。为了借助LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够在给定文本指令下自主规划行为及低级执行，同时观测并纠正任务执行过程中可能出现的失败。为了系统性地评估这一框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上表现出的优越性能而变得日益流行，相比密集型模型更为出色。然而，在大规模设置下从零开始训练MoE模型成本高昂。现有方法通过以下方式缓解这一问题：先独立预训练多个密集专家模型，并利用这些模型来初始化MoE。具体实现时，采用各专家的前馈网络（FFN）来初始化MoE的专家层，同时合并其它参数。但这种方法限制了密集模型参数的复用范围，仅限于FFN层，从而在将这些模型“升级循环”为MoE时限制了潜在优势。我们提出了一种名为BAM（Branch-Attend-Mix，分支-关注-融合）的简单而高效的方法，旨在解决这一不足。BAM充分利用了专门的密集模型，不仅利用它们的FFN来初始化MoE层，还通过将注意力参数完全利用起来，将它们初始化到注意力混合（Mixture of Attention, MoA）层的软变体中，从而充分发挥了升级潜力。  我们探索了两种升级注意力参数的方法：1) 从密集模型中单独初始化注意力专家，包括所有注意力参数，以实现最佳模型性能；2) 在所有专家间共享键（key）和值（value）参数，以促进更优的推理效率。为进一步提升效率，我们将并行注意力变换器架构引入到MoE中，使得注意力专家和FFN专家可以并发计算。在规模从5.9亿到20亿参数的种子模型上的实验表明，BAM在同等计算资源和数据约束条件下，无论是在困惑度还是下游任务性能上，均超越了基线水平。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效对齐两者间的语义表示仍是一个未解的挑战。受此观点启发，我们提出了一种新颖的即插即用对齐框架，用于LLMs与协同模型。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享成分。随后，在共享表示上执行全局和局部结构对齐，以促进知识转移。此外，我们从理论上证明了特定和共享表示包含了更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有的一流算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的显著进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能够以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争论。该争论的核心围绕两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一套理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下可以计算出PN和PS的合适近似值。本研究标志着朝着深入理解LLMs在何时能够进行推理这一目标迈出的重要一步，并通过一系列数学实例加以说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|在不断进步的数字通信系统领域，复值神经网络（CVNNs）已成为基石，尤其在均衡、信道估计、波束成形和解码等任务中展现出卓越性能。在众多CVNN架构中，相位传输径向基函数神经网络（PT-RBF）尤为突出，尤其是在诸如5G MIMO系统这类充满噪声的环境中运行时。尽管其功能强大，但在多层、多输入多输出的PT-RBF中实现收敛仍是一个艰巨挑战。针对这一不足，本文提出了一种新颖的深度PT-RBF参数初始化技术。通过遵循3GPP TS 38标准的严格仿真，我们的方法不仅超越了传统初始化策略（如随机、K-均值和星座基方法），而且是唯一能在深层PT-RBF架构中实现成功收敛的方法。这些发现为在复杂数字通信系统中部署更稳健、更高效的神经网络铺平了道路。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在提供对模型融合方法及理论、其在多种领域及场景中的应用，以及未来研究方向的综合概述。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本论文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED灵活地将AED及后对齐概率值与原始概率值结合，以获得无害且有益的概率分布。因此，我们的方法在提升安全对齐的同时，保持了帮助性。实验涵盖了五个模型和四种常见的越狱攻击，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法称为WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG接着利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了研究发现，并突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，同时概述了进一步研究和发展的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也极具挑战性。通过对评估结果的分析，我们识别了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，却未曾研究分析师在深入到何种程度的材料分析后，才能有效验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名理学硕士学生的试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。虽然临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。  我们开发了一个多智能体CDSS，使用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫度量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。  模型采用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强劲性能。  我们的多智能体CDSS显示了在支持全面紧急医疗服务方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能缓解ED拥挤并改善患者预后。此项工作为AI在急诊医学中的应用领域做出了贡献，并为未来的科研与临床实施指明了有希望的方向。|

## RAG

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们迈出了一步，转向了一个新任务：关注符号图形程序，这是图形内容的一种流行表示形式，可以程序化生成视觉数据。尽管LLMs在程序合成方面展现出了令人兴奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过回答与图形内容相关的问题来衡量LLMs对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过我们进行的人类实验验证，从相应的图形内容回答这些问题将很容易。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个大型基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应关系构建，因此需要最少的人力投入。我们在该基准上评估当前的LLMs，以初步揭示它们从程序中推断视觉场景的能力。我们发现，此任务能区分现有的LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们使用由符号程序生成的问题和图像查询GPT4-o。这些数据随后被用来微调LLM。我们还发现，SIT数据能够提升LLMs的一般指令跟随能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于一个已知的高质量数据集作为参考，这可能引入潜在偏差并损害多样性。在本文中，我们提出了ScalingFilter这一新颖方法，它根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而在过滤过程中消除了参考数据集的影响。理论分析表明，ScalingFilter等价于规模法则的一种逆向利用。通过使用13亿参数的模型在经过不同质量过滤器处理的相同数据源上进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型对语义表示进行度量。广泛的实验揭示了语义多样性是数据集多样性的一个可靠指标，而ScalingFilter在下游性能和语义多样性之间实现了最优平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（LLMs），包括GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3以及Llama 3.1，在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLMs的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些意外的不一致性行为。我们的研究标志着迈向利用人工智能通用解决方案应对复杂交通挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的 log parsing（日志解析）过程，是自动化日志分析任务（如异常检测、故障排查及根本原因分析）的先决条件。然而，现有的日志解析器在实际系统中面临三大挑战：首先，基于传统启发式的方法需要手工特征和领域知识，这很难大规模推广；其次，依赖大型语言模型的现有解析器采用定期离线处理方式，限制了它们在实时应用场景中的有效性；再者，现有的在线解析算法易受日志漂移影响，即日志的微小变化会引发大量误报，从而掩盖真实异常。为解决这些难题，我们提出了HELP（Hierarchical Embeddings-based Log Parser，基于层次嵌入的日志解析器）。HELP是首个利用LLMs（大型语言模型）进行高性能且成本效益高的在线语义解析的日志解析器。我们通过一个创新的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而使查询成本降低数个数量级。为了应对日志漂移问题，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，进一步证实了其在生产环境中的实用性。研究结果表明，HELP能有效且高效地应对高吞吐量的实际日志解析需求。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话提供了洞察用户现实场景、行为和需求的窗口，因此对于模型开发和研究而言，是一种宝贵的资源。尽管盈利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，开源与研究社群在这方面的发展却相对滞后。我们引入了ShareLM集合，这是一套统一的人类与大型语言模型对话的集合，以及一个配套的插件——一个旨在自愿贡献用户-模型对话的网络扩展。鉴于少数平台会分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台分享对话。该插件允许用户对其对话进行评级，既可以在对话层面也可以在回复层面进行评价，并且可在对话离开用户本地存储之前，删除他们希望保持私密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人机数据领域投入更多社区力量。代码、插件及数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并展现出对多模态输入进行分析判断与决策的可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低级执行过程，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估该框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上表现出的优越性能而变得日益流行，相比密集型模型更为出色。然而，在大规模环境下从零开始训练MoE模型成本高昂。现有方法通过预训练多个独立的密集型专家模型并利用它们来初始化MoE模型以缓解这一问题。具体实现时，将这些密集模型的前馈网络（Feed-Forward Network, FFN）用于初始化MoE的专家层，同时合并其它参数。但这种方法限制了密集模型参数的复用范围，仅限于FFN层，从而在将这些模型“升级循环利用”为MoE时限制了潜在优势。我们提出了BAM（Branch-Attend-Mix）这一简便而高效的方法，旨在解决这一不足。BAM充分利用特化的密集模型，不仅利用其FFN来初始化MoE层，还通过将注意力参数全盘利用，将它们初始化到软混合注意力（Mixture of Attention, MoA）层的一个变体中，从而更充分地发挥前期训练成果。  我们探索了两种升级循环注意力参数的方法：1）从密集模型中单独初始化注意力专家，包括所有注意力参数，以实现最佳模型性能；2）在所有专家间共享键（key）和值（value）参数，以促进更高效的推理。为进一步提升效率，我们采纳了并行注意力变压器架构应用于MoE中，使得注意力专家与FFN专家能够并行计算。我们在规模从5亿9千万至20亿参数的种子模型上的实验表明，BAM在保持相同计算资源和数据约束条件下，无论是在困惑度还是下游任务性能上，均超越了基线水平。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本研究证明了直接对LLMs与协同模型的表征进行对齐对于增强下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解难题。受此观点启发，我们提出了一种新颖的即插即用对齐框架，用于LLMs与协同模型的融合。具体而言，我们首先通过投影层和表征正则化，将LLMs与协同模型的潜在表征分解为特定和共享成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识转移。此外，我们理论上证明了特定和共享表征含有更多相关且少冗余信息，从而能提升下游推荐任务的效果。广泛的实验结果在基准数据集上表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作有瑕疵的数据标注员以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法在七项上超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性概率（PN）与充分性概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践意义的框架，旨在评估LLMs运用这些概率测度模拟现实世界推理机制的有效性。通过将LLMs视作经由自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝着深入了解LLMs何时能够进行推理迈出的重要一步，并通过一系列数学实例加以说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式直接传递给LLM，从而避免了遗漏必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保不丢失重要的模式信息。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名第一。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在多种领域及环境下的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在包括涉及多模态数据（如语音）在内的各种任务中取得了显著的性能，但这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这突显了迫切需要解决这些偏见问题。本研究引入了“口语刻板印象集”（Spoken Stereoset），这是一个专门设计用于评估SLLMs中社会偏见的数据集。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。我们的实验揭示了关于它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出最小的偏见，但有些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率分布。随后，AED动态地将AED产生的概率分布和后对齐概率与原始概率分布相结合，从而获得既无害又有助益的输出分布。因此，我们的方法在提升安全对齐的同时保持了模型的有用性。实验覆盖了五个模型及四种常见的越狱攻击场景，结果验证了该方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，并概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|## 背景 在21世纪的乌干达，中学教育质量低下仍是面临的主要挑战之一，特别是在农村地区。研究指出多个问题，其中包括教师授课计划的质量低或缺失。随着政府推动实施新课程，现有的授课计划变得过时，问题更加严峻。针对这一情况，我们采用了一种检索增强生成的方法，开发了一个原型系统，该系统能根据政府认可的教科书生成定制化的授课计划。这有助于教师更高效、更高质量地制定授课计划，确保它们与新课程及能力本位学习方法完全一致。  ## 方法 该原型系统利用Cohere大语言模型、句子嵌入技术以及LangChain框架构建，并公开发布于网站上。我们为三本新课程教科书（信息技术、数学、历史）建立了向量存储库，这些教科书均为中学一年级水平。依据教科书建议的教学时段，我们遵循伪随机生成协议生成了24份授课计划。之后，依据Ndihokubwayo等人（2022年）设计的适用于东非及能力本位课程的授课计划分析协议（LPAP），由三位独立评估员对这些授课计划的技术质量进行了分析。  ## 结果 利用LPAP对24份授课计划进行评估后，其平均质量达到了75%至80%，对应“非常优秀的授课计划”等级。没有一份授课计划得分低于65%，尽管有一份计划在主题覆盖上可能存在争议。总的来说，生成的授课计划质量至少与人工制定的计划相当，甚至更好。这从卢旺达的一项研究中得到印证，在那项研究中，没有任何一份人工制定的授课计划达到50%的基准分数。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，从而减缓了分析过程。以往的研究主要集中在威胁分析的整体效能上，但没有前人工作探讨过分析师必须深入到何种程度，才能有效地验证已识别的安全威胁。  我们提出了一项对照实验，旨在与从业者合作，研究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少的材料。此外，我们还分享了对41名硕士研究生进行先导研究的关键发现，这些发现被用来改进实验设计。最后，我们提供了一个初步的复制包，其中包含了实验材料、数据分析脚本，并计划根据与从业者进行的最终数据收集活动（例如，预先筛选问题）来扩展包含新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划和资源分配等关键领域展现了强劲性能。   我们的多智能体CDSS在支持全面紧急医疗服务管理方面显示出了巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗交付，缓解ED拥挤并提升患者预后。这一工作为急诊医学中AI应用的不断增长领域做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

## text2sql

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验对此进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个针对符号图形程序语义理解的大规模基准测试。该基准测试通过程序-图形对应关系构建，因此需要最少的人力投入。我们在该基准上评估当前的LLMs，以初步了解它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们使用由符号程序生成的问题和图像来查询GPT4-o。此类数据随后被用于微调LLMs。我们还发现，SIT数据能提高LLMs的一般指令跟随能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于一个已知的高质量数据集作为参考，这可能引入潜在偏差并损害多样性。在本文中，我们提出了ScalingFilter这一新颖方法，它根据在同一数据上训练的两个语言模型的困惑度差异来评估文本质量，从而在过滤过程中消除了参考数据集的影响。理论分析表明，ScalingFilter等价于规模法则的逆向利用。通过使用13亿参数的模型在同一数据源上，经过不同质量过滤器处理后的数据进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型进行语义表示。广泛实验揭示，语义多样性是数据集多样性的可靠指标，而ScalingFilter在下游性能和语义多样性之间实现了最佳平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（LLMs），包括GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3以及Llama 3.1，在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用于评估各种商业及开源LLMs的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致行为。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战这一领域的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的日志解析工作，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中面临三大问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会引发大量误报，从而掩盖真实的异常情况。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs（大型语言模型）进行高性能且成本效益高的日志解析的在线语义解析器。我们通过一个创新的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而使查询成本降低数个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公开数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，进一步证实了其在生产环境中的实用性。研究结果表明，HELP对于高吞吐量的实际日志解析任务既有效又高效。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话提供了洞察用户现实场景、行为和需求的窗口，因此对于模型开发和研究而言，是一种宝贵的资源。尽管盈利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，开源与研究社群在这方面的发展却相对滞后。我们引入了ShareLM集合，这是一组统一的人类与大型语言模型的对话数据集，以及配套的插件——一个旨在自愿贡献用户-模型对话的网络扩展。鉴于少数平台会分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台分享对话。该插件允许用户在对话及回复层面进行评价，并可在对话离开用户本地存储之前，删除他们希望保持私密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人类-模型数据领域投入更多社群力量。代码、插件及数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并展现出对多模态输入进行分析判断与决策的可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种基于语言模型的新框架，使机器人能够根据给定的文字指令自主规划行为及低级执行，并在任务执行过程中观察及纠正可能出现的失败。为了系统性地评估该框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了此方法在具备自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上相比密集模型的卓越性能而变得流行。然而，在大规模设置下从头开始训练MoE模型成本高昂。现有方法通过独立预训练多个密集专家模型并用它们来初始化MoE来缓解这一问题。这是通过使用专家的前馈网络（FFN）来初始化MoE的专家层，同时合并其他参数来实现的。但是，这种方法限制了密集模型参数的重用仅限于FFN层，从而在将这些模型“升级循环利用”为MoE时限制了优势。我们提出了BAM（Branch-Attend-Mix），一个简单而有效的方法来解决这个缺点。BAM通过不仅利用密集模型的FFN来初始化MoE层，还通过将注意力参数完全初始化到注意力混合（Mixture of Attention, MoA）层的软变体中，充分利用了专门化的密集模型。  我们探索了两种升级循环利用注意力参数的方法：1）从密集模型中包括所有注意力参数初始化单独的注意力专家，以实现最佳模型性能；2）在所有专家间共享键和值参数，以促进更优的推理效率。为了进一步提高效率，我们采用了一种并行注意力变压器架构应用于MoE，使得注意力专家和FFN专家可以并行计算。我们在从5.9亿到20亿参数规模的种子模型上的实验表明，BAM在相同的计算和数据约束下，在困惑度和下游任务性能上均超越了基线。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，已有多种尝试旨在从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐对于增强下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效地在协同模型与LLMs之间对齐语义表示的问题仍未得到妥善解决。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局和局部结构对齐，以促进知识迁移。此外，我们从理论上证明了特定和共享表示包含了更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的显著进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能够以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争论。该争论的核心围绕两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践意义的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝着深入了解LLMs何时能够进行推理这一目标迈出的重要一步，并通过一系列数学实例进行了说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够跳过模式链接环节，直接将完整的数据库模式传递给LLM，从而避免了信息缺失的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，在不牺牲关键模式信息的前提下提升了文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在通过一项综合调查来填补这一空缺，全面概述模型融合方法与理论、它们在不同领域及环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地探讨了现有的模型融合技术。其次，我们讨论了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多种机器学习子领域的应用。最后，我们指出了模型融合存在的挑战，并探讨了未来的研究趋势。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，加剧了迫切需要解决这些偏见的问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED灵活地将AED产生的概率值与后对齐概率值及原始概率值结合起来，以获得无害且有助益的概率分布。因此，我们的方法在提升安全对齐的同时保持了模型的有用性。我们在五个模型上针对四种常见的越狱攻击进行了实验，结果验证了我们方法的有效性。代码可在https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现人工智能通用（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并时常生成“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成了重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过将知识图谱的结构化表示与密集向量检索的灵活性相结合，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱来满足多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别出的关键问题包括可解释性、可扩展性和对不断演变威胁的适应性等。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和发展的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，从而减缓了分析过程。以往的研究主要集中在威胁分析的整体效能上，但没有前人工作探讨过分析师必须深入到何种程度，才能有效地验证已识别的安全威胁。  我们提出了一项对照实验，与从业人员合作，旨在研究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少的材料。此外，我们还分享了与41名硕士研究生进行先导试验的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与从业人员的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由一名临床急诊医学专家进行评定。与单智能体系统基线相比，CDSS在分诊决策方面的准确性表现出色。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域也表现强劲。   我们的多智能体CDSS显示了在支持全面紧急护理管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例进行演示，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文提出了一种针对LLMs的统一框架，使它们能够自选有影响力的示范性示例以构建上下文；对不同示范组合的候选进行自排名；并通过强化学习自优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于LLM自身偏好的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|

## AIOps

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验验证了这一点。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个大规模的基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应构建，因此需要最少的人力投入。我们在这一基准上评估当前的LLMs，以初步揭示它们根据程序推断视觉场景的能力。我们发现，此任务能区分现有LLMs，并且在推理方面表现良好的模型在此任务上表现更佳。最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们使用由符号程序生成的问题和图像来查询GPT4-o。这些数据随后被用来微调LLMs。我们还发现，SIT数据能够提高LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于一个已知的高质量数据集作为参考，这可能引入潜在偏差并损害多样性。本文提出了一种名为ScalingFilter的新方法，该方法根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而在过滤过程中消除了参考数据集的影响。理论分析表明，ScalingFilter等价于规模法则的一种逆向利用。通过使用13亿参数的模型在同一数据源上，经不同质量过滤器处理后的数据进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型对语义表示进行度量。广泛的实验揭示了语义多样性是数据集多样性的一个可靠指标，而ScalingFilter在下游性能和语义多样性之间实现了最优平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（LLMs），包括GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3以及Llama 3.1，在解决选定的本科层次交通运输工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理和控制问题样本。该数据集被人类专家用来评估各种商业及开源LLMs的性能，尤其是它们在解决交通运输工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度以及一些未预料到的不一致行为。我们的研究标志着利用人工智能通用解决复杂交通运输挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的 log parsing（日志解析）过程，是自动化日志分析任务（如异常检测、故障排查及根本原因分析）的先决条件。然而，现有的日志解析器在实际系统中面临三大挑战：首先，基于传统启发式的方法需要手工特征和领域知识，这很难大规模推广；其次，依赖大型语言模型的现有解析器采用定期离线处理方式，限制了它们在实时应用场景中的有效性；再者，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会引发大量假阳性结果，从而掩盖真实异常。为解决这些难题，我们提出了HELP（Hierarchical Embeddings-based Log Parser，基于层次嵌入的日志解析器）。HELP 是首个利用LLMs（大型语言模型）进行高性能且成本效益高的在线语义解析的日志解析器。我们通过一个创新的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而使查询成本降低数个数量级。为了应对日志漂移问题，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，进一步证实了其在生产环境中的实用性。研究结果表明，HELP能高效且有效地应对高吞吐量的实际日志解析需求。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话提供了用户现实世界场景、行为和需求的窗口，因此是模型开发和研究的宝贵资源。尽管营利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，但开源和研究社区在这方面进展较慢。我们推出了ShareLM集合，这是一组统一的人类与大型语言模型的对话数据集，以及配套的插件——一个允许自愿贡献用户-模型对话的网络扩展。鉴于少数平台分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台分享对话。该插件允许用户在对话及回复层面进行评级，并可在对话离开用户本地存储之前删除他们希望保密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人机数据领域投入更多社区力量。代码、插件和数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时在多模态输入的分析判断与决策方面展现出实用性。为了借助LLMs的力量促进人形机器人的移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低级执行过程，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估该框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并使用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用价值。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上表现出的优越性能而变得日益流行，相比密集型模型更具优势。然而，在大规模环境下从零开始训练MoE模型成本高昂。现有方法通过预训练多个独立的密集型专家模型并利用它们来初始化MoE模型以缓解这一问题。具体实现时，将这些密集模型的前馈网络（Feed-Forward Network, FFN）用于初始化MoE的专家层，同时合并其它参数。但这种方法的局限在于仅重用了密集模型的FFN层参数，限制了将其“升级循环利用”为MoE模型时所能获得的好处。我们提出了一种名为BAM（Branch-Attend-Mix）的方法，旨在解决这一不足。BAM通过不仅利用密集模型的FFN来初始化MoE层，并且通过将专家的注意力参数全盘利用，以软变体的混合注意力（Mixture of Attention, MoA）层形式进行初始化，从而充分利用了特化的密集模型。  我们探索了两种升级循环利用注意力参数的方法：1）从密集模型中单独初始化包含所有注意力参数的注意力专家，以实现最佳模型性能；2）在所有专家间共享键（key）和值（value）参数，以促进更优的推理效率。为了进一步提升效率，我们采纳了并行注意力变压器架构应用于MoE，使得注意力专家与FFN专家能够并行计算。我们在规模从5亿9千万到20亿参数的种子模型上的实验表明，BAM在同等计算和数据约束条件下，无论是在困惑度还是下游任务性能上，均超越了基线水平。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本研究证明，直接对LLMs与协同模型的表征进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解难题。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表征正则化，将LLMs与协同模型的潜在表征分解为特定和共享成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表征含有更多相关且少冗余的信息，能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了仅使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性概率（PN）与充分性概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文引入了一个理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝着更深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不涉及昂贵的计算成本。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然匮乏。本调查旨在提供对模型融合方法与理论、其在多种领域及场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于训练数据的特性，往往会表现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现出来，这凸显了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了关于模型性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出的偏见最小，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐能力。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还集成了一个自我评估机制，使LLM能够评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严谨框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于的IDS在多种环境和应用中的实施情况，涉及计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还解决了研究挑战和未来方向，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并强调了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在通过分类层次方法评估基于图片的数学问题场景，检验MLLMs的理论理解与应用能力。  我们对11个先进的MLLMs进行了多维度评估，发现即使是最高级的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进实验设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一种多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者结局。此项工作对急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指出了一个有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例作为演示，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文提出了一种针对LLMs的统一框架，使模型能够自选有影响力的示范性例句来构建其上下文；对不同示范组合的候选进行自排名；并通过强化学习来自我优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于模型自身偏好的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的例子，并在检索中融入更多多样性。|

## PPC

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|null|联邦学习（FL）是一种增强隐私的技术，用于分布式机器学习。通过本地训练模型并聚合更新，联邦能够在不进行集中数据收集的情况下协同学习。FL在医疗、金融和个人计算领域日益受到欢迎。然而，它继承了经典机器学习中的公平性挑战，并因数据质量差异、客户端参与度、通信限制、聚合方法及底层硬件差异引入了新的挑战。公平性仍然是FL中一个未解决的问题，社区已识别出缺乏简明的定义和指标来量化公平性；为应对这一问题，我们提出了联邦公平性分析方法论——一种衡量公平性的方法。我们的公平性定义包括四个概念，并配有相应的创新指标。这些定义是针对问题的症状性定义，利用了源自可解释AI、合作博弈论和网络工程的技术。  我们在不同的实验设置下进行了测试，包括改变FL方法、机器学习任务和数据设置。结果表明，统计异质性和客户端参与度会影响公平性，而诸如Ditto和q-FedAvg等注重公平性的方法仅在一定程度上改善了公平性与性能之间的权衡。借助我们的技术，FL从业者能够揭示其系统公平性的前所未有的深入见解，这些见解涵盖不同层次的细节，从而帮助解决FL中的公平性挑战。我们的工作已开源，访问地址为：https://github.com/oscardilley/federated-fairness。|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|分布式太阳能发电系统的快速增长给配电系统规划和调度带来了挑战，主要原因是这类系统背后的太阳能发电难以观测。为了解决集中式机器学习方法在估算用户侧（BTM）太阳能发电量时的数据泄露问题，联邦学习（FL）方法因具备分布式学习能力而受到研究者的关注。然而，传统的联邦学习方法面临着异构性、通信故障以及恶意隐私攻击等多种挑战。针对这些挑战，本研究提出了一种针对异构社区级BTM太阳能发电量的通信鲁棒性和隐私安全的分布式估计算法。具体而言，本研究采用多任务联邦学习作为主体框架，旨在学习所有社区间的共同特征与独特特性。同时，研究中嵌入了一种更新参数估计算法到多任务联邦学习中，能够自动识别任意两个客户端之间的相似性，并为无法通信的客户端估计更新参数，从而减轻通信故障带来的负面影响。最后，本研究在动态隐私预算分配策略下采用了差分隐私机制，以抵御恶意隐私攻击并提升模型训练效率。案例研究表明，在存在异构性和通信故障的情况下，所提出的算法相比于传统联邦学习和局部化学习方法，展现出更优的估测精度和收敛性能，同时提供了更强的隐私保护。|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|联邦学习是一种高效框架，旨在促进跨多个分布式设备的协作式模型训练，同时保护用户数据隐私。联邦学习的一大挑战是数据层面的异质性，即私人数据的偏斜或长尾分布。尽管已提出多种方法来应对这一挑战，但大多数方法假设全局数据在所有客户端上呈均匀分布。本文研究了数据层面异质性的联邦学习，并通过简要回顾重新定义了一个更为实际且具有挑战性的场景，称为偏斜异质联邦学习（Skewed Heterogeneous Federated Learning, SHFL）。据此，我们提出了一种新颖的联合原型修正与个性化方法，该方法包括两部分：联邦个性化和联邦原型修正。前者旨在根据私人数据在优势类和少数类之间构建平衡的决策边界，而后者则利用类别间区分度和类别内一致性来校正经验原型。在三个流行基准上的实验表明，所提出的这种方法超越了当前最先进的方法，并在个性化与泛化性能上均实现了平衡。|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|住房与无家可归者关爱系统（HHSC）的首要任务是将无家可归者与支持性住房连接起来。该系统通常包含众多服务于相同人群的机构。由于各机构间的信息技术平台在类型和质量上存在差异，它们的数据往往是彼此孤立的。较大的机构可能拥有足够的数据来训练和测试人工智能（AI）工具，而较小的机构通常不具备这样的条件。为解决这一差距，我们引入了一种联邦学习（FL）方法，使所有机构能够协同训练预测模型，同时无需共享其敏感数据。我们展示了如何在HHSC内部使用FL，以使所有机构都能平等获得高质量的AI资源，并进一步辅助人类决策者在系统内更有效地分配资源。这一过程在不分享个人识别信息、未经本人同意不同机构间共享数据的情况下，保护了数据中个体的隐私。我们的实验结果利用了来自加拿大阿尔伯塔省卡尔加里的真实世界HHSC数据，证明了我们的FL方法在性能上可与理想情形相媲美，即在机构间完全共享并链接数据来训练预测模型。|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|联邦学习（FL）通过协同训练机器学习模型，为个人数据提供了更好的隐私保护。当联邦学习参与者行使被遗忘权，即脱离已参与的联邦学习框架并删除其对全局模型的过往贡献时，联邦学习解决方案应执行所有必要步骤以实现这一目标，同时不牺牲全局模型的整体性能，而当前最先进的相关解决方案尚不支持这一功能。本文提出了一种名为FedQUIT的新算法，利用知识蒸馏技术从联邦学习全局模型中抹去待遗忘数据的贡献，同时保持其泛化能力。FedQUIT直接在客户端设备上运行，与常规联邦学习过程相比，无需共享额外信息，也不假设公开可用代理数据的存在。我们的解决方案高效、有效，并且适用于集中式和联邦式两种设置。实验结果表明，平均而言，FedQUIT在擦除后恢复泛化性能所需的额外通信轮次不到2.5%，得到的经过净化的全局模型预测结果可与从未见过待遗忘数据的全局模型相媲美。|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|物联网（IoT）设备在多个领域的迅速普及引发了严重的网络安全问题，这促使了针对网络攻击分类的基于机器学习（ML）的入侵检测系统（IDS）的持续研究。传统ML模型需要将数据从IoT设备传输到集中式服务器进行流量分析，这引发了严重的隐私担忧。为了解决这一问题，研究人员已探索使用联邦学习（FL）构建IDS，该方法能在保持设备数据本地化的同时，在IoT设备间训练模型。然而，由于设备的不同漏洞和攻击向量的复杂性导致的数据异质性，对FL模型的有效性构成了重大挑战。当前研究虽聚焦于在FL框架内调整各种ML模型，但未能有效应对设备间攻击类别不平衡的问题，这一问题显著降低了少数攻击的分类准确性。为克服这一挑战，我们引入了FedMADE，一种新颖的动态聚合方法，它根据设备的流量模式对其进行聚类，并根据其对整体性能的贡献来聚合局部模型。我们通过与针对非独立同分布（non-IID）数据设计的其他FL算法对比评估了FedMADE，观察到了少数攻击分类准确度高达71.07%的提升。此外，我们还展示FedMADE对中毒攻击具有鲁棒性，并且相较于FedAvg，每轮通信仅增加4.7%（5.03秒）的延迟开销，同时不增加IoT设备的计算负担。|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|联邦学习（FL）旨在解决由隐私、安全法规及所有权顾虑所导致的数据孤岛问题。尽管存在这些障碍，FL仍能使这些孤立的数据存储库在不损害隐私或安全的前提下参与协同学习。同时，区块链技术的进步以及Web 3.0时代中去中心化应用（DApps）的发展，为网络开发带来了变革性的可能。因此，将FL融入Web 3.0为通过协同学习克服数据孤岛限制铺平了道路。然而，鉴于以太坊（ETH）等核心区块链的交易速度限制及智能合约的延迟，采用一次性联邦学习（one-shot FL）——即将传统FL中的客户端-服务器交互减少到单次交换——更适合Web 3.0环境。本文提出了一种针对Web 3.0实用的一次性联邦学习系统，称为OFL-W3。OFL-W3利用区块链技术，通过智能合约管理交易，同时借助于星际文件系统（IPFS）与Flask通信的结合，促进后端服务器操作以应用现有的一次性FL算法。通过整合激励机制，OFL-W3展示了一种在Web 3.0上有效实施一次性FL的方法，为AI与Web 3.0结合的研究提供了宝贵见解及未来方向。|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|卫星任务设计正经历从传统的单一庞大卫星向由多颗小型卫星组成的分布式任务配置的范式转变。随着越来越多这类卫星被部署到轨道上，每颗卫星都收集了大量的数据，对轨上边缘计算的兴趣日益增长。联邦学习是一种有前景的分布式计算方法，在此背景下，可使多颗卫星高效协作，进行轨上机器学习模型的训练。尽管近期关于在轨道边缘计算中使用联邦学习的研究主要集中在同质卫星星座上，但联邦学习同样可以应用于异构卫星之间的临时协作场景，例如由不同运营商运行的通信卫星之间。此类应用向联邦学习范式提出了额外挑战，这些挑战主要源自系统的异构性。在这篇立场论文中，我们针对跨运营商应用场景，系统地回顾了这些挑战，对每一项挑战的现状进行了简要概述，并为深入探讨每个问题提供了入口。|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|分布式联邦学习（FL）范式基于区块链架构构建，利用分布式节点集群替代单一服务器执行FL模型聚合。这一范式解决了原始联邦学习中集中式恶意服务器的脆弱性问题，并继承了区块链提供的可信度和健壮性。然而，现有的区块链支持方案面临着模型保密性不足以及区块链执行大规模FL计算的计算资源有限等挑战。本文提出了Voltran，一个创新的混合平台，旨在通过可信执行环境（TEE）与区块链技术的结合，为基于FL的学习实现信任、保密性和健壮性。我们将FL聚合计算卸载到TEE中，以提供一个隔离的、可信的和可定制的链下执行环境，并确保聚合结果在区块链上的真实性和可验证性。此外，我们通过引入多SGX并行执行策略来分摊大规模FL工作负载，从而为多种FL场景提供了强大的可扩展性。我们实现了Voltran的原型，并进行了全面的性能评估。广泛的实验结果表明，Voltran在保证信任、保密性和真实性的同时，仅带来最小的额外开销，并且相比最先进的密文聚合方案显著加速。|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|联邦学习（FL）是一种分布式机器学习方法，它使设备能够在不共享本地数据的情况下协作训练模型，从而确保用户隐私和可扩展性。然而，将FL应用于现实世界的数据面临着挑战，特别是因为现有的大多数FL研究集中在单模态数据上。多模态联邦学习（MFL）应运而生以解决这些挑战，利用模态特定的编码器模型来处理多样化的数据集。当前的MFL方法常常统一地分配所有模态的计算频率，这对于资源有限的物联网设备而言效率低下。在本文中，我们提出了FlexMod这一新颖方法，旨在通过根据各模态编码器的重要性与训练需求自适应地分配训练资源，以此增强MFL中的计算效率。我们采用原型学习来评估模态编码器的质量，使用Shapley值来量化每个模态的重要性，并采纳深度强化学习中的深度确定性策略梯度（DDPG）方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化了模型性能和资源利用。在三个真实世界数据集上的实验结果表明，我们提出的方法显著提高了MFL模型的性能。|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|分布式健康智能网络（DHIN）是一个理论框架，旨在解决因医疗数据在各提供者与机构间碎片化而导致的健康数据主权和人工智能在医疗领域应用的重大挑战。该框架首先确立了医疗保健供应的主权架构作为建立主权健康网络的前提，然后通过克服获取多样化的医学数据源障碍，促进人工智能的有效利用。这一综合框架利用以下三点：1）结合个人健康记录（PHR）的自我主权身份架构，作为实现健康数据主权的基础；2）在公共区块链上实施可扩展的联邦学习（FL）协议，以实现医疗领域的去中心化人工智能训练，其中健康数据保留在参与者手中，仅共享模型参数更新；3）建立一个可扩展且无需信任的奖励机制，激励参与并确保奖励公平分配。该框架确保没有任何实体能够阻止或控制对参与者提供的健康数据进行训练的访问，或决定经济利益，因为这些过程在具有不可篡改记录且无第三方的公共区块链上运行。它支持在医疗领域进行有效的人工智能训练，使患者能够保持对自己健康数据的控制，获得经济收益，并为利用集体智能开发有益于医疗保健的算法贡献于一个去中心化、可扩展的生态系统。作为参与联邦学习协议的激励，患者会收到数字钱包中的奖励，长期规划是为去中心化保险解决方案提供资金。这种方法引入了一种新颖的自筹资金医疗模式，该模式适应个人需求，补充现有体系，并重新定义了普遍覆盖的概念。它强调了在赋予患者权力的同时，转变医疗数据管理和人工智能利用方式的潜力。|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|在金融和医疗等高度受监管的行业领域，数据治理面临严峻挑战，数据的交换与利用尤为困难。联邦学习（FL）作为一种创新的分布式机器学习范式，能够在多个机构间协同进行模型训练，同时保持数据分散，从而应对了这一挑战。然而，FL虽有其优势，却也面临着诸多敌对威胁，特别是在由中心服务器管理的模型聚合阶段容易遭受中毒攻击。此外，神经网络模型仍有可能不经意地记住并潜在暴露个别训练实例，这构成了重大的隐私风险，因为攻击者可能利用模型内部蕴含的信息来重建私人数据。当前的解决方案未能提供一个既完全防止信息泄露又计算高效的安全联邦学习系统。针对这些顾虑，我们提出了Lancelot这一创新且计算高效的联邦学习框架，它采用全同态加密（FHE）技术来防御恶意客户端行为，同时保护数据隐私。广泛的测试表明，包括医学影像诊断和广泛应用的公开图像数据集在内，Lancelot显著超越现有方法，处理速度提升超过二十倍，同时确保了数据隐私。|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|null|心血管疾病是全球范围内导致死亡的主要原因，强调了准确诊断方法的重要性。本研究利用UCI数据集，该数据集包含来自美国、匈牙利和瑞士四家医院的920份患者记录，对心脏病分类中的集中式和联邦机器学习算法进行了基准测试。基准测试得到了Shapley值可解释性分析的支持，以量化特征对于分类的重要性。在集中式设置中，使用多种二元分类算法对汇总数据进行训练，其中支持向量机（SVM）达到了最高的测试准确率83.3%，超过了使用逻辑回归建立的78.7%的既定基准。此外，我们还探索了联邦学习算法，其中四个客户端（医院）各自持有数据，利用数据集的自然划分来增强隐私保护，同时不牺牲准确性。联邦SVM作为一种文献中较少见的方法，在此场景下达到了73.8%的最高测试准确率。我们的可解释性分析与现有的心脏病指标医学知识相吻合。总的来说，本研究为高效且可解释的心脏病预筛查工具建立了基准，同时维护了患者的隐私。|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|**联邦学习（FL）在面临拜占庭攻击时变得尤为脆弱，这种情况下，部分参与者通过发送恶意模型更新以损害模型的效用或阻碍模型的收敛。以往的研究提出采用鲁棒性规则来聚合参与者的更新，以抵御不同类型的拜占庭攻击；然而，攻击者也能针对已知的具体聚合规则设计更高级的拜占庭攻击算法。实际上，联邦学习系统可能包含一个黑盒服务器，使得采用的聚合规则对参与者不可访问，这自然能够防御或削弱某些拜占庭攻击。本文深入探讨了配备黑盒服务器的联邦学习系统的拜占庭健壮性。我们的研究显示，采用动态防御策略的黑盒服务器能显著提升对抗拜占庭攻击的鲁棒性。我们通过实证证据和理论分析揭示，黑盒服务器能够将拜占庭攻击的最大影响程度降低至期望影响程度，这一效果归因于黑盒服务器固有的不可访问性和随机性所提供的保护。为了促进社区内的进一步研究，相关源代码已公开，可于https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense获取。**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

