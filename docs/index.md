---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.26
> Usage instructions: [here](./docs/README.md#usage)

## agent

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-22**|**MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents**|Congchi Yin et.al.|[2408.12142](http://arxiv.org/abs/2408.12142)|**[link](https://github.com/lemonsis/mdd-5k)**|**临床诊断大多精神障碍主要依赖于精神科医生与患者的对话。构建此类诊断对话数据集对于推动AI心理健康研究领域具有巨大潜力。然而，由于严格的隐私和伦理考量，直接收集真实诊断场景中的对话近乎不可能。为解决这一难题，我们旨在利用易于获取的匿名患者病例来合成诊断对话。具体而言，我们设计了一种神经符号多智能体框架，借助大型语言模型来合成精神障碍的诊断对话。该框架以患者病例为输入，能够基于单个病例生成多种多样的对话。其基本原理涉及医生智能体与患者智能体之间的交互，并通过来自工具智能体的动态诊断树，在符号控制下实现文本生成。  通过应用所提出的框架，我们开发了最大的中文精神障碍诊断数据集MDD-5k。该数据集基于与一家先锋精神病院合作清理的1000份真实患者病例构建，包含5000条高质量的长对话记录，每条对话均附有诊断结果作为标签。据我们所知，这也是首个带有标签的中文精神障碍诊断数据集。人类评估表明，提出的MDD-5k数据集成功模拟了精神障碍的人类诊断过程。数据集和代码将在https://github.com/lemonsis/MDD-5k公开访问。**|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|**大型语言模型（LLMs）在视觉与语言导航（VLN）任务中展现出潜力，但当前应用面临挑战。尽管LLMs在一般对话场景中表现出色，它们在专门的导航任务上表现挣扎，相比专门的VLN模型，其性能次之。我们引入了FLAME（FLAMingo架构的多模态实体代理），一种针对城市VLN任务设计的新型多模态LLM基代理及架构，能高效处理多重观察结果。我们的方法采用了一种三阶段微调技术以有效适应导航任务，包括单感知微调用于街景描述、多感知微调用于轨迹概括，以及在VLN数据集上的端到端训练。增强的数据集通过自动化方式合成。实验结果表明，FLAME相较于现有方法的优越性，在Touchdown数据集上的任务完成率提高了7.3%，超越了最先进方法。此工作彰显了多模态大型语言模型（MLLMs）在复杂导航任务中的潜力，标志着向实用化MLLMs在具身AI应用前进的重要一步。项目页面：https://flame-sjtu.github.io**|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|由于新兴能力，大型语言模型（LLMs）已被用作基于语言的智能体，以执行各种任务并以越来越高的自主程度做出决策。这些自治智能体能够理解高级指令，与环境互动，并使用可供它们选择的工具执行复杂任务。随着智能体能力的扩展，确保其安全性和可信度变得愈发重要。本研究中，我们引入了雅典娜框架，该框架利用了言语对比学习的概念，其中过去安全和不安全的轨迹作为上下文（对比）示例，旨在引导智能体在完成给定任务的同时趋向安全。此外，框架还融入了一个评判机制，用于在每一步指导智能体避免危险行为。鉴于目前缺乏关于基于LLM智能体安全推理能力的现有基准，我们汇编了一套包含8个类别、180个场景的80个工具包集，用以提供安全评估基准。我们的实验评估，涵盖了封闭源码与开源LLMs，表明言语对比学习及交互层面的评判显著提高了安全率。|
|**2024-08-19**|**IDEA: Enhancing the rule learning ability of language agent through Induction, DEuction, and Abduction**|Kaiyu He et.al.|[2408.10455](http://arxiv.org/abs/2408.10455)|null|尽管大型语言模型（LLMs）在演绎和归纳推理方面的评估已经相当全面，但它们在互动环境中进行溯因推理与整体规则学习的能力探索尚不充分。本研究引入了RULEARN，一个专为评估LLMs在交互式场景下的规则学习能力而设计的新基准。在RULEARN中，代理通过与环境互动收集观察并识别模式，利用这些洞察解决问题。为了进一步提升LLM代理在该基准中的规则学习能力，我们提出了IDEA代理，它融合了归纳、演绎及溯因过程。IDEA代理通过采用结构化的推理序列来优化这一方法：通过溯因生成假设，借助演绎进行测试，并根据归纳反馈进行修正。这一序列使代理能够动态建立并应用规则，模拟人类类似的推理过程。我们对五种代表性LLMs的评估显示，虽然这些模型能生成貌似合理的初始假设，但它们在环境中的策略性互动、有效整合反馈以及假设的适应性细化方面往往面临挑战。IDEA代理在RULEARN基准上展示了显著的性能提升，为开发在现实世界场景中能够进行类似人类规则学习的代理提供了宝贵见解。我们将公开代码和数据。|
|**2024-08-20**|**MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems**|Qian Wang et.al.|[2408.09955](http://arxiv.org/abs/2408.09955)|null|随着大型语言模型（LLMs）的兴起，LLM驱动的多智能体系统（LLM-MA系统）被提出以应对现实任务。然而，这些系统的智能体大多遵循预先定义的标准操作程序（SOPs），在整个交互过程中保持不变，缺乏自主性和可扩展性。此外，当前解决方案往往忽视了有效智能体协作的必要性。为了解决上述局限性，我们提出了MegaAgent框架，一个专为大规模LLM智能体系统中的自主协作设计的实用框架。MegaAgent利用智能体的自主性，根据任务需求动态生成智能体，融入了自动任务分配、系统性规划与监控智能体活动以及管理并发操作等功能。此外，MegaAgent采用层次化结构并运用系统级并行性来增强性能和促进通信。我们通过五子棋游戏开发演示了MegaAgent的有效性，表明它优于流行的LLM-MA系统；并通过国家政策模拟展示了其高度自主性及快速扩展至590个智能体的能力，同时确保它们之间的有效协作。我们的结果显示，MegaAgent是首个无预定义SOP、高效且可大规模扩展的自主大型LLM-MA系统，为该领域的进一步研究铺平了道路。我们的代码位于https://anonymous.4open.science/r/MegaAgent-81F3。|
|**2024-08-19**|**GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making**|Arsham Gholamzadeh Khoee et.al.|[2408.09785](http://arxiv.org/abs/2408.09785)|null|在汽车行业中，传统的软件部署决策方法通常依赖于手动分析软件测试的表格数据。这些方法因其劳动密集型特性，常常导致成本增加和软件发布周期的延迟。大型语言模型（LLMs）为解决这些挑战提供了有前景的方案。然而，它们的应用通常需要多轮人为驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠且高效结果的工业终端用户而言。在本文中，我们提出了GoNoGo，一个旨在简化汽车软件部署流程同时满足功能需求和实际工业约束的LLM代理系统。与以往系统不同，GoNoGo特别针对领域特定和风险敏感系统进行了定制。我们利用来自工业实践的零样本和少量样本，对GoNoGo在不同任务难度下的性能进行了评估。结果显示，GoNoGo在使用3个样本的情况下，对于难度达到第2级的任务实现了100%的成功率，并且即使面对更复杂的任务，也能保持高水准的表现。我们发现，GoNoGo能有效自动化较简单任务的决策过程，大幅减少了人工介入的需求。总之，GoNoGo代表了一种高效且用户友好的基于LLM的解决方案，目前已被我们的工业合作伙伴公司采用，以辅助进行软件发布决策，支持对风险敏感的车辆系统发布过程中的更加明智且及时的决策。|
|**2024-08-18**|**HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model**|Mengkang Hu et.al.|[2408.09559](http://arxiv.org/abs/2408.09559)|**[link](https://github.com/hiagent2024/hiagent)**|**基于大型语言模型（LLM）的智能体在众多领域展现出巨大潜力，它们作为交互系统运作，处理环境观察以生成针对目标任务的可执行动作。这些智能体的有效性在很大程度上取决于其记忆机制，该机制将历史经验记录为动作-观察对的序列。我们将记忆分为两类：跨试次记忆，横跨多次尝试累积；以及试次内记忆（工作记忆），在单次尝试中累积。尽管大量研究已通过优化跨试次记忆来提升性能，但通过改善工作记忆的利用以增强智能体表现的研究仍相对未开发。现有方法常常涉及将整个历史动作-观察对直接输入到LLMs中，这在长 horizon 任务中导致了冗余。受人类问题解决策略启发，本论文介绍了一种名为HiAgent的框架，它利用子目标作为记忆块来对LLM智能体的工作记忆进行层次化管理。具体而言，HiAgent促使LLMs在生成可执行动作前先制定子目标，并使LLMs能够主动决定用总结的观察来替换先前的子目标，仅保留与当前子目标相关的动作-观察对。跨五个长 horizon 任务的实验结果表明，HiAgent成功率提高了两倍，并将所需的平均步数减少了3.8步。此外，我们的分析显示，HiAgent在不同步骤上持续改进性能，强调了其稳定性和泛化能力。项目页面：https://github.com/HiAgent2024/HiAgent 。**|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应的传感器数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力框架从用户行为、视线聚焦和XR环境中的情境记忆中隐式提取上下文。这最大限度地减少了对人为设计的明确提示的依赖，促进了根植于实际情境且直观的交互，从而为聊天机器人提供用户洞察。用户研究证明了我们方法的可行性及其在简化XR中用户与聊天机器人交互方面的变革性潜力，同时为未来XR实体化LLM代理的设计提供了洞见。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担不仅复杂化了设计流程，还阻碍了BIM及基于模型设计在建筑、工程和施工（AEC）行业的普及。为更直观地表达设计意图，我们提出了Text2BIM，一个基于大型语言模型（LLM）的多智能体框架，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作与推理，将用户文本输入转化为可执行代码，进而调用BIM创作工具的API，直接在软件中生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，我们还在智能体工作流程中融入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体识别并解决生成模型中的问题，从而迭代提升模型质量。通过大量实验，我们对比分析了三种不同LLM在所提框架下的性能。评估结果表明，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入的抽象概念保持一致。最后，我们开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主性、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练不足以赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往尝试通过在专家演示的监督微调来弥合这一差距，往往会因累积错误和有限的探索数据而受限，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式蒙特卡洛树搜索（MCTS）与自我批评机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和强化微调基线，并在具备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升到单日数据收集后的81.7%成功率（相对增长340%），进一步利用在线搜索可达到95.4%。我们认为，这代表了自主代理能力的重大飞跃，为现实世界环境中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|**[link](https://github.com/hiyouga/llama-factory)**|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## llm

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-23**|**DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation**|Qiming Zhu et.al.|[2408.13204](http://arxiv.org/abs/2408.13204)|null|代码基准测试，如HumanEval，被广泛用于评估大型语言模型（LLMs）的能力，揭示了它们在编程任务上的优势和劣势。然而，当前的基准测试主要集中在常见的编码任务上（例如，冒泡排序、最大公约数），而对于领域特定的编码任务（如计算、系统、加密）则鲜有涉及。为了填补这一空白，我们提出了一个多领域的代码基准测试DOMAINEVAL，旨在全面评估LLMs的编码能力。我们的流程完全自动化，能够从代码仓库到待研究主题的格式化构建实现一键式操作。通过使用DOMAINEVAL对12个代表性的LLMs进行评估，我们发现了一些有趣的现象。注意到LLMs普遍擅长处理计算任务，但在加密和系统编码任务上表现欠佳。某些LLMs在这些领域上的性能差距甚至可达68.94%（80.94%对比12.0%）。此外，我们观察到生成更多样本可以提升LLMs的整体表现，但同时可能加剧领域偏见。本研究的贡献包括：一个涵盖六个流行领域的代码生成基准数据集DOMAINEVAL，一个用于构建代码基准的全自动化管道，以及根据LLMs在DOMAINEVAL上的表现，识别出其在代码生成任务中的局限性，为未来的研究改进指明了方向。基准测试的排行榜可访问https://domaineval.github.io/。|
|**2024-08-23**|**Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning**|Hourui Deng et.al.|[2408.13184](http://arxiv.org/abs/2408.13184)|null|在大型语言模型（LLMs）中，空间推理是实现具身智能的基础。然而，即使在简单的迷宫环境中，LLMs在长期路径规划方面仍面临挑战，这主要受到空间幻觉和由长期推理引起的情境不一致性幻觉的影响。为了解决这一挑战，本研究提出了一种创新模型——空间到关系转换与课程Q学习（S2RCQL）。针对LLMs的空间幻觉问题，我们提出了空间到关系的转化方法，该方法将空间提示转化为实体关系及代表实体关系链的路径，充分利用了LLMs在序列思维方面的潜力。基于此，我们设计了一种基于Q学习的路径规划算法以缓解情境不一致性幻觉，从而增强LLMs的推理能力。通过使用状态-动作的Q值作为提示的辅助信息，我们纠正了LLMs的幻觉，引导其学习最优路径。最后，我们提出了一种基于LLMs的反向课程学习技术，进一步减轻情境不一致性幻觉。通过降低任务难度并利用积累的成功经验，LLMs能迅速掌握并应用于更复杂的任务中。我们在百度自研的大型语言模型ERNIE-Bot 4.0上进行了全面的实验。结果显示，我们的S2RCQL相比于先进的提示工程方法，在成功率和最优解率上分别实现了23%至40%的提升。|
|**2024-08-23**|**IntelliCare: Improving Healthcare Analysis with Variance-Controlled Patient-Level Knowledge from Large Language Models**|Zhihao Yu et.al.|[2408.13073](http://arxiv.org/abs/2408.13073)|null|在电子健康记录（EHR）数据分析领域，尽管开创性的深度学习方法已取得重大进展，但它们往往难以仅凭有限数据全面捕捉多样化的医疗编码语义。将大型语言模型（LLMs）的外部知识融入其中，为提升医疗保健预测提供了有前景的途径。然而，LLM分析可能因模糊性问题和一致性问题而表现出显著的变异性，阻碍了它们的有效利用。为了解决这些挑战，我们提出了IntelliCare这一创新框架，它利用LLMs提供高质量的患者级外部知识，以增强现有的EHR模型。具体来说，IntelliCare通过识别患者群体并运用与任务相关的统计信息来增强LLM的理解和生成能力，有效缓解了模糊性问题。此外，它还通过混合方法细化LLM衍生的知识，生成多份分析，并利用EHR模型及困惑度指标进行校准。在两个大规模EHR数据集上的三项临床预测任务的实验评估显示，IntelliCare为现有方法带来了显著的性能提升，彰显了其在推进个性化医疗预测和决策支持系统方面的潜力。|
|**2024-08-23**|**Guiding IoT-Based Healthcare Alert Systems with Large Language Models**|Yulan Gao et.al.|[2408.13071](http://arxiv.org/abs/2408.13071)|null|Healthcare alert systems (HAS) are undergoing rapid evolution, propelled by advancements in artificial intelligence (AI), Internet of Things (IoT) technologies, and increasing health consciousness. Despite significant progress, a fundamental challenge remains: balancing the accuracy of personalized health alerts with stringent privacy protection in HAS environments constrained by resources. To address this issue, we introduce a uniform framework, LLM-HAS, which incorporates Large Language Models (LLM) into HAS to significantly boost the accuracy, ensure user privacy, and enhance personalized health service, while also improving the subjective quality of experience (QoE) for users. Our innovative framework leverages a Mixture of Experts (MoE) approach, augmented with LLM, to analyze users' personalized preferences and potential health risks from additional textual job descriptions. This analysis guides the selection of specialized Deep Reinforcement Learning (DDPG) experts, tasked with making precise health alerts. Moreover, LLM-HAS can process Conversational User Feedback, which not only allows fine-tuning of DDPG but also deepen user engagement, thereby enhancing both the accuracy and personalization of health management strategies. Simulation results validate the effectiveness of the LLM-HAS framework, highlighting its potential as a groundbreaking approach for employing generative AI (GAI) to provide highly accurate and reliable alerts.|
|**2024-08-23**|**In-Context Learning with Reinforcement Learning for Incomplete Utterance Rewriting**|Haowei Du et.al.|[2408.13028](http://arxiv.org/abs/2408.13028)|null|在大规模语言模型（LLMs）领域，基于上下文的学习（ICL）日益受到关注，其中LLMs仅根据附有少量示例的指令做出预测。现有的ICL示例选择方法采用稀疏或密集检索器，并已展现出有效性能。然而，这些方法并未利用LLM的直接反馈来训练检索器，所选示例未必能提升LLM的类比能力。针对这一挑战，我们提出了一种用于示例选择的基于策略的强化学习框架（RLS），该框架包含一个语言模型（LM）选择器和一个LLM生成器。LM选择器将候选示例编码为密集表示，并挑选出排名前k的示例加入到演示中供LLM使用。LLM的输出被用来计算奖励并据此更新LM选择器的策略梯度。我们在不同数据集上进行了实验，显著超越了现有的示例选择方法。此外，我们的方法在少量样本设置下相较于监督微调（SFT）模型显示出优势。进一步的实验表明，示例的丰富性与与测试案例的相似性之间的平衡对LLM的ICL性能至关重要。|
|**2024-08-23**|**Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates**|Hui Wei et.al.|[2408.13006](http://arxiv.org/abs/2408.13006)|null|在对大型语言模型（LLMs）进行对齐的策略中，如基于强化学习的奖励塑形（RLHF）和直接偏好优化（DPO），正在积极研究以实现与人类偏好的一致。近期，诸如GPT-4之类的商业大型语言模型被用于评估和比较不同的LLM对齐方法。这些模型充当人类评估者的替代品，凭借其快速反馈和低成本的显著优势，能够近似人类的偏好。这种方法论被称为“LLM作为评判者”（LLM-as-a-judge）。然而，对其可靠性的担忧浮现出来，主要归因于LLM评判者的偏见及决策不一致性。先前的研究努力开发了强大的评估框架来检验LLM评判者的可靠性及其与人类偏好的一致性，但所采用的评估指标往往缺乏足够的可解释性，并且未能解决LLM内部不一致性的问题。此外，现有研究在应用LLM-as-a-judge方法时，未能充分探索不同提示模板的影响，可能导致对不同对齐算法的比较不一致。本工作中，我们通过定义具有更强理论可解释性的评估指标，并分离出与LLM内部不一致性相关的可靠性指标，系统地评估了在对齐任务（例如，摘要生成）中的LLM评判者。我们构建了一个框架来评估、比较并可视化LLM评判者的可靠性和对其与人类评估者偏好的一致性，提供了有助于选择适用于对齐任务的LLM评判者的有见地的观察结果。我们的结果显示，提示模板对LLM评判者的表现有显著影响，同时测试的LLM评判者与人类评估者之间的一致性水平仅处于中等程度。|
|**2024-08-23**|**CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution**|Ruiyang Xu et.al.|[2408.13001](http://arxiv.org/abs/2408.13001)|null|代码基准测试，如HumanEval，被广泛用于评估大型语言模型（LLMs）的编码能力。然而，现有的代码基准测试存在不可忽视的编程语言偏见——超过95%的代码生成基准以Python为主导，使得LLMs在Java、C/C++等其他编程语言中的能力未知。此外，编码任务偏见也是一个关键问题。大多数基准侧重于代码生成能力，而针对代码推理（给定输入，推断输出；给定输出，推断输入）的基准测试不足，这是编程能力的一个重要方面。然而，构建多语言基准测试可能既昂贵又劳动密集型，并且从竞赛网站（如LeetCode）获取的代码在训练过程中容易受到数据污染。为了填补这一空白，我们提出了CRUXEVAL-X，一个包含19种编程语言的多语言代码推理基准。它每种语言至少包含600个主题，以及总共19000个内容一致的测试。特别是，CRUXEVAL-X的构建流程采用全自动和测试引导的方式，通过执行反馈迭代生成和修复代码。此外，为了跨越语言障碍（例如，Python/C++中的动态/静态类型系统），我们制定了不同语言对之间的转换规则以促进翻译。我们对24个代表性LLMs进行的深入评估揭示了语言对之间的相关性。例如，TypeScript和JavaScript显示出显著的正相关，而Racket与其他语言的相关性较小。更有趣的是，即使仅在Python上训练的模型也能在其他语言中最多达到34.4%的Pass@1准确率，揭示了LLMs的跨语言泛化能力。|
|**2024-08-23**|**Open Llama2 Model for the Lithuanian Language**|Artūras Nakvosas et.al.|[2408.12963](http://arxiv.org/abs/2408.12963)|null|在本文中，我们提出并描述了首个针对立陶宛语的开源大语言模型（LLMs）——Llama2，同时发布了配套的问答（Q/A）数据集及流行LLM基准测试的立陶宛语翻译。我们对开放区域LLMs进行了简要回顾，并详细介绍了所提议LLMs及其训练过程。此外，我们通过实证评估，比较了所提LLMs与其他现代开源LLMs的困惑度。进一步，对立陶宛语理解任务的基准测试表明，高质量的预训练数据集对于模型在这些基准上高效表现至关重要。所述LLMs的完整实现可在随附的开源仓库\url{https://huggingface.co/neurotechnology}中获得。|
|**2024-08-23**|**Multimodal Contrastive In-Context Learning**|Yosuke Miyanishi et.al.|[2408.12959](http://arxiv.org/abs/2408.12959)|null|大型语言模型（LLMs）使用的迅速增长凸显了无梯度的即时学习（ICL）方法的重要性。然而，解释这些模型的内部工作原理仍然是一项挑战。本文介绍了一种新颖的多模态对比即时学习框架，旨在增强我们对LLMs中ICL机制的理解。首先，我们提出了一种基于对比学习的ICL解释方法，该方法在现实世界场景中运作，将关键值表示之间的距离作为ICL差异的关键区分因素。其次，我们构建了一个分析框架来解决真实世界数据集上多模态输入格式的偏差问题。我们通过实例展示了即使在未见过的格式下，当基线性能较差时，ICL示例仍能发挥效用。最后，我们提出了一种针对ICL的在线处理方法（以文本为锚的ICL），该方法在检测仇恨性模因这一任务中展现出有效性，传统ICL在此类任务上因资源限制而面临困难。在多模态数据集上的广泛实验表明，我们的方法显著提高了在各种场景下的ICL性能，包括具有挑战性的任务和资源受限环境。此外，它也为理解LLMs中即时学习机制提供了宝贵见解。我们的发现对于开发更具可解释性、高效性和鲁棒性的多模态AI系统具有重要意义，特别是在面对挑战性任务和资源有限环境时。|
|**2024-08-23**|**E-code: Mastering Efficient Code Generation through Pretrained Models and Expert Encoder Group**|Yue Pan et.al.|[2408.12948](http://arxiv.org/abs/2408.12948)|null|随着摩尔定律的减弱，软件行业越来越重视寻找持续性能提升的替代方案。近年来，软件性能优化的重要性和研究成果不断增加，特别是在大型语言模型（LLMs）推动下取得了进展。然而，传统的性能缺陷修正策略在竞争激烈的代码效率优化层面显示出重大局限性，关于这一主题的研究出乎意料地稀少。目标：本研究旨在填补该领域的研究空白，为遇到的各种挑战提供实际解决方案。具体而言，我们克服了传统性能优化策略的限制，并为竞争性的代码效率优化领域开发了一种定制的语言模型（LM）。方法：我们引入了E-code，一种先进的程序合成LM。受近期专家LM成功的启发，我们设计了一种创新结构——专家编码器组。该结构利用多个专家编码器来提取针对不同输入类型量身定做的特征。我们在一个竞争性数据集上评估了E-code与其他领先模型的性能，并进行了深入的消融实验。结果：经过系统评估，E-code在代码效率方面实现了54.98%的提升，显著优于其他先进模型。在消融实验中，我们进一步验证了专家编码器组及其他E-code内部组件的重要性。结论：研究结果表明，专家编码器组能有效处理效率优化任务中的各种输入，显著提高了模型的性能。|
|**2024-08-22**|**Controllable Text Generation for Large Language Models: A Survey**|Xun Liang et.al.|[2408.12599](http://arxiv.org/abs/2408.12599)|**[link](https://github.com/iaar-shanghai/ctgsurvey)**|**在自然语言处理（NLP）领域，大型语言模型（LLMs）展现了高水平的文本生成质量。然而，在实际应用中，LLMs需满足日益复杂的诉求。除了要避免产生误导性或不适宜内容外，LLMs还需适应用户的特定需求，例如模仿特定写作风格或生成富含诗意的文本。这些多样的要求促进了可控文本生成（CTG）技术的发展，该技术确保模型输出遵循预定义的控制条件——如安全性、情感倾向、主题一致性及语言风格等——同时保持帮助性、流畅性和多样性的高标准。本文系统回顾了LLMs在CTG方面的最新进展，提供了该领域核心概念的全面定义，并明确了控制条件与文本质量的需求。我们将CTG任务分为两大类：内容控制与属性控制。文中讨论了主要方法，包括模型重训练、微调、强化学习、提示工程、潜在空间操纵及解码时干预。我们分析了每种方法的特点、优势与局限性，为实现生成控制提供了深刻见解。此外，我们还回顾了CTG的评估方法，总结了其跨领域的应用，并探讨了当前研究中的关键挑战，如流畅度降低及实用性问题。我们提出几点呼吁，比如未来研究应更重视现实应用场景。本文旨在为该领域的研究人员和开发者提供宝贵的指导。参考文献列表及中文版本已开源，访问地址为https://github.com/IAAR-Shanghai/CTGSurvey。**|
|**2024-08-22**|**RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**|Xiaohan Wang et.al.|[2408.12579](http://arxiv.org/abs/2408.12579)|null|大型语言模型（LLMs），如GPT-4、MedPaLM-2和Med-Gemini，在各种医学评估标准上取得了与人类专家相当的性能。然而，它们在进行类似医师的专业诊断时仍面临挑战，尤其是在高效收集患者信息和推断最终诊断方面。针对这一问题，我们提出了RuleAlign框架，旨在将LLMs与特定诊断规则对齐。我们构建了一个包含基于规则的患者与医师交流的医疗对话数据集，并设计了通过偏好学习进行的对齐学习方法。实验结果证明了所提方法的有效性。我们希望，我们的工作能够激发探索LLMs作为AI医师潜力的研究灵感。|
|**2024-08-22**|**Towards Evaluating and Building Versatile Large Language Models for Medicine**|Chaoyi Wu et.al.|[2408.12547](http://arxiv.org/abs/2408.12547)|**[link](https://github.com/magic-ai4med/meds-ins)**|**在本研究中，我们提出了MedS-Bench，一个综合性的基准测试工具，旨在评估大型语言模型（LLMs）在临床场景中的性能。与现有侧重于选择题回答的基准不同，MedS-Bench涵盖了11项高级临床任务，包括临床报告总结、治疗建议、诊断、命名实体识别和医学概念解释等。我们采用了少样本提示方法，评估了六种顶尖的LLMs，例如MEDITRON、Mistral、InternLM 2、Llama 3、GPT-4以及Claude-3.5，发现即使是最先进的模型也难以胜任这些复杂任务。为了解决这些局限性，我们开发了MedS-Ins，一个大规模的医学指令调优数据集。MedS-Ins包含了58个面向医学的语言语料库，总计1350万个样本，涉及122项任务。为了展示该数据集的实用性，我们进行了一项概念验证实验，对一个轻量级、开源的医学语言模型进行了指令调优。由此产生的模型MMedIns-Llama 3在几乎所有临床任务上显著超越了现有模型。为了推动LLMs在解决临床挑战方面的进一步发展，我们已完全公开MedS-Ins数据集，并邀请研究界共同参与其扩充。此外，我们还启动了MedS-Bench的动态排行榜，计划定期更新测试集以追踪进展，促进通用LLMs向医疗领域的适应。排行榜链接：https://henrychur.github.io/MedS-Bench/。GitHub仓库：https://github.com/MAGIC-AI4Med/MedS-Ins。**|
|**2024-08-22**|**MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**|Hao Wei et.al.|[2408.12496](http://arxiv.org/abs/2408.12496)|null|大型语言模型（LLMs）对包括医学和医疗在内的多个研究领域产生了重大影响。然而，作为医学教育副驾的角色，LLMs的潜力尚未得到充分探索。当前基于AI的教育辅助工具受限于单一学习方式，无法模拟真实医学培训的多学科和交互性质。为解决这些局限性，我们提出了MEDCO（医学教育副驾系统），这是一种新颖的多智能体协同系统，专门设计来模仿现实世界的医学训练环境。MEDCO整合了三个主要智能体：一个主动患者智能体、一位专家医生智能体，以及一位放射科医生智能体，从而促进了多模式和交互式学习环境。我们的框架着重于培养熟练的提问技巧、跨学科合作以及学生之间的同伴讨论。实验结果显示，经过MEDCO训练的虚拟学生不仅实现了与高级模型相当的显著性能提升，还展示出类似人类的学习行为和进步，伴随学习样本数量的增加。本工作通过引入实施交互式与合作学习方法的副驾，为医学教育做出了贡献，并为集成AI的培训模式的有效性提供了宝贵见解。|
|**2024-08-22**|**GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models**|Kunsheng Tang et.al.|[2408.12494](http://arxiv.org/abs/2408.12494)|**[link](https://github.com/kstanghere/gendercare-ccs24)**|**大型语言模型（LLMs）在自然语言生成方面展现了非凡的能力，但它们也被观察到会放大社会偏见，尤其是与性别相关的偏见。针对这一问题，已经提出了几个基准来评估LLMs中的性别偏见。然而，这些基准往往缺乏实际灵活性或无意中引入了偏见。为了解决这些不足之处，我们引入了GenderCARE，这是一个全面的框架，涵盖了创新性的标准、偏见评估、减缓技术以及用于量化和减轻LLMs中性别偏见的评估指标。首先，我们确立了性别平等基准的开创性标准，涵盖了包容性、多样性、可解释性、客观性、稳健性和现实性等多个维度。在这些标准的指导下，我们构建了GenderPair，一个新颖的配对基准，旨在全面评估LLMs中的性别偏见。我们的基准提供了标准化和贴近现实的评估，包括之前被忽视的性别群体，如跨性别和非二元性别个体。此外，我们还开发了有效的去偏技术，这些技术结合了反事实数据增强和专门的微调策略，能够在不损害LLMs整体性能的前提下减少性别偏见。广泛的实验表明，在各种性别偏见基准上偏见显著减少，最高减少超过90%，并且在17个不同的LLMs上的平均减少率超过35%。重要的是，这些减少在主流语言任务上的变异性很小，保持在2%以下。通过提供对性别偏见的实际评估和针对性的减缓措施，我们希望GenderCARE能代表朝向LLMs中实现公平和平等的重要一步。更多细节可参见https://github.com/kstanghere/GenderCARE-ccs24。**|
|**2024-08-22**|**Frame Order Matters: A Temporal Sequence-Aware Model for Few-Shot Action Recognition**|Bozheng Li et.al.|[2408.12475](http://arxiv.org/abs/2408.12475)|null|在本文中，我们提出了一种新颖的时序序列感知模型（Temporal Sequence-Aware Model，TSAM），用于少量样本动作识别（Few-Shot Action Recognition，FSAR）。该模型在一个预训练框架中融入了序列感知的感知器适配器，旨在整合空间信息与序列时间动态到特征嵌入中。与现有通过探索所有帧间关系来捕获时间信息的微调方法不同，我们的基于感知器的适配器沿时间轴递归地捕捉序列动态，能够感知顺序变化。为了获得每个类别的判别性表示，我们利用大型语言模型（Large Language Models，LLMs）为每个类别扩展了一个文本语料库，并通过融合上下文语义信息来丰富视觉原型。此外，我们引入了一种不平衡的最优运输策略进行特征匹配，以减轻类别无关特征的影响，从而促进更有效的决策制定。在五个FSAR数据集上的实验结果表明，我们的方法树立了新的基准，以显著优势超越了次优竞争者。|
|**2024-08-22**|**DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems**|Jiaju Chen et.al.|[2408.12470](http://arxiv.org/abs/2408.12470)|null|大型语言模型（LLMs）在推荐系统中的整合极大地提升了性能，但往往以牺牲推荐多样性为代价，这可能对用户满意度产生负面影响。为了解决这一问题，可控制的推荐方法应运而生，它允许用户指定偏好，从而获得满足其多样化需求的推荐。尽管潜力巨大，现有的可控制推荐系统通常依赖于简单的机制，如单一提示来调节多样性，这种做法未能充分捕捉到用户偏好的复杂性。针对这些局限性，我们提出了DLCRec这一创新框架，旨在实现对基于LLM推荐中的多样性的细粒度控制。与传统方法不同，DLCRec采用了一种细粒度的任务分解策略，将推荐过程分为三个连续的子任务：类型预测、类型填充和项目预测。这些子任务独立训练并根据用户定义的控制参数顺序推理，确保了对多样性的更精确控制。此外，与多样性相关的用户行为数据的稀缺性和分布不均对微调构成了重大挑战。为克服这些障碍，我们引入了两种数据增强技术，增强了模型对噪声和分布外数据的鲁棒性。这些技术使模型接触到更广泛的行为模式，提高了其在生成不同多样性水平推荐时的适应性。广泛的实证评估表明，DLCRec不仅提供了对多样性的精准控制，还在多种推荐场景下超越了当前的最先进基线。|
|**2024-08-22**|**Envisioning Class Entity Reasoning by Large Language Models for Few-shot Learning**|Mushui Liu et.al.|[2408.12469](http://arxiv.org/abs/2408.12469)|null|小样本学习（FSL）旨在利用有限的视觉样本来识别新概念。现有方法尝试将语义信息融入有限的视觉数据中以实现类别理解。然而，这些方法常常通过抽象的类别名称来丰富类级别的特征表示，未能捕捉到有效泛化所必需的细微特征。为了解决这一问题，我们提出了一种新颖的FSL框架，该框架结合了抽象的类别语义和从大型语言模型（LLMs）中提取的具体类别实体，以增强类别原型的表示。具体来说，我们的框架包括一个语义引导的视觉模式提取（SVPE）模块和一个原型校准（PC）模块，其中SVPE模块精细地提取跨多个尺度的语义感知视觉模式，而PC模块则无缝集成这些模式以优化视觉原型，提升其代表性。在四个小样本分类基准数据集及BSCD-FSL跨领域基准上的广泛实验表明，与当前最先进的方法相比，我们的方法取得了显著的进步。尤其在挑战性的一次性射击设置中，使用ResNet-12作为骨干网络，我们的方法相比第二名竞争对手平均提高了1.95%，表现令人瞩目。|
|**2024-08-22**|**Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing**|Mengqi Zhang et.al.|[2408.12456](http://arxiv.org/abs/2408.12456)|null|大型语言模型（LLMs）在内部知识准确性及信息时效性方面面临挑战，知识编辑作为一种关键方法应运而生，旨在缓解这些问题。尽管当前的知识编辑技术在单跳推理任务上展现出良好的性能，但它们在处理多跳推理时表现出局限性。借鉴认知神经科学与LLMs运作机制，我们假设残留的单跳知识在编辑后仍存于模型中，导致模型在处理多跳问题时回溯至原始答案，从而削弱了其在多跳推理任务中的表现。为了验证这一假设，我们进行了一系列实验证实了我们的设想。基于验证的假设，我们提出了一种新颖的知识编辑方法，即面向大型语言模型编辑的知识擦除机制（KELE）。具体而言，我们设计了针对残留知识的擦除函数和注入新知识的函数。通过联合优化，我们求得最优的召回向量，随后在秩一编辑框架内利用此向量更新目标模型层的参数。在GPT-J和GPT-2 XL上的广泛实验表明，KELE显著提升了编辑后LLMs的多跳推理能力。|
|**2024-08-22**|**A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation**|Weijia Zhang et.al.|[2408.12398](http://arxiv.org/abs/2408.12398)|null|大型语言模型（LLMs）在生成内容时往往会包含未得到支持或无法验证的信息，这一现象被称为“幻象”。为了解决这一问题，采用检索增强型LLM能够在其内容中融入引用，以此将内容锚定在可验证的来源上。尽管有这样的发展，手动评估引用对相应陈述的支持程度仍是一个重大挑战。以往的研究通过利用忠实度指标来自动估计引用支持度，以此应对这一挑战。然而，它们将这种引用支持度评估局限于二元分类场景，忽略了实际情境中的细粒度引用支持评估。为了探究忠实度指标在细粒度场景下的有效性，我们提出了一种比较评估框架，该框架用于评估指标在区分三类支持水平（完全支持、部分支持和无支持）时的有效性。我们的框架运用了相关性分析、分类评估和检索评估，全面地衡量了指标得分与人工判断之间的一致性。结果显示，没有单一指标能在所有评估中持续表现优异，这凸显了准确评估细粒度支持水平的复杂性。尤其我们发现，表现最佳的指标在区分部分支持与完全支持或无支持上存在困难。基于这些发现，我们为开发更有效的指标提供了实用建议。|
|**2024-08-21**|**SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs**|Yuanyang Yin et.al.|[2408.11813](http://arxiv.org/abs/2408.11813)|null|
|**2024-08-21**|**Story3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models**|Yuzhou Huang et.al.|[2408.11801](http://arxiv.org/abs/2408.11801)|null|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800](http://arxiv.org/abs/2408.11800)|null|
|**2024-08-21**|**EE-MLLM: A Data-Efficient and Compute-Efficient Multimodal Large Language Model**|Feipeng Ma et.al.|[2408.11795](http://arxiv.org/abs/2408.11795)|null|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793](http://arxiv.org/abs/2408.11793)|null|
|**2024-08-21**|**Critique-out-Loud Reward Models**|Zachary Ankner et.al.|[2408.11791](http://arxiv.org/abs/2408.11791)|**[link](https://github.com/zankner/cloud)**|
|**2024-08-21**|**Personality Alignment of Large Language Models**|Minjun Zhu et.al.|[2408.11779](http://arxiv.org/abs/2408.11779)|**[link](https://github.com/zhu-minjun/palign)**|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775](http://arxiv.org/abs/2408.11775)|**[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)**|
|**2024-08-21**|**Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**|Yiyi Chen et.al.|[2408.11749](http://arxiv.org/abs/2408.11749)|**[link](https://github.com/siebeniris/vec2text_exp)**|
|**2024-08-21**|**Mixed Sparsity Training: Achieving 4 $\times$ FLOP Reduction for Transformer Pretraining**|Pihe Hu et.al.|[2408.11746](http://arxiv.org/abs/2408.11746)|null|
|**2024-08-20**|**Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks**|Nathaniel Pinckney et.al.|[2408.11053](http://arxiv.org/abs/2408.11053)|**[link](https://github.com/nvlabs/verilog-eval)**|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|
|**2024-08-21**|**MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**|Jian Chen et.al.|[2408.11049](http://arxiv.org/abs/2408.11049)|null|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|
|**2024-08-20**|**While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?**|Wen Cheng et.al.|[2408.11006](http://arxiv.org/abs/2408.11006)|**[link](https://github.com/sensente/security-attacks-on-lccts)**|
|**2024-08-20**|**CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models**|Michael Reinisch et.al.|[2408.10995](http://arxiv.org/abs/2408.10995)|null|
|**2024-08-20**|**Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models**|Yuyan Chen et.al.|[2408.10947](http://arxiv.org/abs/2408.10947)|null|
|**2024-08-20**|**HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments**|Kazi Hasan Ibn Arif et.al.|[2408.10945](http://arxiv.org/abs/2408.10945)|**[link](https://github.com/hasanar1f/hired)**|
|**2024-08-20**|**SysBench: Can Large Language Models Follow System Messages?**|Yanzhao Qin et.al.|[2408.10943](http://arxiv.org/abs/2408.10943)|**[link](https://github.com/pku-baichuan-mlsystemlab/sysbench)**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-20**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Ling He et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-19**|**Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models**|Jiao Chen et.al.|[2408.09972](http://arxiv.org/abs/2408.09972)|null|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## Wireless Network

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

## Wireless Communications

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

## Wireless Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

## Communication Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-04-02**|**LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**|Zhiyuan He et.al.|[2404.01617](http://arxiv.org/abs/2404.01617)|null|我们介绍了LLM-ABR系统，这是首个利用大型语言模型（LLMs）的生成能力来自行设计适应性比特率（ABR）算法的系统，旨在满足多样化的网络特性需求。LLM-ABR在强化学习框架内运作，使LLMs能够设计出如状态和神经网络架构等关键组件。我们在包括宽带、卫星、4G及5G在内的多种网络环境下对LLM-ABR进行了评估，该系统表现出持续超越默认ABR算法的性能。|

## RAG

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-22**|**Graph Retrieval Augmented Trustworthiness Reasoning**|Ying Zhu et.al.|[2408.12333](http://arxiv.org/abs/2408.12333)|**[link](https://github.com/EvoNexusX/Graph-Retrieval-Augmented-Trustworthiness-Reasoning)**|**在信息不完全的多人游戏中，信任推理至关重要，它使代理能够识别潜在的盟友和对手，从而加强推理和决策过程。传统方法依赖于预训练模型，需要大量的领域特定数据及可观的奖励反馈，且其缺乏实时适应性限制了在动态环境中的有效性。本文引入了图检索增强推理（GRATR）框架，利用检索增强生成（RAG）技术来加强代理的信任推理能力。GRATR构建了一个动态的信任图，实时更新并加入证据信息，并检索相关信任数据以增强大型语言模型（LLMs）的推理能力。我们通过在多人游戏“狼人杀”上的实验验证了我们的方法，将GRATR与基线LLM以及集成原生RAG和重排RAG的LLM进行对比。结果显示，GRATR在胜率上超过基线方法30%以上，展现出更优越的推理性能。此外，GRATR有效缓解了LLM产生的幻觉问题，如身份遗忘和目标遗忘，并且通过使用信任图，使得推理过程更加透明和可追溯。**|
|**2024-08-22**|**LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction**|Aishik Nagar et.al.|[2408.12249](http://arxiv.org/abs/2408.12249)|null|大型语言模型（LLMs）在医疗领域的应用日益增多，它们在问答和文档摘要等任务上已达到领域专家的性能水平。然而，尽管在这些任务上取得了成功，LLMs在传统生物医学领域所追求的任务，如结构化信息抽取方面的表现仍不明确。为了弥补这一差距，本文系统地评估了LLMs在医疗分类和命名实体识别（NER）任务中的性能。我们的目标是剖析不同因素对性能的贡献，特别是LLMs的任务知识和推理能力、其（参数化的）领域知识以及外部知识附加的影响。为此，我们采用标准提示、Chain-of-Thought (CoT)和自我一致性推理方法，以及利用PubMed和Wikipedia语料库进行的检索增强生成（RAG），对多种开放的LLMs——包括BioMistral和Llama-2模型——在一系列生物医学数据集上的表现进行了评估。出乎意料的是，我们的结果表明，标准提示在两项任务中均持续优于更复杂的技巧，这揭示了当前在生物医学领域应用CoT、自我一致性和RAG存在的局限性。研究发现表明，为知识密集型或推理密集型任务开发的先进提示方法，如CoT或RAG，在需要精确结构化输出的生物医学任务中不易移植。这强调了在真实世界生物医学应用中，为了提升LLMs的性能，更有效地整合外部知识和推理机制的必要性。|
|**2024-08-22**|**Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs**|Ronit Singhal et.al.|[2408.12060](http://arxiv.org/abs/2408.12060)|null|在社交媒体上错误信息的广泛传播背景下，对网络言论进行事实核查变得至关重要。手动验证每条言论极为困难，突显出自动化事实核查系统的需求。本文介绍了一个旨在解决该问题的系统。我们利用Averitec数据集来评估声明的真实性。除了真实性预测外，我们的系统还提供支持证据，这些证据从数据集中提取而来。我们开发了一个检索与生成（RAG）流程，用于从知识库中抽取与待核查声明相关的证据句子，随后将这些证据与声明一起输入大型语言模型（LLM）进行分类。同时，我们也评估了几种LLM的少量样本在上下文学习（ICL）中的能力。我们的系统实现了0.33的'Averitec'评分，相较于基线有22%的绝对提升。所有代码将在https://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms 公开提供。|
|**2024-08-21**|**RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization**|Jinhu Qi et.al.|[2408.12003](http://arxiv.org/abs/2408.12003)|null|随着现代社会经济的发展，旅游已成为满足人们精神需求的重要方式，为旅游业带来了发展机遇。然而，现有的大型语言模型（LLMs）在个性化推荐能力方面面临挑战，并且在生成内容时有时会产生虚假现象。本研究针对西藏旅游LLMs提出了一种基于检索增强生成（RAG）技术的优化方案。通过构建旅游景点数据库并利用向量化技术处理数据，我们显著提高了检索准确性。RAG技术的应用有效解决了内容生成中的虚假问题。优化后的模型在内容生成的流畅性、准确性和相关性方面显示出显著改善。本研究表明，RAG技术在文化旅游信息标准化与数据分析方面具有潜力，为智能文化旅游服务系统的开发提供了理论和技术支持。|
|**2024-08-23**|**Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy**|Priyanka Mandikal et.al.|[2408.11903](http://arxiv.org/abs/2408.11903)|**[link](https://github.com/priyankamandikal/vedantany-10m)**|**大型语言模型（LLMs）已经彻底改变了信息检索和知识传播的格局。然而，在特定领域应用时，这些模型常因事实错误和虚构现象，特别是在长尾知识分布中的问题而受阻。我们探索了在专业领域长篇问答（LFQA）中使用检索增强生成（RAG）模型的潜力。我们提出了VedantaNY-10M数据集，该数据集从关于古印度哲学“Advaita Vedanta”的大量公开论述中精心汇编而成。我们开发并基准测试了一个RAG模型，与标准非RAG LLM相比，在转录、检索和生成性能上进行评估。计算语言学家和领域专家的人工评估显示，RAG模型在产生事实准确且全面回答的同时，减少了虚构现象，显著优于标准模型。此外，强调独特低频词汇的关键词混合检索器进一步提升了结果。我们的研究为现代大型语言模型与古老知识体系的有效整合提供了洞见。项目网页含数据集和代码：https://sites.google.com/view/vedantany-10m**|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800](http://arxiv.org/abs/2408.11800)|null|在自然语言处理（NLP）与文本生成领域日新月异的发展背景下，检索增强生成（RAG）作为一种新兴技术，展现出巨大潜力，通过利用用户指定数据库中检索到的信息来提升生成文本的质量与可靠性。为了评估和比较不同RAG配置在检索器与生成器方面的性能，基准测试至关重要，它能为理解这些配置的有效性、可扩展性及针对特定领域和应用的适用性提供深入见解。本文提出了一套综合框架，用于生成领域相关的RAG基准测试。该框架依托于自动问答生成机制，并采用人类（领域专家）与大型语言模型（LLM）协同工作模式。作为案例研究，我们通过引入PermitQA，一个针对风力选址及许可领域的首创性基准测试，演示了该框架的应用。PermitQA涵盖了与风能项目环境影响相关的多份科学文献/报告。我们的框架系统性地利用多样化的指标与不同复杂度的问题类型，对RAG性能进行了全面评估。同时，我们还在该基准上展示了多种模型的表现情况。|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793](http://arxiv.org/abs/2408.11793)|null|分子性质预测与通过深度学习模型进行的生成设计一直是研究的重点，因为它有望加速新型、高性能材料的开发。近期，这些工作流程因大型语言模型（LLMs）的出现以及由LLM驱动的代理系统的发展而得到了显著增强，这些系统能够利用预训练模型在更复杂的研发任务中进行预测。虽然有效，但针对材料设计任务的信息检索方面，代理系统仍有很大的改进空间。此外，利用预测性深度学习模型的潜在表示以促进跨模态检索增强生成，并在代理系统中实现特定任务的材料设计，这一替代用途尚未得到探索。本文展示大型预训练化学基础模型可作为支持小分子、复杂聚合物材料及反应的语义化学信息检索的基础。同时，我们展示了化学基础模型与图像模型（如OpenCLIP）的结合使用，促进了跨多表征数据领域的前所未有的查询与信息检索能力。最后，我们演示了如何在多代理系统中整合这些系统，以支持基于结构和拓扑的自然语言查询及复杂研究任务中的信息检索。|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775](http://arxiv.org/abs/2408.11775)|**[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)**|**最近的研究表明，大型语言模型（LLMs）在电信领域的技术标准处理上存在困难。我们提出了一种基于Phi-2小型语言模型（SLM）的微调检索增强生成（RAG）系统，用作通信网络的智囊。所开发的系统采用前瞻性的语义分块方法，根据嵌入相似度自适应地确定解析断点，有效处理多样化的文档格式。针对技术标准中多类相似上下文的挑战，我们采用重新排序算法来优先考虑最相关的检索块。考虑到Phi-2小模型有限的上下文窗口限制，我们实施了一项名为SelfExtend的最新技术，在推理过程中扩展上下文窗口，这不仅提升了性能，还能适应从普通用户查询到专业技术人员设计需求的更广泛范围。在微调阶段，我们利用低秩适配（LoRA）技术提高训练期间的计算效率，并允许在小数据集上进行有效微调。全面的实验表明，与电信领域现有的问答方法相比，我们的方法取得了显著的进步，其性能甚至超过了规模大880倍的GPT-4等大型语言模型。此项工作为利用SLM处理通信网络提供了一种新颖的方法，实现了效率与性能的平衡，可作为迈向网络代理语言模型基础的重要一步。**|
|**2024-08-23**|**Xinyu: An Efficient LLM-based System for Commentary Generation**|Yiquan Wu et.al.|[2408.11609](http://arxiv.org/abs/2408.11609)|null|评论为读者提供了深入理解事件的途径，通过展示多样的观点和证据。然而，撰写评论是一项耗时的任务，即便是熟练的评论员也面临挑战。大型语言模型（LLMs）简化了自然语言生成的过程，但将其直接应用于评论创作仍面临挑战，这主要是因为该任务具有独特的要求。这些要求可以分为两个层次：1）基本要求，包括构建结构良好、逻辑连贯的叙述；2）高级要求，涉及产生高质量的论点并提供有说服力的证据。在本文中，我们介绍了Xinyu，一个高效的基于LLM的系统，旨在辅助创建中文评论。为了满足基本要求，我们将生成过程分解为顺序步骤，为每个步骤提出针对性策略并通过监督式微调（SFT）进行优化。针对高级要求，我们提出了一个论点排序模型以提升论点质量，并建立了包含最新事件和经典文献的综合证据数据库，利用检索增强生成（RAG）技术强化证据的支撑力度。为了更公正地评估生成的评论，我们根据两层次要求引入了一个全面的评价指标，该指标从五个不同角度审视评论生成。实验结果证实了我们提出的系统有效性。同时，在现实场景中观察到评论员的工作效率显著提高，平均撰写评论的时间从4小时缩短至20分钟。重要的是，这种效率的提升并未牺牲评论的质量。|
|**2024-08-23**|**A Quick, trustworthy spectral detection Q&A system based on the SDAAP Dataset and large language model**|Jiheng Liang et.al.|[2408.11557](http://arxiv.org/abs/2408.11557)|null|大型语言模型（LLM）在广泛的自然语言处理（NLP）任务中展示了显著的成功，特别是在通用领域。LLM的出现为包括自然科学在内的多个领域引入了创新方法。研究者旨在利用LLM实施自动化、并发的过程，以替代传统的手动、重复且劳动密集型工作。在光谱分析与检测领域，研究者迫切需要自主获取关于不同研究对象的相关知识，这包括实验与分析中采用的光谱技术及化学计量学方法。然而，尽管光谱检测被公认为一种有效的分析手段，其基础知识的检索过程仍然既耗时又重复。  针对这一挑战，我们首先推出了光谱检测与分析论文基础（SDAAP）数据集，这是首个面向光谱分析与检测领域的开源文本知识数据集，包含了标注的文献资料及相应的知识指导数据。随后，我们设计了一个基于SDAAP数据集的自动问答框架，该框架能通过提取输入中的实体作为检索参数，来检索相关知识并生成高质量的回答。值得注意的是，在此框架中，LLM仅作为一种工具提供泛化能力，而RAG技术则用于精确捕捉知识来源。这一方法不仅提高了生成回答的质量，还确保了知识的可追溯性。实验结果显示，与基线相比，我们的框架生成了具有更高专业可信度的回答。|
|**2024-08-21**|**RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**|Xuanwang Zhang et.al.|[2408.11381](http://arxiv.org/abs/2408.11381)|**[link](https://github.com/fate-ubw/raglab)**|
|**2024-08-20**|**Reading with Intent**|Benjamin Reichman et.al.|[2408.11189](http://arxiv.org/abs/2408.11189)|null|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|
|**2024-08-19**|**Enhanced document retrieval with topic embeddings**|Kavsar Huseynova et.al.|[2408.10435](http://arxiv.org/abs/2408.10435)|null|
|**2024-08-19**|**LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain**|Nicholas Pipitone et.al.|[2408.10343](http://arxiv.org/abs/2408.10343)|**[link](https://github.com/zeroentropy-cc/legalbenchrag)**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-20**|**Carbon Footprint Accounting Driven by Large Language Models and Retrieval-augmented Generation**|Haijin Wang et.al.|[2408.09713](http://arxiv.org/abs/2408.09713)|null|
|**2024-08-17**|**Developing a Llama-Based Chatbot for CI/CD Question Answering: A Case Study at Ericsson**|Daksh Chaudhary et.al.|[2408.09277](http://arxiv.org/abs/2408.09277)|null|
|**2024-08-17**|**TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems**|Xinke Jiang et.al.|[2408.09199](http://arxiv.org/abs/2408.09199)|null|
|**2024-08-16**|**A Primer on Generative AI for Telecom: From Theory to Practice**|Xingqin Lin et.al.|[2408.09031](http://arxiv.org/abs/2408.09031)|null|
|**2024-08-16**|**Meta Knowledge for Retrieval Augmented Large Language Models**|Laurent Mombaerts et.al.|[2408.09017](http://arxiv.org/abs/2408.09017)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-16**|**Extracting polygonal footprints in off-nadir images with Segment Anything Model**|Kai Li et.al.|[2408.08645](http://arxiv.org/abs/2408.08645)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535](http://arxiv.org/abs/2408.08535)|null|
|**2024-08-16**|**MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering**|Zhengyuan Zhu et.al.|[2408.08521](http://arxiv.org/abs/2408.08521)|null|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444](http://arxiv.org/abs/2408.08444)|**[link](https://github.com/jmnian/weak_label_for_rag)**|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422](http://arxiv.org/abs/2408.08422)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

## text2sql

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|**[link](https://github.com/hkustdial/nl2sql_handbook)**|**翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对由LLMs驱动的NL2SQL技术的全面回顾，从以下四个方面覆盖其整个生命周期：（1）模型：处理NL的歧义和规格不足的NL2SQL翻译技术，以及恰当映射NL与数据库模式和实例；（2）数据：从训练数据的收集，到因训练数据稀缺而进行的数据合成，再到NL2SQL基准测试；（3）评估：使用不同指标和粒度从多个角度评估NL2SQL方法；及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的演进。此外，我们为开发NL2SQL解决方案提供了一条经验法则。最后，我们讨论了LLMs时代NL2SQL的研究挑战和开放问题。**|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但实现数据科学管道的全自动化——包括数据查询、分析、可视化和报告——仍是一个复杂挑战。本研究介绍了一种名为SageCopilot的高级行业级系统，该系统通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs）来自动化数据科学管道。具体而言，SageCopilot采用了一个两阶段设计：在线阶段利用情境学习（ICL）精炼用户输入为可执行脚本并运行这些脚本以生成结果报告与可视化；离线阶段则准备ICL在线阶段所需演示。该系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格的测试和与基于提示的解决方案的对比分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面能实现端到端的卓越性能，所有测试均基于真实世界数据集。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证明能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作常采用现成的编码器来动态检索示例，但外部检索器与LLMs之间的表征能力存在固有差异。此外，优化示例选择并非易事，因为缺少直接方法在不进行成对推断的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们设计了一种代理评分，根据输出查询间的相似性来估算示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为了解决这一问题，我们提出了一种多角度的NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情境下，如不同的数据领域和SQL特性，对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下鉴别出了一种有效的NL2SQL方法，即SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，表现出竞争优势。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术让不熟悉数据库的非专业用户也能利用SQL进行数据分析。其中，将自然语言转化为商业智能（NL2BI）是NL2SQL在实际生产系统中一个广泛的应用场景。与NL2SQL相比，NL2BI带来了更多挑战。本文提出了ChatBI这一综合且高效的解决方案，旨在应对NL2BI任务。首先，我们分析了交互模式这一关键模块，它是NL2SQL与NL2BI在应用中的主要区别之处，并设计了一个更小巧、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而难以进行。BI场景中较高比例的列含糊性也加大了模式链接的难度。ChatBI结合了数据库领域现有的视图技术，首先将模式链接问题分解为单视图选择问题，随后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列作为所需列输入到LLM中进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，使得ChatBI能更准确地生成包含复杂语义和比较关系的SQL。    我们在百度的数据平台上部署了ChatBI，并将其整合进多条产品线中，进行了大规模生产任务的评估。所获得的结果彰显了其在实用性、通用性和效率上的优越性。同时，在我们的实际BI场景数据表和查询下，与当前主流的NL2SQL技术相比，ChatBI也取得了最佳性能。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进翻译，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而无法生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含来自不同数据库的已知NL2SQL转换。LLMs能够从输入的示例中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（用于逻辑增强的预训练模型检索提示），该方法通过检索包含所需逻辑运算符组合的示例以提高NL2SQL任务的准确性，从而指导LLMs生成更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的完全集合匹配准确率和87.8%的执行匹配准确率，树立了新的状态-of-the-art性能标准。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确度，展现出其稳健性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在上下文学习模型中选择示例至关重要。然而，仅基于查询的自然语言表达来评估结构相似性，而不考虑SQL查询，是一个重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为了实现这一目标，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。我们的全面评估表明，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到了证明。尤其值得注意的是，与OpenAI和Cohere的强竞争力嵌入模型相比，我们的模型表现更优。此外，与这些竞争模型相比，我们提出的编码器在1-shot上下文学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提高了1-2%，CodeLlama-7B提高了4-8%，CodeLlama-13B提高了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进展集中在利用大语言模型（LLM）的上下文学习能力上，取得了显著成果。然而，这些方法在处理冗长的数据库信息和复杂用户意图时面临挑战。本文提出了一种两阶段框架，旨在提升当前基于LLM的自然语言转SQL系统的性能。首先，我们引入一种新颖的提示表示方式，称为参考增强表示，它融入了模式信息及从表格中随机抽取的单元格值，以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM产生一个初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，利用已链接的模式，我们简化提示中的模式信息，并指示LLM输出最终SQL。最后，作为后处理优化模块，我们建议采用跨LM的一致性而非单一LM内部的自一致性。我们的方法在Spider基准测试上达到了新的最佳水平，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域执行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们使用ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，该方法提取与查询NL相关的模式作为输入上下文，用以指导LLMs生成精确的GQL。我们在源自金融领域和医疗领域的两个构建好的数据集——FinGQL和MediGQL上评估了我们的方法。实验结果表明，相较于一系列基线方法，我们的方法显著提升了性能，分别在精确匹配（EM）上提高了5.90和6.36的绝对分数，在 existence（EX）上提高了6.00和7.09的绝对分数。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资产。访问控制跨越两个领域：策略（组织级原则，定义谁应拥有访问权限）和流程（数据库级原语，实际实施策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式——面向数据库的意图型访问控制（Intent-Based Access Control for Databases，简称IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix，NLACM）得以更精确地表达。数据库访问控制原语会根据这些NLACMs自动生成。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（我们称之为LLM4AC），以及初步的基准测试，用以评估此类系统的准确性和覆盖范围。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC远远超越了其他基线，在我们的初始Dr. Spider基准测试中达到了高准确率和F1分数。在所有系统上，我们发现对于扩大的基准测试，包括需要外部知识的最先进NL2SQL数据和来自Amazon Access数据集的真实世界角色层次结构，整体表现出了高性能。|

## AIOps

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|

## PPC

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-23**|**Social Welfare Maximization for Federated Learning with Network Effects**|Xiang Li et.al.|[2408.13223](http://arxiv.org/abs/2408.13223)|null|合理的机制设计能帮助联邦学习（FL）通过协调自利客户端在学习过程中的行为，以实现良好的社会福利。然而，现有机制忽略了客户端参与的网络效应，导致激励不充分和社会福利次优。本文旨在填补这一空白，通过探究联邦学习中激励机制设计的网络效应。我们建立了一个理论模型来分析FL模型性能，并量化网络效应对异质性客户端参与的影响。分析结果显示，FL中的网络效应具有非单调性。为了利用这些效应，我们提出一个模型交易与共享（MTS）框架，使客户端能够通过参与或购买来获取FL模型。针对异质性客户端的战略行为，我们进一步设计了一种社会效率模型交易与共享（SEMTS）机制。该机制仅通过客户支付就能实现社会福利最大化，无需额外的激励成本。在联邦学习硬件原型上的实验结果表明，与现有机制相比，社会福利提高了高达148.86%。|
|**2024-08-23**|**Improving the Classification Effect of Clinical Images of Diseases for Multi-Source Privacy Protection**|Tian Bowen et.al.|[2408.13038](http://arxiv.org/abs/2408.13038)|null|在医疗领域，隐私数据保护对数据共享构成了挑战，限制了跨医院整合数据以训练高精度辅助诊断模型的能力。传统的集中式训练方法因违反隐私保护原则而难以应用。联邦学习作为一种分布式机器学习框架，有助于解决这一问题，但它要求多家医院同时参与训练，这在实践中难以实现。针对这些挑战，我们提出了一种基于数据向量的医学隐私数据训练框架。该框架允许每家医院在其私人数据上对预训练模型进行微调，计算数据向量（代表解决方案空间中模型参数优化方向），并将这些向量相加以生成综合权重，从而集成来自多家医院的模型信息。这一方法在不交换私人数据或要求同步训练的情况下提升了模型性能。实验结果表明，该方法有效利用了分散的私人数据资源，同时保护了患者隐私。采用此方法训练的辅助诊断模型显著优于单一医院独立训练的模型，为解决医疗数据隐私保护与模型训练之间的矛盾提供了新视角，推动了医疗智能化的发展。|
|**2024-08-23**|**A Web-Based Solution for Federated Learning with LLM-Based Automation**|Chamith Mawela et.al.|[2408.13010](http://arxiv.org/abs/2408.13010)|null|联邦学习（FL）作为一种在分布式设备间开展协作式机器学习的有前景方法，其应用受到构建可靠通信架构的复杂性和机器学习与网络编程专业知识需求的限制。本文提出了一种综合性解决方案，旨在简化FL任务的协调过程，并融入了基于意图的自动化技术。我们开发了一个用户友好的网络应用程序，支持联邦平均（FedAvg）算法，使用户能够通过直观的界面配置参数。后端解决方案高效管理参数服务器与边缘节点间的通信。同时，我们还实现了模型压缩和调度算法以优化FL性能。此外，我们在FL中探索了基于意图的自动化，利用针对特定数据集微调的语言模型（LLM），使得用户能够通过高级指令执行FL任务。观察结果显示，基于LLM的自动解决方案在达到与标准网页解决方案相当的测试精度的同时，能将传输字节减少高达64%，并将CPU时间减少最多46%。此外，我们利用神经架构搜索（NAS）和超参数优化（HPO）结合LLM的方法来提升性能，发现对于执行的FL任务，测试精度可提高10%-20%。|
|**2024-08-23**|**Enhancing Vehicle Environmental Awareness via Federated Learning and Automatic Labeling**|Chih-Yu Lin et.al.|[2408.12769](http://arxiv.org/abs/2408.12769)|null|车辆环境感知对于提升道路安全至关重要。通过多种传感器与车车间通信，车辆能收集大量数据。然而，要使这些数据发挥作用，必须有效地整合传感器数据。本文聚焦于图像数据与车车间通信数据的融合，具体目标是识别发送信息的车辆在图像中的位置，这一难题被称为车辆识别问题。我们采用监督学习模型来应对车辆识别挑战，但面临两大实际问题：首先，驾驶员通常不愿分享涉及隐私的图像数据；其次，驾驶员很少参与数据标注工作。为解决这些难题，本文提出了一种综合解决方案，结合监督学习模型，运用联邦学习与自动标注技术。我们通过实验验证了所提方法的可行性。|
|**2024-08-22**|**Tackling Data Heterogeneity in Federated Learning via Loss Decomposition**|Shuang Zeng et.al.|[2408.12300](http://arxiv.org/abs/2408.12300)|**[link](https://github.com/zeng-shuang/fedld)**|**联邦学习（FL）作为一种新兴的协作式且隐私保护的机器学习方法，允许大规模医疗数据保留在各个客户端本地，正日益受到关注。然而，客户端间的数据异质性问题常导致局部模型偏离，影响全局模型的最优性。为了减轻数据异质性对FL性能的影响，我们首先通过将全局损失分解为三部分：局部损失、分布偏移损失和聚合损失，来分析FL训练如何影响FL性能。值得注意的是，我们的损失分解揭示了现有的基于本地训练的FL方法主要试图减少分布偏移损失，而全局聚合为基础的FL方法则提出更佳的聚合策略以减少聚合损失。尽管如此，目前文献中对于综合考虑同时减少这三项损失的全面努力仍然有限，导致在处理数据异质性挑战时性能不尽如人意。  为填补这一空白，我们提出了一种基于全局损失分解的新FL方法，名为FedLD，旨在联合减少这三项损失。FedLD采用了一种边距控制正则化在本地训练中以减少分布偏移损失，并利用主梯度服务器聚合策略来减少聚合损失。尤其在不同数据异质性程度下，我们的策略在视网膜与胸片分类任务上相比其他FL算法展现出更优且更稳健的性能。我们的代码已开源，可访问\href{https://github.com/Zeng-Shuang/FedLD}{https://github.com/Zeng-Shuang/FedLD}。**|
|**2024-08-22**|**Weight Scope Alignment: A Frustratingly Easy Method for Model Merging**|Yichu Xu et.al.|[2408.12237](http://arxiv.org/abs/2408.12237)|null|在某些注重模型效率与鲁棒性的应用中，模型融合已成为一项基本操作。训练过程中的随机性或非独立同分布（Non-I.I.D.）数据为基于平均的模型融合带来了巨大挑战。以往的研究主要集中在元素级的正则化或神经网络权重的排列上，以增强模型融合的效果，却忽略了模型间权重范围的变化对融合效果的显著影响。本文揭示了不同训练条件下权重范围的变化，并探讨了其对模型合并的影响。幸运的是，每层参数基本上遵循高斯分布，这一发现启发了一种新颖且简单的正则化方法——权重范围对齐（Weight Scope Alignment, WSA）。该方法包含两个关键组成部分：1) 利用目标权重范围指导模型训练过程，确保后续模型融合时的权重范围匹配；2) 将两个或多个模型的权重范围融合为统一范围，以支持多阶段模型融合。我们将WSA正则化扩展到两种不同的场景中，即模式连通性和联邦学习。丰富的实验研究验证了我们方法的有效性。|
|**2024-08-22**|**Empowering Over-the-Air Personalized Federated Learning via RIS**|Wei Shi et.al.|[2408.12162](http://arxiv.org/abs/2408.12162)|null|空中计算（AirComp）结合了模拟通信与面向任务的计算，成为无线网络中通信高效联邦学习（FL）的关键使能技术。然而，单一全局共识模型的AirComp支持FL（AirFL）未能解决现实生活中FL场景中非独立同分布本地数据集的数据异质性问题。本文引入了可重构智能表面（RIS）技术，以实现高效的个性化AirFL，缓解数据异质性问题。首先，我们利用RIS的相位偏移配置，在个性化AirFL框架中实现了跨不同集群的统计干扰消除。接着，我们从一阶和二阶矩的角度出发，提出了两种涉及功率控制和去噪因子设计的个性化聚合方案，以增强FL的收敛性能。数值结果验证了我们提出的方案相对于现有基线的优越性能。|
|**2024-08-22**|**Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective**|Zifan Wang et.al.|[2408.12119](http://arxiv.org/abs/2408.12119)|null|联邦学习（FL）是一种新兴的协作学习范式，旨在保护数据隐私。然而，近期研究表明FL算法易受到严重的数据重建攻击。现有研究缺乏对联邦学习中数据可被重建程度的理论基础，并且由于这些攻击性能不稳定，其有效性难以进行公平比较。为解决这一不足，我们提出一个理论框架来理解针对联邦学习的数据重建攻击。该框架涵盖对数据重建误差的界限分析，攻击的误差界限反映了其固有的攻击效能。在此框架下，我们可以从理论上比较现有攻击的有效性。例如，我们在多个数据集上的结果验证了iDLG攻击在本质上优于DLG攻击。|
|**2024-08-21**|**Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data**|Guojun Tang et.al.|[2408.12029](http://arxiv.org/abs/2408.12029)|null|电子健康记录（EHR）的集成与机器学习应用为提升数据驱动型糖尿病预测的准确性和可获取性提供了契机。特别是，开发数据驱动的机器学习模型能够实现对高风险糖尿病患者的早期识别，进而可能促进更有效的治疗策略并降低医疗成本。然而，监管限制为构建集中式预测模型设置了障碍。本文针对这一挑战，引入了联邦学习方法，该方法在不进行集中数据存储和处理的前提下整合预测模型，从而避免了隐私问题。这是首次将联邦学习应用于加拿大实际临床数据集中的糖尿病预测，这些数据集从加拿大初级保健监测网络（CPCSSN）提取，且未涉及省份间患者数据共享。我们通过下采样技术解决了类别不平衡问题，并将联邦学习性能与基于省份及集中式模型进行了对比。实验结果显示，联邦多层感知器（MLP）模型相比于集中式方法训练的模型，展现出相似或更高的性能。然而，联邦逻辑回归模型的表现则不如其集中式对应模型。|
|**2024-08-21**|**RFID based Health Adherence Medicine Case Using Fair Federated Learning**|Ali Kamrani khodaei et.al.|[2408.11782](http://arxiv.org/abs/2408.11782)|**[link](https://github.com/MibclAric/Smart-Pill-Case)**|**药物依从性的缺乏显著降低了治疗效果，然而在患者中这一问题仍然普遍存在。非依从性与不良后果相关联，包括增加死亡风险和住院风险。尽管存在多种方法帮助患者跟踪服药时间表，如智能给药系统（IDAS）和智能泡罩包装，这些工具在商业可行性上常面临挑战。基于物联网中剂量测量与信息通讯的原理，我们引入了智能药盒——一种利用RFID进行数据记录及NFC进行数据提取的智能健康管理工具。该系统集成了负载传感器以实现精确剂量测量，并配备有安卓应用程序以监控药物摄入、提供建议及发出警告。  为了增强智能药盒的有效性和个性化程度，我们提议融入联邦学习机制。联邦学习使智能药盒能够从多个用户的药物依从性模式中学习，同时不侵犯个人隐私。通过对来自各个智能药盒的去中心化数据进行机器学习模型训练，系统能持续改进其建议和警告，适应不同用户的需求和行为习惯。这一方法不仅增强了工具支持药物依从性的能力，还确保了敏感用户数据的安全与私密。**|
|**2024-08-21**|**FedGS: Federated Gradient Scaling for Heterogeneous Medical Image Segmentation**|Philip Schutte et.al.|[2408.11701](http://arxiv.org/abs/2408.11701)|**[link](https://github.com/trustworthy-ai-uu-nki/federated-learning-disentanglement)**|**在深度学习支持的医疗影像自动分割领域，联邦学习（FL）通过允许在不共享患者数据的情况下进行协作模型训练，有助于保护隐私。然而，FL面临着来自不同机构间数据异质性的挑战，这导致了全局模型的次优表现。将解耦表示学习（DRL）融入FL可以增强其鲁棒性，通过将数据分离为不同的表示特征。现有的DRL方法假设数据异质性仅存在于风格特征中，忽视了基于内容的变异性，如病灶大小和形状。我们提出了FedGS，一种新颖的FL聚合方法，旨在提升对小且代表性不足的目标的分割性能，同时保持整体效能。FedGS在PolypGen和LiTS数据集上展现了相对于FedAvg的优越性能，特别是在处理小病灶时。相关代码及预训练模型检查点可于以下链接获取：https://github.com/Trustworthy-AI-UU-NKI/Federated-Learning-Disentanglement**|
|**2024-08-21**|**Technical Report: Coopetition in Heterogeneous Cross-Silo Federated Learning**|Chao Huang et.al.|[2408.11355](http://arxiv.org/abs/2408.11355)|null|在跨机构联邦学习（FL）中，各公司协同训练一个共享的全局模型，同时不共享异构数据。先前的相关研究主要集中在应对数据异质性的算法开发上，然而，合作与竞争并存的双重问题，即FL合作与市场竞争，尚未得到充分探索。本文利用一个动态双期博弈模型来研究FL中的合作竞争关系。在第一阶段，一家现有公司训练本地模型，并以选定的价格向用户提供基于模型的服务。第二阶段，一家新进入公司加入，两家公司随后决定是否进行FL合作，并以不同的价格向用户出售基于模型的服务以进行市场竞争。  分析这一双期博弈问题极具挑战性，原因在于数据异质性，以及现有公司在第一阶段的定价策略对第二阶段合作竞争产生的时序影响，导致问题非凹。为解决这一难题，我们将问题分解为多个凸子问题，并开发出一种能够达到全局最优解的算法。  数值实验在三个公共数据集上进行，揭示了两个有趣的见解。首先，FL训练带来的模型性能提升同时也伴随着市场竞争损失，只有当性能提升超过损失时，合作才会发生。其次，数据异质性可能促使现有公司在第一阶段限制市场渗透，并在第二阶段加剧价格竞争。|
|**2024-08-21**|**FedMoE: Personalized Federated Learning via Heterogeneous Mixture of Experts**|Hanzi Mei et.al.|[2408.11304](http://arxiv.org/abs/2408.11304)|null|随着大型语言模型（LLMs）不断拓展人工智能的能力边界，它们对数据的需求日益增长。这些数据中很大一部分是私有的，并分布在边缘设备上，使得联邦学习（FL）成为微调（例如，FedLLM）的默认替代方案。然而，由于客户端间存在的固有异质性，包括不同的数据分布和多样的任务类型，联邦学习面临着重大挑战。为了构建一个适应性强的FedLLM，我们用稀疏激活的混合专家（MoE）架构取代了传统的密集模型，其并行的前馈网络提供了更高的灵活性。为了让它在资源受限的环境中更加实用，我们提出了FedMoE，这是一个高效个性化联邦学习框架，旨在解决数据异质性问题，通过为每个客户端构建最优子MoE并将其知识反馈给全局MoE来实现。  FedMoE由两个微调阶段组成。在第一阶段，FedMoE通过基于观察到的激活模式进行启发式搜索简化问题，为每个客户端确定一个次优子模型。在第二阶段，这些子模型被分发给客户端进行进一步训练，并通过一种新颖的模块化聚合策略返回服务器进行聚合。同时，FedMoE通过全局专家推荐逐步调整子模型至最优状态。  实验结果证明，我们的方法相比以往的个性化联邦学习方法具有优越性。|
|**2024-08-21**|**The Key of Parameter Skew in Federated Learning**|Sifan Wang et.al.|[2408.11278](http://arxiv.org/abs/2408.11278)|null|联邦学习（FL）作为一种在不同数据持有者之间进行深度学习而无需交换原始数据的优秀解决方案已崭露头角。然而，联邦学习中的统计异质性带来了关键挑战，导致局部模型参数分布的偏斜现象，这一现象至今为止研究者们关注不足。在此工作中，我们提出了参数偏斜的概念来描述这一现象，该现象能够显著影响全局模型参数估计的准确性。此外，我们引入了FedSA，一种聚合策略，旨在应对参数偏斜所带来的影响，以获得高质量的全局模型。具体而言，我们根据变异系数将参数分为高离散度和低离散度两组。对于高离散度参数，微类（MIC）和宏类（MAC）分别在微观和宏观层面上表征离散度，构成了FedSA的基础。为了评估FedSA的有效性，我们在三个计算机视觉数据集上使用不同的联邦学习算法进行了广泛实验。结果表明，FedSA相比于八个当前最先进的基线方法，测试准确率提高了约4.7%。|
|**2024-08-20**|**NeuLite: Memory-Efficient Federated Learning via Elastic Progressive Training**|Yebo Wu et.al.|[2408.10826](http://arxiv.org/abs/2408.10826)|null|
|**2024-08-20**|**Security Assessment of Hierarchical Federated Deep Learning**|D Alqattan et.al.|[2408.10752](http://arxiv.org/abs/2408.10752)|null|
|**2024-08-20**|**Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions**|Mirko Nardi et.al.|[2408.10664](http://arxiv.org/abs/2408.10664)|null|
|**2024-08-19**|**Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement**|Jeremiah Birrell et.al.|[2408.10456](http://arxiv.org/abs/2408.10456)|**[link](https://github.com/star-ailab/FSRDP)**|
|**2024-08-19**|**Federated Learning of Large ASR Models in the Real World**|Yonghui Xiao et.al.|[2408.10443](http://arxiv.org/abs/2408.10443)|null|
|**2024-08-19**|**Federated Frank-Wolfe Algorithm**|Ali Dadras et.al.|[2408.10090](http://arxiv.org/abs/2408.10090)|**[link](https://github.com/sourasb05/Federated-Frank-Wolfe)**|
|**2024-08-19**|**Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing**|Vinit Hegiste et.al.|[2408.10024](http://arxiv.org/abs/2408.10024)|null|
|**2024-08-19**|**Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets**|Xingrun Yan et.al.|[2408.09762](http://arxiv.org/abs/2408.09762)|null|
|**2024-08-18**|**Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment**|Tatjana Legler et.al.|[2408.09556](http://arxiv.org/abs/2408.09556)|null|
|**2024-08-20**|**Seamless Integration: Sampling Strategies in Federated Learning Systems**|Tatjana Legler et.al.|[2408.09545](http://arxiv.org/abs/2408.09545)|null|
|**2024-08-18**|**Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets**|Shiyuan Zuo et.al.|[2408.09539](http://arxiv.org/abs/2408.09539)|null|
|**2024-08-18**|**Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover**|Dong-Jun Han et.al.|[2408.09522](http://arxiv.org/abs/2408.09522)|null|
|**2024-08-18**|**Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training**|Huitong Jin et.al.|[2408.09478](http://arxiv.org/abs/2408.09478)|null|
|**2024-08-18**|**Federated Graph Learning with Structure Proxy Alignment**|Xingbo Fu et.al.|[2408.09393](http://arxiv.org/abs/2408.09393)|**[link](https://github.com/xbfu/fedspray)**|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227](http://arxiv.org/abs/2408.09227)|**[link](https://github.com/psudslab/FEDMEKI)**|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

