---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.15
> Usage instructions: [here](./docs/README.md#usage)

## agent

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主性、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练不足以赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往通过在精心策划的专家演示上进行监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式蒙特卡洛树搜索（MCTS）与自我批评机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和增强微调基线，并在具备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法论使Llama-3 70B模型的零样本性能从18.6%提升至81.7%（相对增长340%）仅经过一天的数据收集，进一步利用在线搜索可提升至95.4%。我们相信，这标志着自主代理能力的重大飞跃，为现实世界环境中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的表现各异，有的任务表现出色，而在其他任务上则表现不佳。为了充分利用这些代理的独特优势，我们提出了多样性赋能智能（DEI）框架，它能利用代理们的独特专长。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上的最高个体解决率为27.3%，而通过DEI，它们可以达到34.3%的解决率，实现了25%的提升，并超过了大多数闭源解决方案。我们表现最好的代理组合以55%的解决率脱颖而出，在SWE-Bench Lite上占据了榜首位置。我们的发现为协作AI系统研究领域做出了贡献，展现了它们在解决复杂软件工程挑战方面的潜力。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到层次强化学习（HRL）的启发，我们提出了一种新颖的框架——层次在境强化学习（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即动态地将复杂任务分解为子任务。这些子任务由目标定义，并交由低层策略完成。一旦LLM代理判定目标达成，便会提出新的目标。为了提升代理在多回合执行中的性能，我们提出了回顾性模块化反思（HMR）方法，其中，代理不再对完整轨迹进行反思，而是将任务目标替换为中间目标，让代理针对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果表明，在5个执行回合中，与强大的基于上下文学习基线相比，HCRL能实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工智能通用智能（AGI）。然而，在这些基于LLM的代理在实际世界中的规划任务中的行为、潜在失败原因及改进方法方面的研究还较为匮乏。为了填补这一空白，我们通过一个现实的基准测试——TravelPlanner，来展开研究。在此基准测试中，代理必须满足多重约束以生成准确的计划。我们利用这一基准测试来探讨四个关键研究问题：(1) LLM代理在面对长且含有噪声的上下文时，是否足够稳健以进行推理和规划？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化来改进计划，以及(4) 通过结合正面和负面反馈对LLM进行微调能否带来进一步的提升？  我们的综合实验显示，首先，尽管LLMs能够处理大量参考信息和少样本示例，但它们往往未能关注长上下文中的关键部分；其次，它们在分析长计划时仍面临挑战，无法为细化提供精确的反馈；第三，我们提出了一种反馈感知微调（FAFT）方法，该方法利用正负反馈相结合，相比监督式微调（SFT）取得了显著的进步。我们的发现为涉及现实世界规划应用的多个方面提供了深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大的表达方式，它通过结合叙述技巧与可视化和文本，传达深刻见解。这类故事融合了视觉辅助元素，如图表中突出显示的柱状图和线条，并伴有解释性注释来阐述洞察。然而，创建这样的故事需要对数据有深入的理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种自然语言处理任务上表现出色，但它们生成连贯、全面的数据故事的能力尚未得到充分探索。本研究中，我们引入了一项新颖的数据故事生成任务，并建立了一个包含1449个来自不同来源的故事的基准数据集。为了应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体，旨在模拟人类讲故事的过程：一个负责理解和描述数据（反思），生成提纲和叙述，另一个则负责每一步的验证。尽管我们的智能体框架在基于模型和人类评估中普遍优于非智能体对应物，但结果也揭示了数据故事生成中的一些独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理根据与知名地标相关的语言描述来确定目标位置；仅凭对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间不提供具体指令。这一问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，而地标在该环境中常常不可见。在缺乏导航指引的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs对每个观测做出“反应”并据此做出决策。然而，该基线性能较差，代理往往会重复访问同一位置，并做出短视、不连贯的决策。为解决这些问题，本文提出了一种新颖的代理工作流程，其特点是具有感知、反思和规划的能力。具体而言，我们发现LLaVA-7B模型可以通过微调，以足够精确地感知地标的方向和距离，从而满足城市导航的需求。此外，通过一种记忆机制实现反思，该机制存储过往经验，并能根据当前感知进行检索，以便进行有效的决策论证。规划阶段利用反思结果来制定长期计划，从而避免在长距离导航中做出短视决策。我们证明，设计的这一工作流程显著提高了基于LLM的代理的导航能力，相比现有最先进基线有明显提升。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，这两种方法各有显著缺点。基于相似性的检索在复杂任务中往往召回率较低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的通用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口相结合。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索及代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个现实世界的编程应用。凭借统一的图数据库模式，CodexGraph在学术和现实世界环境中均展现出竞争力和潜力，彰显其在软件工程中的多用性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法既费力又需要在通信、网络和优化领域具有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程方面，网络优化将迎来革新性的方法。这种方法通过精心设计的提示策略，将人类的经验和知识融入这些复杂的LLMs中，并部署自主智能体作为沟通桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合体现了未来人工智能（AI）作为服务和AI简化应用的范式。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实现方式：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa）以及协作式多LLM基自主BSS智能体（CLaBa）。通过实际数据的评估，实验表明，辅助提示的LLMs与基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提高了BSS优化的效率并减少了不必要的手动操作参与。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|大型语言模型（LLMs）在处理具有不完美信息的简单游戏及促进多智能体协调方面已展示出成效，但它们在复杂、不完美信息环境下的实际协作能力，尤其是在非英语环境中的应用，仍有待探索。本研究旨在考察开源与API驱动的LLMs将所学知识应用于需要智能体在不完美信息下进行复杂文本策略游戏中协同合作的能力，并将其性能与采用其他类型智能体的现有基线进行对比。我们提出了一种“心理理论”（Theory of Mind, ToM）规划技术，使LLMs能够仅依据游戏规则、当前状态和历史背景作为输入，针对不同对手调整策略。为应对该游戏中的动态和庞大行动空间挑战，引入了外部工具。实验结果表明，尽管当前LLMs与最先进的强化学习（RL）模型之间存在性能差距，但在该游戏设置中，LLMs展现出了ToM能力。这持续提升了它们对抗对手智能体时的表现，表明它们能够理解盟友与对手的行为并能与盟友建立协作。为了促进进一步的研究与理解，我们已公开了代码库。|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|随着大型语言模型（LLMs）的兴起，研究人员正日益探索其在多个垂直领域的应用，软件工程便是其中之一。LLMs在代码生成和漏洞检测等领域取得了显著成就。然而，它们也表现出许多局限性和缺点。基于LLM的智能体作为一种新颖技术，具有实现人工智能通用（AGI）的潜力，通过将LLMs作为决策与行动的核心，缓解了LLMs固有的某些局限，如缺乏自主性和自我改进能力。尽管存在众多研究和调查探讨在软件工程中使用LLMs的可能性，但目前在LLMs与基于LLM的智能体之间尚缺乏明确的区分。对于统一标准及基准测试以资格认定某一LLM解决方案作为其领域内的基于LLM的智能体，这一领域仍处于初级阶段。  本调研广泛探究了软件工程中LLMs及其基于LLM的智能体的当前实践与解决方案。具体而言，我们总结了六个关键主题：需求工程、代码生成、自主决策、软件设计、测试生成及软件维护。我们从这六个方面回顾并区分了LLMs与基于LLM的智能体的工作，考察了它们在任务、基准及评估指标上的异同。最终，我们讨论了所采用的模型与基准，全面分析了它们在软件工程中的应用及其有效性。我们期待，此项工作能为推动基于LLM的智能体在软件工程领域的未来发展边界提供一些启示。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## llm

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能有效识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在通过一项综合调查来填补这一空白，全面概述模型融合方法与理论、它们在不同领域及环境下的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，详尽地讨论了现有模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多种机器学习子领域的应用。最后，我们指出了模型融合存在的挑战，并讨论了未来的研究路径。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在包括涉及多模态数据（如语音）在内的各种任务中取得了显著的性能，但这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型如何响应来自不同人口群体的语音，我们的目标是识别这些偏见。实验揭示了它们在性能和偏见程度上的重要见解。研究发现，虽然大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效情况，并利用自我评估的反馈来计算后对齐概率分布。随后，AED通过自适应结合AED产生的概率分布、后对齐概率与原始概率分布，从而获得既无害又有助益的输出分布。因此，我们的方法在提升安全对齐性的同时，保持了模型的有益性。我们在五个模型上对四种常见的越狱攻击进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现人工智能通用（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了它们的可靠性，为其在真实场景中的部署带来了严峻挑战。增强LLMs的一种有效途径是结合外部数据库与信息检索机制。针对上述挑战，我们提出一种新方法——WeKnow-RAG，它将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM回答的准确性和可靠性。WeKnow-RAG进一步利用领域特定的知识图谱应对多样化的查询和领域需求，借助稀疏和密集检索方法的多阶段网页检索技术，改善了事实信息处理及复杂推理任务的表现。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大规模语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于综合视觉与文本信息的理解与应用。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来检验MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示了即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏明确的完成标准，这意味着已识别的威胁需要验证，这减缓了分析过程。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展该包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一种多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急医疗服务管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例进行演示教学，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文介绍了一个针对LLMs的统一框架，使它们能够自选有影响力的示范性示例以构建上下文；对不同示范组合的候选进行自我排名；并通过强化学习自我优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于LLM自身偏好的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的确切效果。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## Wireless Network

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。在本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而消除了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的技术综述存在较大空缺。本调查报告旨在提供对模型融合方法及理论、其在多种领域与环境中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们在表现和偏见程度上的重要见解。研究发现，尽管大多数模型显示出最小的偏见，但仍有部分模型表现出轻微的刻板印象或反刻板印象的倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效情况，并利用自我评估的反馈来计算后对齐概率分布。随后，AED通过自适应结合AED产生的概率分布、后对齐概率与原始概率分布，旨在获得既无害又有助益的输出分布。因此，我们的方法在提升安全对齐性的同时保持了模型的有用性。实验涵盖了五个模型及四种常见的越狱攻击场景，结果验证了该方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过整合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|无人驾驶航空器（UAV）已成为下一代无线网络的关键组成部分，特别是在灾难恢复场景中，因其灵活性、机动性和快速部署能力而显得尤为重要。本文聚焦于利用太赫兹（THz）链路优化UAV轨迹，以确保在受灾区域实现有效的通信。我们针对诸如能量消耗、用户优先级以及在复杂的三维障碍物中维持视线（LoS）连接等特定挑战展开研究。我们的贡献包括：开发了一种利用在线三维地图数据的详细建模方法，提出了最优轨迹优化问题的数学模型，并提出了一种基于遗传算法（GA）的方法及一种增强型启发式算法以加速收敛过程。通过三维仿真，我们展示了在最小化总服务时间和优先处理更高权重节点之间的权衡，揭示了不同优先级权重因子对轨迹时间的影响。所提出的算法采用卡塔尔多哈West Bay区域的真实世界数据进行了评估，证明了其在紧急响应中优化UAV轨迹的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别出的关键问题包括可解释性、可扩展性和对不断演变威胁的适应性等。最后，结论总结了发现成果，突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，并概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及运用复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用。MathScape旨在评估基于照片的数学问题场景，通过分类层次化的方法来评估MLLMs的理论理解和应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们还分享了与41名理学硕士学生的试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初始复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一种多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以管理药物。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划和资源分配等关键领域表现强劲。   我们的多智能体CDSS展示了在支持全面紧急护理管理方面的巨大潜力。通过利用先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

## Wireless Communications

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全绕过模式链接步骤，而是将完整的数据库模式传递给LLM，从而消除了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保不遗漏重要的模式信息。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在不同领域与环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于训练数据的特性，往往会表现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现，突显了迫切需要解决这些偏见问题。本研究引入了“口语刻板印象集”（Spoken Stereoset），一个专门设计来评估SLLMs中社会偏见的数据集。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们在表现和偏见程度上的重要见解。研究发现，尽管大多数模型显示出最少的偏见，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐能力。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成了重大挑战。通过结合外部数据库与信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过整合知识图谱的结构化表示与密集向量检索的灵活性，提高LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，提升事实信息处理及复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验与在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用的数据集背景信息。该调查探讨了Transformer在网络入侵检测系统（IDS）中的应用，重点关注不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和基于LLMs的IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还解决了研究挑战和未来方向，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并强调了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及运用复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致已识别的威胁需要验证，从而减缓了分析速度。现有文献主要关注威胁分析的整体效能，却未曾研究分析师在何种程度上深入材料分析，才能有效验证所识别的安全威胁。我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了41名硕士研究生参与先导实验的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初始复制包，包含实验材料和数据分析脚本，并计划根据最终与实践者的数据收集活动扩展其内容（例如，增加预筛选问题）。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强劲性能。   我们的多智能体CDSS显示了在支持全面紧急医疗服务方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗交付，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用的不断增长领域做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，即时学习（ICL）展现出了重要的能力。通过使用少量示例作为演示，ICL使LLMs能够在无需更新数百万参数的情况下执行各种任务。本文提出了一种针对LLMs的统一框架，使它们能够自选有影响力的即时示例来构建上下文；对不同演示组合的候选进行自排名；并通过强化学习来自我优化演示的选择与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在根据LLM自身的偏好获得奖励后，生成优化后的演示。实验结果验证了所提方法在提升ICL性能方面的确切效果。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|

## Wireless Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能有效识别相关的模式元素，无需明确的模式链接。这让文本到SQL的处理流程能够完全绕过模式链接步骤，直接将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在不同领域与环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，强调了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，专门用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了关于它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见微乎其微，但某些模型仍显示出轻微的刻板印象或反刻板印象的倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御手段通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”以量化对齐失效，并借助自我评估反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在提升安全对齐的同时，保持了模型的有益性。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。相关代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过整合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM回答的准确性和可靠性。接着，WeKnow-RAG利用领域特定知识图谱应对多种查询和领域需求，通过稀疏和密集检索方法结合的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能，优化了信息检索的效率与准确性。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。广泛离线实验与在线应用证明了我们方法的卓越效果。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大规模语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及应用复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用。MathScape旨在评估基于照片的数学问题场景，通过分类层次化的方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们还分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展该包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现出强劲性能。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在语言模型领域，就地学习（In-context Learning，ICL）随着大型语言模型（Large Language Models，LLMs）的发展展现出重要能力。通过采用少量示例进行演示教学，ICL使LLMs能够在无需调整数百万参数的情况下，执行各种任务。本论文提出了一种面向LLMs的统一框架，该框架使模型能够自我挑选出构建上下文的关键在地示例，对不同示范组合的候选进行自排名，并通过强化学习来自我优化示范的选择及排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过以LLM自身偏好为奖励的训练后，生成优化的示范。实验结果验证了所提方法能有效提升ICL的表现。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中纳入更多多样性。|

## Communication Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|在不断进步的数字通信系统领域，复值神经网络（CVNNs）已成为基石，尤其在均衡、信道估计、波束成形和解码等任务中展现出卓越性能。在众多CVNN架构中，相位传输径向基函数神经网络（PT-RBF）尤为突出，尤其是在诸如5G MIMO系统这类充满噪声的环境中运行时。尽管其功能强大，但在多层、多输入多输出的PT-RBF中实现收敛仍是一个艰巨挑战。针对这一不足，本文提出了一种新颖的深度PT-RBF参数初始化技术。通过遵循3GPP TS 38标准的严格仿真，我们的方法不仅超越了传统初始化策略（如随机、K-均值和星座基方法），而且是唯一能在深层PT-RBF架构中实现成功收敛的方法。这些发现为在复杂数字通信系统中部署更稳健、更高效的神经网络铺平了道路。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在提供对模型融合方法及理论、其在多种领域及场景中的应用，以及未来研究方向的综合概述。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本论文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED灵活地将AED及后对齐概率值与原始概率值结合，以获得无害且有益的概率分布。因此，我们的方法在提升安全对齐的同时，保持了帮助性。实验涵盖了五个模型和四种常见的越狱攻击，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法称为WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG接着利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了研究发现，并突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，同时概述了进一步研究和发展的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也极具挑战性。通过对评估结果的分析，我们识别了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，却未曾研究分析师在深入到何种程度的材料分析后，才能有效验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名理学硕士学生的试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。虽然临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。  我们开发了一个多智能体CDSS，使用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫度量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。  模型采用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强劲性能。  我们的多智能体CDSS显示了在支持全面紧急医疗服务方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能缓解ED拥挤并改善患者预后。此项工作为AI在急诊医学中的应用领域做出了贡献，并为未来的科研与临床实施指明了有希望的方向。|

## RAG

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式直接传递给LLM，从而避免了遗漏必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，旨在提升文本到SQL的准确性，同时确保不丢失重要的模式信息。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名第一。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在多种领域及环境下的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在包括涉及多模态数据（如语音）在内的各种任务中取得了显著的性能，但这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这突显了迫切需要解决这些偏见问题。本研究引入了“口语刻板印象集”（Spoken Stereoset），这是一个专门设计用于评估SLLMs中社会偏见的数据集。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。我们的实验揭示了关于它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出最小的偏见，但有些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率分布。随后，AED动态地将AED产生的概率分布和后对齐概率与原始概率分布相结合，从而获得既无害又有助益的输出分布。因此，我们的方法在提升安全对齐的同时保持了模型的有用性。实验覆盖了五个模型及四种常见的越狱攻击场景，结果验证了该方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。广泛离线实验与在线应用证明了我们方法的杰出有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，并概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|## 背景 在21世纪的乌干达，中学教育质量低下仍是面临的主要挑战之一，特别是在农村地区。研究指出多个问题，其中包括教师授课计划的质量低或缺失。随着政府推动实施新课程，现有的授课计划变得过时，问题更加严峻。针对这一情况，我们采用了一种检索增强生成的方法，开发了一个原型系统，该系统能根据政府认可的教科书生成定制化的授课计划。这有助于教师更高效、更高质量地制定授课计划，确保它们与新课程及能力本位学习方法完全一致。  ## 方法 该原型系统利用Cohere大语言模型、句子嵌入技术以及LangChain框架构建，并公开发布于网站上。我们为三本新课程教科书（信息技术、数学、历史）建立了向量存储库，这些教科书均为中学一年级水平。依据教科书建议的教学时段，我们遵循伪随机生成协议生成了24份授课计划。之后，依据Ndihokubwayo等人（2022年）设计的适用于东非及能力本位课程的授课计划分析协议（LPAP），由三位独立评估员对这些授课计划的技术质量进行了分析。  ## 结果 利用LPAP对24份授课计划进行评估后，其平均质量达到了75%至80%，对应“非常优秀的授课计划”等级。没有一份授课计划得分低于65%，尽管有一份计划在主题覆盖上可能存在争议。总的来说，生成的授课计划质量至少与人工制定的计划相当，甚至更好。这从卢旺达的一项研究中得到印证，在那项研究中，没有任何一份人工制定的授课计划达到50%的基准分数。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，从而减缓了分析过程。以往的研究主要集中在威胁分析的整体效能上，但没有前人工作探讨过分析师必须深入到何种程度，才能有效地验证已识别的安全威胁。  我们提出了一项对照实验，旨在与从业者合作，研究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少的材料。此外，我们还分享了对41名硕士研究生进行先导研究的关键发现，这些发现被用来改进实验设计。最后，我们提供了一个初步的复制包，其中包含了实验材料、数据分析脚本，并计划根据与从业者进行的最终数据收集活动（例如，预先筛选问题）来扩展包含新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划和资源分配等关键领域展现了强劲性能。   我们的多智能体CDSS在支持全面紧急医疗服务管理方面显示出了巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗交付，缓解ED拥挤并提升患者预后。这一工作为急诊医学中AI应用的不断增长领域做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

## text2sql

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时进行模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够跳过模式链接环节，直接将完整的数据库模式传递给LLM，从而避免了信息缺失的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进措施，在不牺牲关键模式信息的前提下提升了文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在通过一项综合调查来填补这一空缺，全面概述模型融合方法与理论、它们在不同领域及环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地探讨了现有的模型融合技术。其次，我们讨论了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多种机器学习子领域的应用。最后，我们指出了模型融合存在的挑战，并探讨了未来的研究趋势。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，加剧了迫切需要解决这些偏见的问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED灵活地将AED产生的概率值与后对齐概率值及原始概率值结合起来，以获得无害且有助益的概率分布。因此，我们的方法在提升安全对齐的同时保持了模型的有用性。我们在五个模型上针对四种常见的越狱攻击进行了实验，结果验证了我们方法的有效性。代码可在https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现人工智能通用（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并时常生成“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成了重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过将知识图谱的结构化表示与密集向量检索的灵活性相结合，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱来满足多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别出的关键问题包括可解释性、可扩展性和对不断演变威胁的适应性等。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和发展的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁，然而缺乏明确的完成标准，导致识别出的威胁需要验证，从而减缓了分析过程。以往的研究主要集中在威胁分析的整体效能上，但没有前人工作探讨过分析师必须深入到何种程度，才能有效地验证已识别的安全威胁。  我们提出了一项对照实验，与从业人员合作，旨在研究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少的材料。此外，我们还分享了与41名硕士研究生进行先导试验的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与从业人员的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由一名临床急诊医学专家进行评定。与单智能体系统基线相比，CDSS在分诊决策方面的准确性表现出色。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域也表现强劲。   我们的多智能体CDSS显示了在支持全面紧急护理管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例进行演示，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文提出了一种针对LLMs的统一框架，使它们能够自选有影响力的示范性示例以构建上下文；对不同示范组合的候选进行自排名；并通过强化学习自优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于LLM自身偏好的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|

## AIOps

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不涉及昂贵的计算成本。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然匮乏。本调查旨在提供对模型融合方法与理论、其在多种领域及场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于训练数据的特性，往往会表现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现出来，这凸显了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了关于模型性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出的偏见最小，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐能力。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还集成了一个自我评估机制，使LLM能够评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严谨框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于的IDS在多种环境和应用中的实施情况，涉及计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还解决了研究挑战和未来方向，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并强调了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在通过分类层次方法评估基于图片的数学问题场景，检验MLLMs的理论理解与应用能力。  我们对11个先进的MLLMs进行了多维度评估，发现即使是最高级的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进实验设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预先筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一种多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者结局。此项工作对急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指出了一个有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例作为演示，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文提出了一种针对LLMs的统一框架，使模型能够自选有影响力的示范性例句来构建其上下文；对不同示范组合的候选进行自排名；并通过强化学习来自我优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过基于模型自身偏好的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的例子，并在检索中融入更多多样性。|

## PPC

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|联邦学习（FL）通过协同训练机器学习模型，为个人数据提供了更强的隐私保护。当联邦学习参与者行使“被遗忘权”，即脱离已参与的联邦学习框架并移除其过往对全局模型的贡献时，联邦学习解决方案应执行所有必要步骤以实现这一目标，同时不牺牲全局模型的整体性能，而当前最先进的相关方案尚不支持这一功能。本文提出了FedQUIT这一新算法，利用知识蒸馏技术从联邦学习全局模型中抹去待遗忘数据的贡献，同时保持模型的泛化能力。FedQUIT直接在客户端设备上运行，与常规联邦学习过程相比，无需共享额外信息，也不假设存在公开可用的代理数据。我们的解决方案高效、有效，适用于集中式和联邦式两种设置。实验结果表明，平均而言，FedQUIT在撤销学习后恢复泛化性能所需的额外通信轮次不到2.5%，得到的已净化全局模型预测效果可与从未接触待遗忘数据的全局模型相媲美。|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|物联网（IoT）设备在多个领域的迅速普及引发了严重的网络安全问题，这促使了基于机器学习（ML）的入侵检测系统（IDS）在网络安全攻击分类方面的持续研究。传统ML模型需要将数据从IoT设备传输到集中式服务器进行流量分析，这引发了严重的隐私担忧。为了解决这一问题，研究人员已经研究了联邦学习（FL）基于的IDS，它能够在保持数据本地化的同时，在IoT设备间训练模型。然而，由于设备的不同漏洞和攻击向量的复杂性所导致的数据异质性，对FL模型的有效性构成了重大挑战。尽管当前研究集中在将各种ML模型适应于FL框架内，但它们未能有效解决设备间攻击类别不平衡的问题，这一问题显著降低了少数攻击的分类准确性。为克服这一挑战，我们引入了FedMADE，一种新颖的动态聚合方法，它根据设备的流量模式对其进行聚类，并根据其对整体性能的贡献来聚合局部模型。我们通过与针对非独立同分布（non-IID）数据设计的其他FL算法进行对比评估，发现FedMADE最多可提升少数攻击分类准确性达71.07%。我们进一步展示了FedMADE对中毒攻击具有鲁棒性，并且在每次通信轮次中相比FedAvg仅增加4.7%（5.03秒）的延迟开销，同时不增加IoT设备的计算负担。|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|联邦学习（FL）旨在解决由隐私、安全法规及所有权顾虑所导致的数据孤岛问题。尽管存在这些障碍，FL仍能使这些孤立的数据存储库在不损害隐私或安全的前提下参与协同学习。同时，区块链技术的进步以及Web 3.0时代中去中心化应用（DApps）的发展，为网络开发带来了变革性的可能。因此，将FL融入Web 3.0为通过协同学习克服数据孤岛限制铺平了道路。然而，鉴于以太坊（ETH）等核心区块链的交易速度限制及智能合约的延迟，采用一次性联邦学习（one-shot FL）——即将传统FL中的客户端-服务器交互减少到单次交换——更适合Web 3.0环境。本文提出了一种针对Web 3.0实用的一次性联邦学习系统，称为OFL-W3。OFL-W3利用区块链技术，通过智能合约管理交易，同时借助于星际文件系统（IPFS）与Flask通信的结合，促进后端服务器操作以应用现有的一次性FL算法。通过整合激励机制，OFL-W3展示了一种在Web 3.0上有效实施一次性FL的方法，为AI与Web 3.0结合的研究提供了宝贵见解及未来方向。|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|卫星任务设计正经历从传统的单一大型卫星向由多颗小型卫星组成的分布式任务配置的范式转变。随着越来越多的这类卫星被部署到轨道上，每颗卫星都收集了大量的数据，对星上轨道边缘计算的兴趣日益增长。联邦学习是一种有前景的分布式计算方法，在此背景下，可使多颗卫星高效协作，进行星上机器学习模型的训练。尽管近期关于在轨道边缘计算中使用联邦学习的研究主要集中在同质卫星星座上，但联邦学习同样可以应用于让异构卫星形成临时协作的场景，例如由不同运营商运营的通信卫星。此类应用向联邦学习范式提出了额外挑战，这些挑战主要源于系统的异构性。在这篇立场论文中，我们针对跨供应商应用场景，系统地回顾了这些挑战，对每一项挑战给出了当前研究状态的简要概述，并为深入探讨每个问题提供了入口。|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|分布式联邦学习（FL）范式基于区块链架构构建，利用分布式节点集群替代单一服务器执行FL模型聚合。这一范式解决了原始FL中集中式恶意服务器的脆弱性问题，并继承了区块链所提供的可信度与韧性。然而，现有的区块链支持方案在模型保密性和区块链执行大规模FL计算的有限计算资源方面面临挑战。本文提出了Voltran，一个创新的混合平台，旨在通过可信执行环境（TEE）与区块链技术的结合，为基于FL的学习实现信任、保密性和韧性。我们将在TEE中卸载FL聚合计算以提供一个隔离的、可信的和可定制的链下执行环境，并确保聚合结果在区块链上的真实性和可验证性。此外，我们通过引入多SGX并行执行策略来分摊大规模FL工作负载，从而为多种FL场景提供了强大的可扩展性。我们实现了Voltran的原型，并进行了全面的性能评估。广泛的实验结果表明，Voltran在保证信任、保密性和真实性的同时，只带来极小的额外开销，并且相比最先进的密文聚合方案显著加速。|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|联邦学习（FL）是一种分布式机器学习方法，它使设备能够在不共享本地数据的情况下协作训练模型，从而确保用户隐私和可扩展性。然而，将FL应用于现实世界的数据面临着挑战，特别是因为现有的大多数FL研究集中在单模态数据上。多模态联邦学习（MFL）应运而生以解决这些挑战，利用模态特定的编码器模型来处理多样化的数据集。当前的MFL方法常常统一地分配所有模态的计算频率，这对于资源有限的物联网设备而言效率低下。在本文中，我们提出了FlexMod，这是一种新颖的方法，通过根据各模态编码器的重要性与训练需求自适应地分配训练资源，以增强MFL中的计算效率。我们采用原型学习来评估模态编码器的质量，使用Shapley值来量化每个模态的重要性，并采纳深度强化学习中的深度确定性策略梯度（DDPG）方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化了模型性能和资源利用。在三个真实世界数据集上的实验结果表明，我们提出的方法显著提高了MFL模型的性能。|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|分布式健康智能网络（DHIN）是一个理论框架，旨在解决因医疗数据在各提供者与机构间碎片化而导致的健康数据主权和人工智能在医疗领域应用的重大挑战。该框架首先确立了医疗保健供应的主权架构作为建立主权健康网络的前提，随后通过克服访问多样化的医学数据源障碍，促进人工智能的有效利用。这一综合框架利用以下三点：1）结合个人健康记录（PHR）的自我主权身份架构，作为实现健康数据主权的基础；2）在公共区块链上实施的可扩展联邦学习（FL）协议，用于去中心化的医疗保健人工智能训练，其中健康数据保留在参与者手中，仅分享模型参数更新；3）可扩展且无需信任的奖励机制，激励参与并确保奖励公平分配。该框架确保没有任何实体能够阻止或控制对参与者提供的健康数据进行训练的访问，或决定经济利益，因为这些过程在具有不可篡改记录且无需第三方的公共区块链上运行。它支持在医疗保健领域有效的人工智能训练，使患者能够保持对其健康数据的控制，获得经济收益，并为利用集体智能开发有益于医疗保健的算法的去中心化、可扩展生态系统做出贡献。作为参与联邦学习协议的激励，患者会收到数字钱包中的奖励，长期规划是为去中心化保险解决方案提供资金支持。这一方法引入了一种新颖的自融资医疗保健模式，该模式适应个人需求，补充现有体系，并重新定义普遍覆盖的概念。它突显了变革医疗数据管理和人工智能应用的潜力，同时赋予患者权力。|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|在金融和医疗等高度受监管的行业领域，数据治理面临严峻挑战，数据的交换与利用尤为困难。联邦学习（FL）作为一种创新的分布式机器学习范式，能够在多个机构间协同进行模型训练，同时保持数据分散，从而应对了这一挑战。然而，FL虽有其优势，却也面临着诸多敌对威胁，特别是在由中心服务器管理的模型聚合阶段容易遭受中毒攻击。此外，神经网络模型仍有可能不经意地记住并潜在暴露个别训练实例，这构成了重大的隐私风险，因为攻击者可能利用模型内部蕴含的信息来重建私人数据。当前的解决方案未能提供一个既完全防止信息泄露又计算高效的安全联邦学习系统。针对这些顾虑，我们提出了Lancelot这一创新且计算高效的联邦学习框架，它采用全同态加密（FHE）技术来防御恶意客户端行为，同时保护数据隐私。广泛的测试表明，包括医学影像诊断和广泛应用的公开图像数据集在内，Lancelot显著超越现有方法，处理速度提升超过二十倍，同时确保了数据隐私。|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|null|心血管疾病是全球范围内导致死亡的主要原因，强调了准确诊断方法的重要性。本研究利用UCI数据集，该数据集包含来自美国、匈牙利和瑞士四家医院的920份患者记录，对心脏病分类中的集中式和联邦机器学习算法进行了基准测试。基准测试得到了Shapley值可解释性分析的支持，以量化特征对于分类的重要性。在集中式设置中，使用多种二元分类算法对汇总数据进行训练，其中支持向量机（SVM）达到了最高的测试准确率83.3%，超过了使用逻辑回归建立的78.7%的既定基准。此外，我们还探索了联邦学习算法，其中四个客户端（医院）各自持有数据，利用数据集的自然划分来增强隐私保护，同时不牺牲准确性。联邦SVM作为一种文献中较少见的方法，在此场景下达到了73.8%的最高测试准确率。我们的可解释性分析与现有的心脏病指标医学知识相吻合。总的来说，本研究为高效且可解释的心脏病预筛查工具建立了基准，同时维护了患者的隐私。|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|**联邦学习（FL）在面临拜占庭攻击时变得尤为脆弱，这种情况下，部分参与者通过发送恶意模型更新以损害模型的效用或阻碍模型的收敛。以往的研究提出采用鲁棒性规则来聚合参与者的更新，以抵御不同类型的拜占庭攻击；然而，攻击者也能针对已知的具体聚合规则设计更高级的拜占庭攻击算法。实际上，联邦学习系统可能包含一个黑盒服务器，使得采用的聚合规则对参与者不可访问，这自然能够防御或削弱某些拜占庭攻击。本文深入探讨了配备黑盒服务器的联邦学习系统的拜占庭健壮性。我们的研究显示，采用动态防御策略的黑盒服务器能显著提升对抗拜占庭攻击的鲁棒性。我们通过实证证据和理论分析揭示，黑盒服务器能够将拜占庭攻击的最大影响程度降低至期望影响程度，这一效果归因于黑盒服务器固有的不可访问性和随机性所提供的保护。为了促进社区内的进一步研究，相关源代码已公开，可于https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense获取。**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

