---
layout: default
---

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.17
> Usage instructions: [here](./docs/README.md#usage)

## agent

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR中可用的全套自然输入方式，包括内向感应数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、视线聚焦和XR环境中的情境记忆中隐式提取上下文。这最大限度地减少了对人工设计的明确提示的依赖，促进了根植于实际情境且直观的交互，从而为聊天机器人提供用户洞察。用户研究证明了我们的方法在简化XR中与聊天机器人的用户交互方面的可行性与变革潜力，并为未来XR实体化LLM代理的设计提供了启示。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的建筑信息模型（BIM）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使设计过程复杂化，阻碍了建筑、工程与施工（AEC）行业中BIM及基于模型设计的应用普及。为更直观地表达设计意图，我们提出了Text2BIM框架，这是一个基于大型语言模型（LLM）的多智能体系统，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作和推理，将用户的文本输入转化为可执行代码，进而调用BIM创作软件的API，直接在软件内部生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，框架内嵌入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体识别并解决生成模型中的问题，通过迭代优化提升模型质量。我们进行了大量实验，对比分析三种不同LLM在所提框架下的性能。评估结果显示，该方法能有效生成高质量、结构合理的建筑模型，与用户输入的抽象概念保持一致。最后，开发了一款交互式软件原型，将此框架融入BIM创作软件Vectorworks中，通过“聊天式”建模展示了其应用潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个重大挑战。传统的静态数据监督预训练无法使模型获得在动态场景（如网页导航）中执行复杂决策所需的自主代理能力。以往尝试通过在专家演示的监督微调来弥合这一差距，往往会因累积错误和有限的探索数据而受限，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式蒙特卡洛树搜索（MCTS）与自我批判机制，并利用离策略直接偏好优化（DPO）算法变体对基于代理的交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提高了它们在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，该平台持续超越了行为克隆和强化微调基线，并在具备在线搜索能力时超越了人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升至81.7%（相对增长340%），仅经过一天的数据收集，进一步提升至95.4%配合在线搜索。我们认为，这代表了自主代理能力的重大飞跃，为现实世界设置中更复杂和可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的表现各异，有些任务表现出色，而在其他任务上则表现不佳。为了充分利用这些代理的独特专长，我们提出了DEI（多样性赋能智能）这一框架，它能利用它们各自的专业知识。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅超越最佳单个代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上最大个体解决率为27.3%，而通过DEI可达到34.3%的解决率，实现了25%的提升，并超过了大多数闭源解决方案。我们表现最好的群体以55%的解决率脱颖而出，在SWE-Bench Lite上占据榜首。我们的发现为协作AI系统研究领域做出了贡献，彰显了其解决复杂软件工程挑战的潜力。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到层次强化学习（HRL）的启发，我们提出了一种新颖的框架——层次在境强化学习（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即动态地将复杂任务分解为子任务。这些子任务由目标定义，并分配给低层策略去完成。一旦LLM代理判定目标达成，便会提出新的目标。为了提升代理在多回合执行中的表现，我们提出了回顾性模块化反射（HMR）方法，其中，代理不是反思整个轨迹，而是将任务目标替换为中间目标，让代理针对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境中——ALFWorld、Webshop和HotpotQA，评估了所提HCRL在决策能力上的表现。结果显示，在5轮执行中，HCRL相比于强大的基于上下文学习的基线方法，能实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工通用智能（AGI）。然而，在这些模型基于的代理行为、潜在失败原因及改进方法，尤其是在高要求的真实世界规划任务中的研究还较为匮乏。为了填补这一空白，我们通过一个现实主义基准测试——TravelPlanner，来展示我们的研究。在此测试中，代理必须满足多重约束以生成准确的计划。我们利用此基准测试来探讨四个关键研究问题：(1) LLM代理在面对长且含有噪声的上下文时，其推理和规划能力是否足够稳健？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化来改进计划，以及(4) 通过正负反馈相结合的微调方法能否使LLM性能进一步提升？  我们的综合实验显示，首先，尽管LLMs能够处理大量参考信息和少样本示例，但它们往往无法关注到长上下文中的关键部分；其次，它们在分析长计划时仍面临挑战，无法为细化提供精确反馈；第三，我们提出的反馈感知微调（FAFT）方法，利用正负反馈结合的方式，相较于监督微调（SFT）实现了显著的性能提升。我们的发现为社区提供了关于真实世界规划应用多方面的深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大方法，它通过结合叙述技巧与可视化和文本传达洞察。这些故事融入了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释洞察的文本注释。然而，创建此类故事需要对数据有深刻理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种NLP任务上表现出色，但它们生成连贯、全面的数据故事的能力尚未得到充分探索。在本工作中，我们引入了一项新颖的数据故事生成任务及一个包含1,449个来自不同来源的故事的基准数据集。为应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体来模拟人类讲故事的过程：一个负责理解并描述数据（反思），生成概要和叙述，另一个则负责每一步的验证。尽管我们的智能体框架在基于模型和人工评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成特有的挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收到关于目标位置相对于知名地标语言描述的信息；仅依据对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间不提供具体指令。这一问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，而地标在该环境中常常不可见。在缺乏导航指引的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs针对每次观察做出“反应”并据此做出决策。然而，该基线性能较差，代理往往会重复访问同一位置，并做出短视且不连贯的决策。为解决这些问题，本文提出了一种新颖的代理工作流程，其特点是具有感知、反思和规划的能力。具体而言，我们发现LLaVA-7B模型可以通过微调来准确地感知地标的方向和距离，这种精度足以满足城市导航的需求。此外，通过一种记忆机制实现反思，过往经验得以存储，并能与当前感知信息相结合，以便进行有效的决策论证。规划阶段利用反思结果来制定长期计划，从而避免在远距离导航中做出短视的决策。我们证明，设计的这一工作流程显著提升了基于LLM的代理的导航能力，相比现有最先进基线有明显优势。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，这两种方法各有显著缺点。基于相似性的检索在复杂任务中往往召回率较低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的通用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口相结合。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索及代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个现实世界的编程应用案例。凭借统一的图数据库模式，CodexGraph在学术和现实世界环境中均展现出竞争力和潜力，彰显了其在软件工程中的多样性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法既费时又需要在通信、网络和优化领域具有深厚的专业知识。随着大型语言模型（LLMs）及其相关技术的不断进步，特别是在提示工程和智能体工程方面，网络优化将迎来革新性的方法。这种方法通过精心设计的提示，将人类的经验和知识融入这些复杂LLMs中，并部署自主智能体作为通信桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合代表了AI即服务的未来模式，以及让AI更易于使用的趋势。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa）以及协作式多LLM基自主BSS智能体（CLaBa）。通过对真实世界数据的评估，实验表明，辅助提示的LLMs和基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提高了BSS优化的效率并减少了人工参与的琐碎工作。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## llm

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力常常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够以程序方式生成视觉数据。尽管LLMs在程序合成方面显示出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过它们回答与图形内容相关问题的能力来衡量LLMs对符号程序的理解程度。这一任务颇具挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容来回答则相对容易，我们通过人类实验验证了这一点。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个关于符号图形程序语义理解的大规模基准测试，该测试通过程序-图形对应构建，因此需要最少的人力投入。我们在该基准上评估当前的LLMs，以初步了解它们根据程序推理视觉场景的能力。我们发现这个任务能区分现有的LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们使用由符号程序生成的问题和图像查询GPT4-o。此类数据随后被用于微调LLM。我们还发现，SIT数据能提高LLMs的一般指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于一个已知的高质量数据集作为参考，这可能引入潜在偏差并损害多样性。在本文中，我们提出了ScalingFilter这一新颖方法，它根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而在过滤过程中消除了参考数据集的影响。理论分析表明，ScalingFilter等价于对规模法则的逆向利用。通过使用13亿参数的模型在经过不同质量过滤器处理的同一数据源上进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型进行语义表示。广泛实验揭示，语义多样性是数据集多样性的可靠指标，而ScalingFilter在下游性能和语义多样性之间实现了最优平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了诸如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1等最前沿的大型语言模型（LLMs）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLMs的能力，特别是它们在解决交通运输工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度及某些未预料到的一致性问题。我们的研究标志着迈向利用人工通用智能应对复杂交通运输挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排除和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，基于传统启发式的方法需要手工特性和领域知识，这很难大规模泛化。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会产生大量误报，掩盖了真实的异常。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能、成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以对日志进行聚类，从而将查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，定期更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话提供了用户现实场景、行为和需求的窗口，因此是模型开发和研究的宝贵资源。尽管盈利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，但开源和研究社区在这方面进展较慢。我们推出了ShareLM集合，这是一组统一的人类与大型语言模型的对话数据集，以及一个配套的插件——一个允许自愿贡献用户-模型对话的网络扩展。鉴于少数平台分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台分享对话。该插件允许用户在对话及回复层面进行评级，并可在对话离开用户本地存储之前删除他们希望保持私密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人机对话数据领域投入更多社区力量。代码、插件和数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时在多模态输入的分析判断与决策方面展现出可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的语言模型基框架，使机器人能够根据给定的文字指令自主规划行为及低层执行，同时观察并纠正执行任务过程中可能出现的失败。为了系统性地评估该框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上相比密集模型的优越性能而变得流行。然而，在大规模设置下从头开始训练MoE模型成本高昂。现有方法通过预先独立训练多个密集专家模型并用它们来初始化MoE来缓解这一问题。这是通过使用专家的前馈网络（FFN）来初始化MoE的专家层，同时合并其他参数来实现的。但是，这种方法限制了密集模型参数的重用仅限于FFN层，从而在将这些模型“升级循环利用”为MoE时限制了优势。我们提出了BAM（Branch-Attend-Mix），一个简单而有效的方法，解决了这个缺点。BAM通过不仅利用密集模型的FFN来初始化MoE层，还通过将专家的注意力参数完全初始化到注意力混合（Mixture of Attention, MoA）层的软变体中，充分利用了专门的密集模型。  我们探索了两种升级循环利用注意力参数的方法：1）从密集模型中包括所有注意力参数初始化单独的注意力专家，以实现最佳模型性能；2）在所有专家间共享键和值参数，以促进更好的推理效率。为了进一步提高效率，我们采用了一种并行注意力变压器架构应用于MoE，使得注意力专家和FFN专家可以并行计算。我们在从5.9亿到20亿参数的种子模型上的实验表明，BAM在相同的计算和数据约束下，无论是在困惑度还是下游任务性能上，都超越了基线水平。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了利用LLMs增强协同过滤模型，已有多种尝试通过对比学习等技术进行表示对齐以转移知识。然而，本研究证明，直接对齐LLMs与协同模型的表示对于提升下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效对齐两者间的语义表示仍是一个未解挑战。  受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs与协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局与局部结构对齐，以促进知识迁移。此外，我们从理论上证明了特定和共享表示含有更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的显著进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争论。该争论的核心围绕两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践意义的框架，旨在评估LLMs在运用这些概率测度模拟现实世界推理机制方面的有效性。通过将LLMs视作经由自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝着深入了解LLMs何时能够进行推理这一目标迈出的重要一步，并通过一系列数学实例予以说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

## Wireless Network

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够以程序方式生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过提问与图形内容相关的问题来衡量LLMs对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，如果直接查看相应的图形内容，回答这些问题则相对容易，这一点我们通过人类实验进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染出的视觉内容。我们利用这项任务创建了一个针对符号图形程序语义理解的大规模基准测试。该基准测试通过程序-图形对应关系构建，因此需要最少的人力投入。我们在该基准上评估了当前的LLMs，以初步揭示它们根据程序推断视觉场景的能力。我们发现，此任务能区分现有的LLMs，并且被认为擅长推理的模型在此任务上的表现更优。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们向GPT4-o提出问题并提供由符号程序生成的图像。此类数据随后被用于微调LLMs。我们还发现，SIT数据能提升LLMs的通用指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题示例，涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLM的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致性行为。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战这一激动人心的初步尝试。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的日志解析是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有的日志解析器在实际系统中存在三个主要问题：首先，基于传统启发式的解析器需要手工特性和领域知识，这很难大规模泛化。其次，依赖大型语言模型的现有解析器采用定期离线处理方式，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会引发大量误报，从而掩盖真实的异常情况。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能、成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而将查询成本降低数个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，定期更新现有的日志分组。我们在14个大型公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时展现出对多模态输入进行分析判断与决策的可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低级执行，同时观察并纠正执行任务过程中可能出现的失败。为了系统地评估该框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”和“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了利用LLMs增强协同过滤模型，已有多种尝试通过对比学习等技术进行表示对齐以转移知识。然而，本研究证明，直接对齐LLMs与协同模型的表示对于提升下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效对齐两者间的语义表示仍是一个未解挑战。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局和局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表示包含更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于现有最先进的算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，目前尚缺乏深入了解。为了考察针对某一观点的偏见程度，我们通过两项下游任务评估了两种情况：一是使用隐性知识和显性知识来识别社会群体。首先，我们通过极端偏见场景下的压力测试评估，采用带有偏见的模型进行检验。随后，我们评估了当面对观点冲突时，大型语言模型（LLMs）在处理隐性和显性观点时的语言校准情况。研究发现，模型在识别隐性观点与显性观点时存在差异，且普遍倾向于放大与之立场相反的显性观点的偏见。此外，与偏见立场一致的模型在生成回复时采用了更多体现不确定性的表述，相比之下，未对齐（零样本）的基础模型则产生了直接而不谨慎的回应。这些基础模型的直接性反应暗示了在处理高度主观性和社会敏感性话题时，有必要通过融入不确定性标记来进一步细化其决断性，以增强其可靠性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的显著进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争论。该争论的核心围绕两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践性的框架，旨在评估LLMs在利用这些概率测度复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝向更深入理解LLMs在何时能够进行推理这一目标迈出的重要一步，并通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有希望的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即便经过微调，LLM的输出可靠性仍然存疑，尤其是考虑到任务的复杂性和LLMs固有的幻象问题。    为了解决这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转化为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转换为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并汇总以形成层次化的LTL规范。这些规范随后被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过模拟及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果表明，我们的方法在多机器人任务分配和计划生成上达到了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

## Wireless Communications

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够以程序方式生成视觉数据。尽管LLMs在程序合成方面已展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过提问与图形内容相关的问题来衡量LLMs对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，如果直接查看对应的图形内容，回答这些问题则相当容易，这一点我们通过人类实验进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染出的视觉内容。我们利用这一任务创建了一个关于符号图形程序语义理解的大规模基准测试。该基准通过程序-图形对应关系构建，因此需要最少的人力投入。我们在该基准上评估了当前的LLMs，以初步揭示它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有的LLMs，并且在推理方面表现较好的模型在此任务上也更为出色。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们向GPT4-o提出问题并使用符号程序生成的图像，这些数据随后被用于微调LLM。我们还发现，SIT数据能够提升LLMs的一般指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLM的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度以及某些未预料到的一致性问题。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战这一激动人心的初步尝试。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特征和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量误报，掩盖真实的异常。为了解决这些挑战，我们提出了HELP，一个基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能且成本效益高的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前聚类日志，从而将查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，定期更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并且在针对多模态输入进行分析性判断与决策方面展现出可用性。为了借助LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够在给定文本指令下自主规划行为及低级执行方案，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估这一框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐以增强下游推荐任务表现是次优的，这一结论基于信息理论。因此，如何有效地在协同模型与LLMs之间对齐语义表示的问题仍未得到妥善解决。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局和局部结构对齐，以促进知识转移。此外，我们理论上证明了特定和共享表示含有更多相关且较少无关的信息，这能增强下游推荐任务的效果。在基准数据集上的广泛实验结果表明，我们的方法优于现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力，但其成本、网络限制以及安全约束等问题，在融入工作流程时带来了挑战。本研究采纳系统设计方法，将LLMs用作有瑕疵的数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法在七项上超越了仅使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，目前了解尚少。为了考察对某一观点的偏见程度，我们通过两项下游任务评估了隐性和显性社会群体知识在偏见识别中的作用。首先，我们通过使用在极端偏见情境下存在偏见的模型进行压力测试评估。随后，我们分析了当面对与既有观点相冲突的情况时，大型语言模型（LLMs）如何在处理隐性和显性观点时进行语言上的校准。研究结果显示，模型在识别隐性观点与显性观点上存在差异，且普遍倾向于放大与之对立的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多体现不确定性的表述，相比之下，未对齐（零样本）的基础模型则产生了直接而不谨慎的回应。这些未经调整模型的果断回应暗示了在处理高度主观性和社会敏感性话题时，有必要通过融入不确定性标记来进一步优化其决断性，以提升其可靠性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一套理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下能够计算出PN和PS的合适近似值。本研究标志着朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在没有额外信息的情况下，准确识别这些噪声交互特别困难，主要原因在于缺乏明确的监督信号来标注噪音。大型语言模型（LLMs），凭借其丰富的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，将LLMs应用于序列推荐中的去噪任务带来了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常产生不合逻辑的响应；2）即便经过微调，LLM的输出可靠性仍值得怀疑，尤其是考虑到任务的复杂性和LLMs固有的虚构问题。  为应对这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一项自监督微调任务，旨在激活LLMs识别噪声项目并提出替代项的能力。此外，我们开发了一个不确定性估计模块，确保仅采用置信度高的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于多种推荐模型中。广泛的实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总，形成层次化的LTL规范。这些规范随后被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的实际实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成方面实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

## Wireless Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是图形内容的一种流行表示形式，能够以程序方式生成视觉数据。虽然LLMs在程序合成方面展现出令人兴奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过回答与图形内容相关的问题来衡量LLMs对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，如果直接查看对应的图形内容，回答这些问题将变得容易，这一点我们通过人类实验进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染后的视觉内容。我们利用这一任务创建了一个大型基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应关系构建，因此需要最少的人力投入。我们使用此基准测试对现有LLMs进行评估，以初步了解它们从程序中推断视觉场景的能力。我们发现，此任务能区分现有的LLMs，并且在推理方面表现较好的模型在此任务上表现更佳。最后，我们引入了符号指令微调（SIT）以提升这种能力。具体来说，我们向GPT4-o提出问题并展示由符号程序生成的图像。此类数据随后被用来对LLM进行微调。我们还发现，SIT数据能提升LLMs的通用指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新一代大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样例，涵盖了交通系统的规划、设计、管理和控制等多方面内容。该数据集被用于由人类专家评估多种商业及开源语言模型在解决交通工程问题时的能力，特别是它们的准确性、一致性和推理行为。我们的全面分析揭示了每个模型的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度及某些未预料到的一致性问题。我们的研究标志着迈向利用人工智能通用解决方案应对复杂交通挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的 log parsing（日志解析）过程，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有的日志解析器在实际系统中面临三大挑战：首先，基于传统启发式的方法需要手工特征和领域知识，这很难大规模推广；其次，依赖大型语言模型的现有解析器采用定期的离线处理方式，限制了它们在实时应用场景中的有效性；第三，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会引发大量误报，从而掩盖真实的异常。为了解决这些问题，我们提出了HELP（Hierarchical Embeddings-based Log Parser，基于层次嵌入的日志解析器）。HELP 是首个利用大型语言模型进行高性能且成本效益高的在线语义解析的日志解析器。我们通过一个创新的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以聚类日志，从而在查询成本上降低数个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性上的F1分数显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了其在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析任务既有效又高效。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并且在针对多模态输入进行分析性判断与决策方面展现出可用性。为了借助LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够在给定文本指令下自主规划行为及低级执行方案，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估这一框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本研究证明，直接对LLMs与协同模型的表征进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解难题。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表征正则化，将LLMs与协同模型的潜在表征分解为特定和共享成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识迁移。此外，我们从理论上证明了特定和共享表征含有更多相关且较少无关的信息，从而能提升下游推荐任务的效果。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署过程。|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，我们仍知之甚少。为了考察针对某一观点的偏见程度，我们通过两项下游任务评估了隐性和显性社会群体知识的使用情况。首先，我们通过在极端偏见情境下应用带有偏见的模型进行压力测试评估。接着，我们评估了当面对与既有观点相冲突的意见时，大型语言模型（LLMs）如何在语言上针对隐性和显性观点进行校准。研究发现，模型在识别隐性与显性观点方面存在差异，普遍倾向于放大与之对立的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多谨慎性表述，比起未经对齐（零样本）的基础模型更频繁地使用了不确定性词语。相比之下，未经对齐模型的直接且不够谨慎的回应表明，为了提高在高度主观且社会敏感话题上的可靠性，需要进一步优化其决策果断性，特别是通过融入不确定性标记的方式。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践意义的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下能够计算出PN和PS的合适近似值。本研究标志着朝着更深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即使经过微调，LLM的输出可靠性仍然存疑，特别是考虑到任务的复杂性和LLMs固有的幻象问题。为应对这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕获任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并汇总以形成层次化的LTL规范。这些规范继而用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次化推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成上实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

## Communication Intelligence

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验对此进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个大规模的基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应构建，因此需要最少的人力投入。我们使用此基准测试对现有LLMs进行评估，以初步揭示它们根据程序推理视觉场景的能力。我们发现，这一任务能区分现有的LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们向GPT4-o提出问题，并使用由符号程序生成的图像，这些数据随后被用来微调LLM。我们还发现，SIT数据能提升LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，涵盖了交通系统的规划、设计、管理和控制等多个方面。该数据集被人类专家用来评估各种商业及开源LLM在解决交通工程问题时的能力，特别是它们的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的惊人准确度及某些未预期的一致性问题。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模泛化。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，即轻微的日志变化会产生大量误报，从而掩盖了真实的异常。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能且成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而将查询成本降低数个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大型公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并展现出对多模态输入进行分析判断与决策的可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低级执行过程，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估这一框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用价值。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本研究证明，直接对LLMs与协同模型的表征进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解难题。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表征正则化，将LLMs与协同模型的潜在表征分解为特定和共享成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表征含有更多相关且少冗余的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，可用于将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署。|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，我们仍知之甚少。为了考察针对某一观点的偏见程度，我们通过两项下游任务评估了两种情况：一是语言模型在使用对社会群体的隐性和显性知识时的表现。首先，我们通过极端偏见场景下的压力测试评估，采用带有偏见的模型进行检验。随后，我们评估了当面对与既有观点相冲突的情境时，语言模型如何在处理隐性和显性观点上进行语言上的校准。研究结果揭示了语言模型在识别隐性观点与显性观点之间存在差异，普遍倾向于放大与之立场相反的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比之下，未对齐（零样本）的基础模型则产生了直接而不谨慎的回复。未经对齐模型的这种直接且欠考虑的反应提示我们，为了提高在高度主观且涉及社会细微差别的议题上的可靠性，有必要进一步细化其决定性，特别是通过融入不确定性标记的方式。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。该争议的核心围绕两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个兼具理论与实践意义的框架，旨在评估LLMs在运用这些概率测度模拟现实世界推理机制方面的有效性。通过将LLMs视作经由自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着朝着深入了解LLMs何时能够进行推理这一目标迈出的重要一步，并通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有希望的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即便经过微调，LLM的输出可靠性仍然存疑，尤其是考虑到任务的复杂性和LLMs固有的幻象问题。    为了解决这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总形成层次LTL规范。这些规范继而用于借助现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过模拟及涉及人类参与者的实际环境实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成方面实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

## RAG

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验验证了这一点。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个大规模的基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应构建，因此需要最少的人力投入。我们在这一基准上评估当前的LLMs，以初步揭示它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有的LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们向GPT4-o提出问题并使用符号程序生成的图像，这些数据随后被用来微调LLM。我们还发现，SIT数据能增进LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（LLMs），包括GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3以及Llama 3.1，在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用于评估各种商业及开源LLMs的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的全面分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致行为。我们的研究标志着利用人工智能通用解决方案应对复杂交通挑战这一激动人心的初步尝试。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。将半结构化的日志消息转换为结构化模板的日志解析工作，是自动化日志分析任务（如异常检测、故障排查及根本原因分析）的先决条件。然而，现有日志解析器在实际系统中面临三大挑战：首先，传统的基于规则的解析器需要手工设计特征及领域知识，难以大规模推广。其次，依赖大型语言模型的现有解析器采用定期离线处理方式，限制了其在实时应用场景中的效能。再次，现有的在线解析算法易受日志漂移影响，即日志的微小变动会引发大量误报，掩盖真实异常。为解决这些问题，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs（大型语言模型）进行高性能且成本效益高的在线语义解析器，通过创新的层次嵌入模块实现。该模块对文本嵌入模型进行微调，以在解析前对日志进行聚类，从而将查询成本降低数个数量级。为应对日志漂移，我们还开发了迭代再平衡模块，周期性地更新现有日志分组。我们在14个大规模公共数据集上对HELP进行了详尽评估，结果显示HELP在加权分组和解析准确性方面显著优于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，进一步证实了其在生产环境中的实用性。研究结果表明，HELP能有效且高效地应对高吞吐量的真实世界日志解析需求。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务展示强大的规划与推理能力、以及在多模态输入上运用分析性判断和决策方面，已展现出巨大潜力。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为和低级执行，并在任务执行过程中观察及纠正可能出现的失败。为了系统地评估这一框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”和“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了该方法在具备自主行为规划的机器人任务中的有效性和应用价值。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，已有多种尝试旨在从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐以增强下游推荐任务表现是次优的，这一结论基于信息理论。因此，如何有效地在协同模型与LLMs之间对齐语义表示仍是一个未解决的挑战。受此观点启发，我们提出了一种新颖的即插即用对齐框架，用于LLMs与协同模型的融合。具体而言，我们首先通过投射层和表示正则化，将LLMs与协同模型的潜在表示分解为特定和共享成分。随后，在共享表示上执行全局与局部结构对齐，以促进知识迁移。此外，我们从理论上证明了特定和共享表示包含了更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于现有的最先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，可用于将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署。|
|**2024-08-15**|**Covert Bias: The Severity of Social Views' Unalignment Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，我们仍知之甚少。为了考察针对某一观点的偏见程度，我们通过两项下游任务评估了模型在使用隐性和显性社会群体知识时的表现。首先，我们通过在极端偏见情境下应用有偏模型进行压力测试评估。随后，我们评估了当模型面临与既有观点相冲突的情况时，它们如何在语言上针对隐性和显性观点进行校准。研究发现，模型在识别隐性观点与显性观点方面存在差异，普遍趋向于对持反对立场的显性观点表现出更大偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比之下，未对齐（零样本）的基础模型则产生了直接而不谨慎的回应。这些基础模型的直接回应表明，为了提高在高度主观且社会敏感话题上的可靠性，有必要通过融入不确定性标记来进一步细化其决断性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性概率（PN）与充分性概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个理论与实践并重的框架，旨在评估LLMs在利用这些概率度量模拟现实世界推理机制方面的有效性。通过将LLMs视为通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下可以计算出PN和PS的合适近似值。本研究标志着朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在没有额外信息的情况下，准确识别这些噪声交互特别困难，主要原因在于缺乏明确的监督信号来标注噪音。大型语言模型（LLMs），凭借其丰富的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，将LLMs应用于序列推荐的去噪任务中带来了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即便经过微调，LLM的输出可靠性仍然存疑，特别是考虑到任务的复杂性和LLMs固有的幻象问题。  为了解决这些挑战，我们提出了LLM4DSR，这是一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，旨在激活LLMs识别噪声项目并提出替代建议的能力。此外，我们还开发了一个不确定性估计模块，确保仅采用置信度高的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，使得修正后的序列能灵活应用于多种推荐模型中。广泛的实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕获任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并汇总以形成层次化的LTL规范。这些规范随后被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次化推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的现实世界实验评估，我们证明了相较于现有方法，我们的方法能处理更复杂的指令。结果表明，我们的方法在多机器人任务分配和计划生成方面实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

## text2sql

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|null|翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对LLM驱动的NL2SQL技术的全面回顾，从以下四个方面覆盖其整个生命周期：（1）模型：解决NL模糊性、规范不足的同时，适当映射NL与数据库模式及实例的NL2SQL翻译技术；（2）数据：从训练数据的收集、因训练数据稀缺而进行的数据合成，到NL2SQL基准测试集；（3）评估：采用不同指标和粒度从多角度评估NL2SQL方法；以及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进一步发展。此外，我们还为开发NL2SQL解决方案提供了一套基本指南。最后，我们讨论了LLMs时代NL2SQL面临的研究挑战和开放问题。|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现完全自动化——包括数据查询、分析、可视化和报告——仍是一个复杂挑战。本研究介绍了一种名为SageCopilot的高级行业级系统，该系统通过整合大型语言模型（LLMs）、自动代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用两阶段设计：在线阶段利用上下文学习（ICL）细化用户输入为可执行脚本并运行这些脚本以生成结果报告与可视化；离线阶段则准备在线阶段ICL所需演示。该系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格测试和与基于提示的解决方案的对比分析，SageCopilot已被实证验证在生成或执行脚本及提供带有可视化的结果方面具有端到端的优越性能，并有真实世界数据集支持。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning，ICL）已被证明能有效提升大型语言模型（Large Language Models，LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转化为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器动态检索示例，但外部检索器与LLMs之间在表征能力上存在固有差异。此外，优化示例选择并非易事，因为缺乏直接方法可以在不进行成对推断的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们提出了一种代理分数，根据输出查询之间的相似性来估计示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最先进的基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为了解决这一问题，我们提出了一种多角度的NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情境下（如不同的数据领域和SQL特性）对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下鉴别出了一种有效的NL2SQL方法——SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现了竞争力强的性能。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术使不熟悉数据库的非专业用户能够使用SQL进行数据分析。将自然语言转换为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一种全面且高效的解决方案ChatBI，用于应对NL2BI任务。首先，我们分析了交互模式这一重要模块，这是NL2SQL与NL2BI在应用中的主要区别之处，并设计了一个更小、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而无法进行。BI场景中更高比例的列存在歧义性也使得模式链接变得困难。ChatBI结合了数据库社区现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列作为所需列输入到LLM进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，使得ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其融入多条产品线中，进行了大规模生产任务的评估。获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，在我们的实际BI场景数据表和查询下，与当前主流的NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进翻译，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而未能生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含来自不同数据库的已知NL2SQL翻译。LLMs能够从输入的示例中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（利用预训练模型检索提示以进行逻辑增强），该方法通过检索包含所需逻辑运算符组合的示例来进行NL2SQL任务，从而引导LLMs产生更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的完全集合匹配准确率和87.8%的执行匹配准确率，树立了新的状态-of-the-art性能。PURPLE在不同的基准、预算限制及多种LLMs上保持了高准确度，展现出鲁棒性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在上下文学习模型中选择示例至关重要。然而，仅基于查询的自然语言表达来评估结构相似性，而不考虑SQL查询，是一个重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为了实现这一目标，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。我们的全面评估表明，所提出的模型能有效捕获问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到了证实。尤其值得注意的是，我们的模型超越了来自OpenAI和Cohere的强大竞争性嵌入模型。此外，与这些竞争模型相比，我们提出的编码器在1-shot上下文学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进展集中在利用大语言模型（LLM）的上下文学习能力上，取得了显著成果。然而，这些方法在处理冗长的数据库信息和复杂用户意图时面临挑战。本文提出了一种两阶段框架，旨在提升基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示方式，称为参考增强表示，该表示包含了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，促使LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，有效浓缩有用信息。进入第二阶段，利用链接后的模式，我们简化提示中的模式信息，并指导LLM产出最终SQL。最后，作为后处理优化模块，我们建议采用跨LLM的一致性而非单个LLM内部的一致性作为评判标准。我们的方法在Spider基准测试上达到了新的最优水平，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们利用ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，该方法能够从查询的自然语言中提取相关模式作为输入上下文，以此来引导LLMs更准确地生成GQL。我们在两个构建于金融和医疗领域的图数据库——FinGQL和MediGQL上评估了我们的方法。实验结果显示，相较于一系列基线方法，我们的方法显著提高了性能，分别在精确匹配（EM）指标上提升了5.90和6.36绝对百分点，在 existence 匹配（EX）指标上提升了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资源。访问控制跨越两个领域：策略（组织级原则，定义谁应具有访问权限）和流程（数据库级原语，实际实施策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式，名为面向数据库的意图型访问控制（Intent-Based Access Control for Databases，简称IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix，NLACM）得到更精确的表达。数据库访问控制原语会根据这些NLACMs自动生成。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构，一个针对PostgreSQL的初始实现（我们称之为LLM4AC），以及初步的基准测试，用以评估此类系统的准确性和覆盖范围。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC在我们的初始Dr. Spider基准测试中显著优于其他基线，达到了高准确率和F1分数。在所有系统上，我们发现对于扩展的基准测试，包括需要外部知识的最先进NL2SQL数据和来自Amazon Access数据集的真实世界角色层次结构，整体性能均很高。|

## AIOps

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|在AIOps（面向IT运营的人工智能）时代，准确预测系统状态至关重要。在微服务系统中，这一任务面临着动态和复杂的空间-时间关系挑战，这主要归因于动态部署、多样的调用路径以及实例间的级联效应。当前的时间序列预测方法主要关注内在模式，在空间关系至关重要的环境中显得不足。同样，空间-时间图方法往往忽视了时间趋势的本质，更多地集中在节点间的消息传递上。此外，微服务领域的现有研究常常低估了网络指标和拓扑结构在捕捉系统动态演化中的重要性。本文提出了STMformer模型，该模型专为微服务环境中的系统状态预测而设计，能够处理多节点和多变量时间序列。我们的方法利用动态网络连接数据和拓扑信息来帮助建模系统内部复杂的空间-时间关系。此外，我们集成了PatchCrossAttention模块以全局计算级联效应的影响。基于微服务系统，我们构建了一个数据集，并对STMformer进行了全面的实验对比领先方法。在短期和长期预测任务中，我们的模型持续实现了8.6%的MAE（平均绝对误差）降低和2.2%的MSE（均方误差）减少。源代码可于https://github.com/xuyifeiiie/STMformer获取。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|**AIOps算法在微服务系统的维护中发挥着关键作用。许多先前基准测试的性能排行榜为选择合适算法提供了宝贵的指导。然而，现有的AIOps基准主要利用离线数据集来评估算法，无法持续使用实时数据集评估算法性能，并且评估的操作场景是静态的，这对于有效选择算法是不够的。为了解决这些问题，我们提出了一种评估一致性与场景导向的评估框架，名为MicroServo。其核心思想是构建一个实时微服务基准，以生成实时数据集，并持续模拟特定操作场景。MicroServo根据操作场景选择特定算法和数据集来支持不同的排行榜，同时支持多种类型算法的部署，实现算法的热插拔。最后，我们通过三个典型的微服务操作场景测试了MicroServo，以展示其效率和可用性。**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|大型语言模型（LLMs）和AI代理在软件开发与部署中的迅速应用正在革新信息技术领域。尽管代码生成受到广泛关注，但AI代理在云服务运营韧性方面的应用具有更高的影响力，目前这类服务需要大量的人力投入和专业知识。AIOps（AI for IT Operations）作为新兴热点，旨在通过自动化复杂运维任务，如故障定位和根本原因分析，来减少人工干预并降低对客户的影响。然而，实现自治和自愈合云的AIOps愿景受到缺乏构建、评估及改进AIOps代理标准化框架的阻碍。本论文旨在奠定此类框架的基础，首先明确需求，随后讨论满足这些需求的设计决策。我们提出了AIOpsLab原型实现，它利用代理-云接口来编排应用程序，通过混沌工程实时注入故障，并与代理接口以定位和解决这些故障。我们报告了有前景的结果，并为构建、评估及提升自治云所需的模块化、健壮框架奠定了基础。|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|**日志分析对于确保信息系统有序、稳定运行至关重要，尤其在人工智能运维（AIOps）领域。大型语言模型（LLMs）在自然语言处理任务中展现出巨大潜力。在AIOps领域，它们在异常检测、故障根本原因分析、运维脚本生成及告警信息总结等任务上表现出色。然而，当前LLMs在日志分析任务中的性能尚缺乏充分验证。为解决这一缺口，我们引入了LogEval——首个全面的基准测试套件，旨在首次评估LLMs在各种日志分析任务中的能力。该基准涵盖了日志解析、日志异常检测、日志故障诊断和日志总结等任务。LogEval利用4,000条公开的日志数据条目对每个任务进行评估，并为每个任务采用15种不同的提示，以确保评估的深入与公正。通过严格评估领先LLMs，我们展示了不同LLM技术对日志分析性能的影响，特别关注自一致性与少量样本上下文学习方面。同时，我们也讨论了模型量化、中英文问答评估及提示工程的相关发现。这些发现揭示了多语言环境下LLMs的强项与弱点，以及不同提示策略的有效性。针对不同任务采用多种评估方法，精准衡量LLMs在日志分析中的表现，确保了全面的评估。LogEval的评估洞察揭示了LLMs在日志分析任务中的优势与局限，为研究人员和实践者提供了宝贵的指导。**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|随着软件系统的日益复杂化，人工智能运维（AIOps）方法在软件系统故障管理中的应用越来越广泛，以确保大型分布式软件系统的高可用性和可靠性。然而，这些方法仍面临一些挑战，如跨平台通用性不足和跨任务灵活性欠缺。幸运的是，大型语言模型（LLMs）的最新进展能显著解决这些挑战，已有众多研究探索这一领域。但目前尚缺乏一份全面的综述来讨论基于LLM的AIOps与传统AIOps方法之间的差异。因此，本文提出了一个关于LLM时代故障管理AIOps技术的综合性调查。内容涵盖AIOps故障管理任务的详细定义、AIOps的数据来源，以及用于AIOps的LLM基方法。此外，本调查深入探讨了AIOps子任务、适用于不同AIOps子任务的具体LLM基方法，以及该领域的挑战与未来发展方向，旨在促进其进一步发展和应用。|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|**动态图中的异常边检测旨在识别与正常模式显著偏离的边，应用于网络安全、金融交易和AIOps等多个领域。随着时间的推移，异常边的类型不断涌现，而针对每种类型的标注异常样本却十分有限。现有方法要么旨在检测随机插入的边，要么需要大量标注数据进行模型训练，这限制了它们在实际应用中的适用性。本文针对这一问题，通过利用大型语言模型（LLMs）中丰富的知识进行协作，并提出了一种名为AnomalyLLM的方法。为了使动态图与LLMs对齐，AnomalyLLM预先训练了一个动态感知编码器以生成边的表示，并利用词嵌入原型重编程边。与编码器相配套，我们设计了一个基于上下文学习的框架，该框架整合了少量标注样本的信息，以实现少样本异常检测。在四个数据集上的实验表明，AnomalyLLM不仅能显著提升少样本异常检测的性能，还能在无需更新模型参数的情况下，对新出现的异常类型达到优异的检测效果。**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|我们推出了一款基于机器学习的异常检测产品——AI检测与响应（AIDR），它能够实时监控沃尔玛的业务和系统健康状况。在为期3个月的验证期间，该产品为超过25个应用、平台和运营团队提供了来自3000多个模型的预测，覆盖了63%的重大事件，并将平均检测时间（MTTD）缩短了超过7分钟。与以往的异常检测方法不同，我们的解决方案结合使用了统计学、机器学习和深度学习模型，同时继续融入基于规则的静态阈值，以吸纳领域特定知识。为了实现可扩展性和高可用性，我们通过分布式服务部署和维护了单变量及多变量的机器学习模型。AIDR具有反馈机制，利用漂移检测算法和客户反馈来评估模型质量，并且提供了自我接入能力和定制化功能。AIDR已成功应用于多个内部团队，相比以往方法实现了更短的检测时间和更少的误报。展望未来，我们旨在扩大事件覆盖范围和预防能力，减少噪音，并进一步与根本原因推荐（RCR）集成，以实现端到端的AIDR体验。|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|在云原生技术中，微服务架构日益增长的复杂性给维持系统稳定性和效率带来了重大挑战。为了对告警事件进行根本原因分析（RCA）和解决，我们提出了一种开创性的框架——面向微服务架构的根本原因分析多智能体区块链启发式协作（mABC），旨在革新人工智能运维（AIOps）领域。该框架下，多个基于强大大型语言模型（LLMs）的智能体依据智能体工作流程中的标准化任务和查询处理程序，采用区块链启发式的投票机制达成最终共识。具体而言，根据Agent Workflow设计的七种专业智能体各自利用其专长和内在软件知识的LLMs协作，形成一个去中心化的链条，共同为根本原因分析提供宝贵见解。为了避免LLMs潜在的稳定性问题，并充分利用去中心化结构中固有的透明和平等优势，mABC采纳了受区块链治理原则启发的决策过程，同时考虑每个智能体的贡献指数和专业指数。在公开基准AIOps挑战数据集和我们创建的火车票数据集上的实验结果显示，与以往的强基线相比，mABC在准确识别根本原因和制定有效解决方案方面表现出更优越的性能。进一步的消融研究突显了mABC各组成部分的重要性，其中智能体工作流程、多智能体协作以及区块链启发式投票对于达到最佳性能至关重要。mABC为微服务架构提供了一个全面的自动化根本原因分析与解决框架，在AIOps领域相对于现有基线实现了显著提升。|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|**大型语言模型（LLMs）在众多领域推动了新一轮的交互式AI应用浪潮。然而，由于生成模型的自回归特性，有效服务于LLM推理请求极具挑战性，因为它们的执行时间不可预测。现有的LLM服务系统采用先来先服务（FCFS）调度策略，这会遭受队头阻塞问题的影响。为了应对LLM的非确定性本质并实现高效的交互式LLM服务，我们提出了一种推测式最短作业优先（SSJF）调度器，它使用一个轻量级代理模型来预测LLM输出序列的长度。我们的开源SSJF实现无需对内存管理或批处理策略进行修改。在真实世界数据集和生产工作负载跟踪上的评估显示，与FCFS调度器相比，SSJF能将平均作业完成时间减少30.5%-39.6%，并将吞吐量提高2.2-3.6倍，这涵盖了无批处理、动态批处理和连续批处理等多种设置。**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|现代IT系统的管理带来了独特的挑战，要求在处理大量数据流时具备可扩展性、可靠性和效率。传统的依赖手动任务和基于规则方法在应对IT系统产生的大量数据量和警报时显得效率低下。为解决这一问题，人工智能操作系统（AIOps）应运而生，它利用机器学习和大数据等高级分析技术来加强事件管理。AIOps能够检测和预测事件、识别根本原因，并自动化执行修复操作，从而提升服务质量并降低运营成本。然而，尽管潜力巨大，AIOps领域仍处于初级阶段，分散于多个行业之中，并且缺乏统一的标准规范。目前，研究与产业界的贡献分布在各处，缺乏一致的数据管理框架、目标问题定义、实施细节、需求及能力标准。本研究提出了一套AIOps的术语和分类法，旨在建立一个结构化的事件管理流程，并为构建AIOps框架提供指导。研究还根据事件管理任务、应用领域、数据源和技术方法等标准对贡献进行了分类。其目标是全面回顾AIOps在事件管理中的技术与研究方面，旨在构建知识体系、识别研究空白，并为该领域的未来发展奠定基础。|

## PPC

| Publish Date | Title | Authors | PDF | Code | Abstract | 
|:---------|:---------------|:------|:------|:------|:--------------------|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|**联邦学习（FL）是一种增强隐私的技术，用于分布式机器学习。通过本地训练模型并聚合更新，联邦能够在不进行集中数据收集的情况下共同学习。FL在医疗、金融和个人计算领域日益受到欢迎。然而，它继承了经典机器学习中的公平性挑战，并由于数据质量差异、客户端参与度、通信限制、聚合方法及底层硬件差异引入了新的挑战。公平性仍然是FL中一个未解决的问题，社区已识别出缺乏简明的定义和指标来量化公平性；为应对这一问题，我们提出了联邦公平性分析方法论——一种衡量公平性的方法。我们的公平性定义包括四个概念，并配有新颖的相应指标。这些定义是针对问题症状提出的，并利用了源自可解释AI、合作博弈论和网络工程的技术。  我们在多种实验设置下进行了测试，改变了FL方法、机器学习任务和数据设置。结果表明，统计异质性和客户端参与度会影响公平性，而诸如Ditto和q-FedAvg等注重公平性的方法仅在一定程度上改善了公平性与性能之间的权衡。借助我们的技术，FL从业者能够揭示其系统公平性的前所未有的深入见解，包括不同粒度级别的见解，从而应对FL中的公平性挑战。我们的工作已在https://github.com/oscardilley/federated-fairness开源。**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|分布式太阳能发电系统的快速增长给配电系统规划和调度带来了挑战，主要问题在于无法直接观测到的居民侧（BTM）太阳能发电量。为了解决集中式机器学习方法在估计BTM太阳能发电量时的数据泄露问题，联邦学习（FL）方法因具备分布式学习能力而受到研究者的关注。然而，传统的FL方法面临着异构性、通信故障及恶意隐私攻击等多种挑战。针对这些挑战，本研究提出了一种通信鲁棒性和隐私安全性的分布式估算方法，专门用于处理社区级异构BTM太阳能发电量的估算问题。具体而言，本研究采用多任务联邦学习作为核心架构，旨在学习所有社区间的共性和独特特征。同时，研究嵌入了一种更新参数估计算法到多任务FL中，能够自动识别任意两个客户端之间的相似性，并为通信不可达的客户端估算更新参数，以此减轻通信故障带来的负面影响。最后，本研究在动态隐私预算分配策略下采用了差分隐私机制，以抵御恶意的隐私攻击并提升模型训练效率。案例研究表明，在存在异构性和通信故障的情况下，与传统FL和局部化学习方法相比，所提出的方案展现出更优的估算精度和收敛性能，同时提供了更强的隐私保护。|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|联邦学习是一种高效框架，旨在促进跨多个分布式设备的协作模型训练，同时保护用户数据隐私。联邦学习面临的主要挑战之一是数据层面的异质性，即私人数据的偏斜或长尾分布。尽管已提出多种方法来应对这一挑战，但大多数方法假设全局数据在所有客户端上呈均匀分布。本文研究了数据层面异质性的联邦学习，并通过简要回顾重新定义了一个更为实际且具有挑战性的场景，称为偏斜异构联邦学习（Skewed Heterogeneous Federated Learning，简称SHFL）。相应地，我们提出了一种新颖的联邦原型校正与个性化方法，该方法包含两部分：联邦个性化和联邦原型校正。前者旨在基于私人数据，在主导类和少数类之间构建平衡的决策边界，而后者则利用类别间辨别性和类别内一致性来校正经验原型。在三个流行基准上的实验表明，所提出的方案优于当前最先进的方法，并在个性化与泛化性能上均实现了均衡。|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|住房与无家可归者关爱系统（HHSC）的首要任务是将无家可归者与支持性住房连接起来。该系统通常包含众多服务于同一人群的机构。由于各机构间的信息技术平台在类型和质量上存在差异，它们的数据往往是彼此孤立的。较大的机构可能拥有足够的数据来训练和测试人工智能（AI）工具，而较小的机构通常不具备这样的条件。为了解决这一差距，我们引入了一种联邦学习（FL）方法，使所有机构能够协作训练预测模型，同时无需共享其敏感数据。我们展示了如何在HHSC内部应用FL，以使所有机构都能平等地访问高质量的AI，并进一步协助人类决策者在系统内更有效地分配资源。这一过程在不未经个人同意的情况下共享识别信息，从而保护了数据中的个人隐私。利用来自加拿大阿尔伯塔省卡尔加里的真实世界HHSC数据进行的实验结果显示，我们的FL方法在性能上可与理想情况相媲美，即在机构间完全共享并链接数据的情况下训练预测模型。|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|联邦学习（FL）通过协同训练机器学习模型，为个人数据提供了更强的隐私保护。当联邦学习参与者行使“被遗忘权”，即脱离已参与的FL框架并移除其对全局模型的过往贡献时，FL解决方案应执行所有必要步骤以实现该目的，同时不牺牲全局模型的整体性能，而当前最先进的相关方案尚不支持这一功能。本文提出了一种名为FedQUIT的新算法，利用知识蒸馏技术从FL全局模型中抹去待遗忘数据的贡献，同时保持其泛化能力。FedQUIT直接在客户端设备上运行，与常规FL过程相比，无需共享额外信息，也不假设存在公开可用的代理数据。我们的解决方案高效、有效，适用于集中式和联邦式两种设置。实验结果表明，平均而言，FedQUIT在遗忘后恢复泛化性能所需的额外通信轮次不到2.5%，得到的经过净化的全局模型其预测效果可与从未接触待遗忘数据的全局模型相媲美。|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|物联网（IoT）设备在多个领域的迅速普及引发了严重的网络安全问题，这促使了基于机器学习（ML）的入侵检测系统（IDS）在网络安全攻击分类方面的持续研究。传统ML模型需要将数据从IoT设备传输到集中式服务器进行流量分析，这引发了严重的隐私担忧。为了解决这一问题，研究人员已经研究了联邦学习（FL）基于的IDS，它能够在保持数据本地化的同时，在IoT设备间训练模型。然而，由于设备的不同漏洞和攻击向量的复杂性所导致的数据异质性，对FL模型的有效性构成了重大挑战。当前的研究虽然侧重于在FL框架内调整各种ML模型，但未能有效解决设备间攻击类别不平衡的问题，这一问题显著降低了少数攻击的分类准确性。为克服这一挑战，我们引入了FedMADE，一种新颖的动态聚合方法，它根据设备的流量模式对其进行聚类，并根据其对整体性能的贡献来聚合局部模型。我们通过与针对非独立同分布（non-IID）数据设计的其他FL算法进行对比评估，发现FedMADE能将少数攻击的分类准确率提高高达71.07%。此外，我们还展示FedMADE对中毒攻击具有鲁棒性，并且在每次通信轮次中相比FedAvg仅增加4.7%（5.03秒）的延迟开销，同时不增加IoT设备的计算负担。|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|卫星任务设计正经历从传统的单一大型卫星向由多颗小型卫星组成的分布式任务配置的范式转变。随着目前轨道上部署的这类卫星数量迅速增加，每颗卫星都在收集大量数据，对轨上边缘计算的兴趣日益增长。联邦学习是一种有前景的分布式计算方法，在此背景下，可使多颗卫星高效协作，进行船上机器学习模型的训练。尽管最近关于在轨道边缘计算中使用联邦学习的研究主要集中在同质卫星星座上，但联邦学习同样可以应用于异构卫星之间的临时协作场景，例如由不同运营商运行的通信卫星。此类应用向联邦学习范式提出了额外挑战，这些挑战主要源于系统的异构性。在这篇立场论文中，我们针对跨供应商应用场景，系统地回顾了这些挑战，对每一项挑战的现状进行了简要概述，并为深入探讨每个问题提供了入口。|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|分布式联邦学习（FL）范式基于区块链架构构建，利用分布式节点集群替代单一服务器执行FL模型聚合，旨在解决原始FL中集中式恶意服务器的脆弱性问题，并继承了区块链所提供的可信度和健壮性。然而，现有的区块链支持方案在模型保密性和区块链执行大规模FL计算的有限计算资源方面面临挑战。本文提出了Voltran这一创新混合平台，旨在通过可信执行环境（TEE）与区块链技术的结合，为基于FL的学习实现信任、保密性和健壮性的目标。我们将在TEE中卸载FL聚合计算，以提供一个隔离的、可信且可定制的链下执行环境，并随后确保聚合结果在区块链上的真实性和可验证性。此外，我们通过引入多SGX并行执行策略来分摊大规模FL工作负载，从而为多种FL场景提供了强大的可扩展性。我们实现了Voltran的原型，并进行了全面的性能评估。广泛的实验结果表明，Voltran在保证信任、保密性和真实性的同时，仅产生最小的额外开销，并且与最先进的密文聚合方案相比，显著加速了计算过程。|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|联邦学习（FL）是一种分布式机器学习方法，它使设备能够在不共享本地数据的情况下协作训练模型，从而确保用户隐私和可扩展性。然而，将FL应用于现实世界数据面临着挑战，特别是因为现有的大多数FL研究集中在单模态数据上。多模态联邦学习（MFL）应运而生，旨在解决这些挑战，利用模态特定的编码器模型来处理多样化的数据集。当前的MFL方法通常统一地分配所有模态的计算频率，这对于资源有限的物联网设备而言效率低下。在本文中，我们提出了FlexMod，这是一种新颖的方法，通过根据各模态编码器的重要性和训练需求自适应地分配训练资源，以增强MFL中的计算效率。我们采用原型学习来评估模态编码器的质量，使用Shapley值来量化每个模态的重要性，并采纳深度强化学习中的深度确定性策略梯度（DDPG）方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化模型性能和资源利用。在三个真实世界数据集上的实验结果表明，我们提出的方法显著提高了MFL模型的性能。|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|分布式健康智能网络（DHIN）是一个理论框架，旨在解决因医疗数据在各提供者与机构间碎片化而导致的健康数据主权和人工智能在医疗领域应用的重大挑战。该框架首先确立了医疗服务的主权架构作为主权健康网络的前提条件，随后通过克服访问多样化医疗数据源的障碍来促进人工智能的有效利用。这一综合框架利用以下三个核心要素：1）结合个人健康记录（PHR）的自我主权身份架构，作为实现健康数据主权的基础；2）在公共区块链上实施的可扩展联邦学习（FL）协议，用于去中心化的医疗人工智能训练，其中健康数据保留在参与者手中，仅模型参数更新被共享；3）一个可扩展且无需信任的奖励机制，激励参与并确保奖励公平分配。此框架确保没有任何实体能够阻止或控制对参与者提供的健康数据进行训练的访问，或决定经济利益，因为这些过程都在具有不可篡改记录的公共区块链上操作，无需第三方介入。它支持在医疗领域进行有效的人工智能训练，使患者能够保持对其健康数据的控制，获得经济利益，并为利用集体人工智能开发有益于医疗保健的算法贡献于一个去中心化、可扩展的生态系统。作为参与联邦学习协议的激励，患者会收到数字钱包中的奖励，长期规划是为去中心化保险解决方案提供资金支持。这种方法引入了一种新颖的自筹资金医疗模式，该模式适应个人需求，补充现有体系，并重新定义了全民医保的概念。它强调了转变医疗数据管理和人工智能应用潜力的同时，增强了患者的自主权。|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|null|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

