[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.20
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems**|Qian Wang et.al.|[2408.09955](http://arxiv.org/abs/2408.09955)|null|随着大型语言模型（LLMs）的兴起，LLM驱动的多智能体系统（LLM-MA系统）被提出以应对现实任务。然而，这些系统的智能体大多遵循预先定义的标准操作程序（SOPs），在交互过程中保持不变，缺乏自主性和可扩展性。此外，当前解决方案往往忽视了有效智能体协作的必要性。为了解决上述局限性，我们提出了MegaAgent框架，一个专为大规模LLM智能体系统中的自主协作设计的实用框架。MegaAgent利用智能体的自主性，根据任务需求动态生成智能体，融入了自动任务分配、系统性规划与监控智能体活动以及管理并发操作等功能。此外，MegaAgent采用层次化结构并利用系统级并行性来增强性能和加速通信。我们通过五子棋游戏开发演示了MegaAgent的有效性，表明它优于流行的LLM-MA系统；并通过国家政策模拟展示了其高度自主性及快速扩展至590个智能体的能力，同时确保它们之间的有效协作。我们的结果显示，MegaAgent是首个无预定义SOP、高效且可大规模扩展的自主大型LLM-MA系统，为该领域的进一步研究铺平了道路。我们的代码位于https://anonymous.4open.science/r/MegaAgent-81F3。|
|**2024-08-19**|**GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making**|Arsham Gholamzadeh Khoee et.al.|[2408.09785](http://arxiv.org/abs/2408.09785)|null|在汽车行业中，传统的软件部署决策方法通常依赖于手动分析软件测试的表格数据。这些方法因其劳动密集型特性，常常导致成本增加和软件发布周期的延迟。大型语言模型（LLMs）为解决这些挑战提供了有前景的方案。然而，它们的应用通常需要多轮人为驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠且高效结果的工业终端用户而言。在本文中，我们提出了GoNoGo，一个旨在简化汽车软件部署流程的同时满足功能需求和实际工业约束的LLM代理系统。与以往系统不同，GoNoGo特别针对领域特定和风险敏感系统进行了定制。我们利用来自工业实践的零样本和少量样本，对GoNoGo在不同任务难度下的性能进行了评估。结果显示，GoNoGo在使用3个样本的情况下，对于难度达到第2级别的任务实现了100%的成功率，并且即使面对更复杂的任务，也保持了较高的性能。我们发现，GoNoGo能有效自动化较简单任务的决策过程，大幅减少了人工干预的需求。总之，GoNoGo代表了一种高效且用户友好的基于LLM的解决方案，目前已被我们的工业合作伙伴公司采用，以辅助进行软件发布决策，支持对风险敏感的车辆系统发布过程中的更加明智且及时的决策。|
|**2024-08-18**|**HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model**|Mengkang Hu et.al.|[2408.09559](http://arxiv.org/abs/2408.09559)|**[link](https://github.com/hiagent2024/hiagent)**|**基于大型语言模型（LLM）的智能体在众多领域展现出巨大潜力，它们作为交互系统运作，处理环境观测以生成针对目标任务的可执行动作。这些智能体的有效性极大程度上取决于其记忆机制，该机制将历史经验记录为动作-观察对的序列。记忆可分为两类：跨试次记忆，横跨多次尝试累积；以及试次内记忆（工作记忆），在单次尝试中累积。尽管大量研究已通过优化跨试次记忆来提升性能，但通过改善工作记忆利用以增强智能体性能的研究仍不够深入。现有方法常常涉及将整个历史动作-观察对直接输入到LLMs中，这在长 horizon 任务中导致了冗余。受人类问题解决策略启发，本论文介绍了一种名为HiAgent的框架，它利用子目标作为记忆块来对LLM智能体的工作记忆进行层次化管理。具体而言，HiAgent促使LLMs在生成可执行动作前先制定子目标，并使LLMs能够主动决定用总结过的观察结果替换先前的子目标，仅保留与当前子目标相关的动作-观察对。跨五个长 horizon 任务的实验结果显示，HiAgent使成功率提高了两倍，并将所需的平均步数减少了3.8步。此外，我们的分析表明，HiAgent在不同步骤上持续提升性能，彰显了其稳定性和泛化能力。项目页面：https://github.com/HiAgent2024/HiAgent 。**|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLM）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应传感器数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、眼动追踪以及XR环境中的上下文记忆中隐式提取情境。这最大限度地减少了对人为设计的明确提示的依赖，促进了基于现实情境且直观的交互，从而为聊天机器人提供用户洞察。用户研究证明了我们方法的可行性及其在简化XR中用户与聊天机器人交互方面的变革性潜力，并为未来XR融合型LLM代理的设计提供了启示。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使设计过程复杂化，阻碍了BIM及基于模型设计在AEC（建筑、工程和施工）行业的普及。为更直观地表达设计意图，我们提出了Text2BIM框架，这是一个基于大型语言模型（LLM）的多智能体系统，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作与推理，将用户的文本输入转化为可执行代码，进而调用BIM创作工具的API，直接在软件内部生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，我们还在智能体工作流程中融入了基于规则的模型检查器，利用预定义的领域知识引导LLM智能体识别并解决生成模型中的问题，从而迭代提升模型质量。通过广泛实验，我们对比分析了三种不同LLM在所提框架下的性能。评估结果显示，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入的抽象概念保持一致。最后，我们开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的可能性。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练无法赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往通过在精心策划的专家演示上进行监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为了克服这些挑战，我们提出了一种框架，该框架结合了引导式蒙特卡洛树搜索（MCTS）与自我批评机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，该平台持续超越了行为克隆和强化微调基线，并在配备在线搜索能力时超越了人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升至81.7%（相对增长340%），在单天数据收集后，进一步提升至95.4%结合在线搜索。我们认为，这代表了自主代理能力的重大飞跃，为现实世界设置中更复杂和可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际软件工程（SWE）问题上展现出巨大潜力。目前最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的表现各异，有的任务表现出色，而在其他任务上则不尽人意。为了充分利用这些代理的独特优势，我们提出了多样性赋能智能（DEI）框架，旨在利用它们的专业能力。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅度超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上的最高个体解决率为27.3%，但在DEI的引导下，这一解决率可提升至34.3%，实现了25%的性能提升，并超过了大多数闭源解决方案。我们表现最优的代理组合更是达到了55%的解决率，在SWE-Bench Lite上位列榜首。我们的研究发现为协作AI系统解决复杂软件工程挑战的潜力提供了重要贡献。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力的候选者。受分层强化学习（HRL）启发，我们提出了一种新颖的框架——分层上下文强化学习（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即在运行时通过高层策略将复杂任务分解为子任务。这些子任务由目标定义，并分配给低层策略完成。一旦LLM代理判断目标达成，便会提出新的目标。为了提升代理在多回合执行中的表现，我们提出了事后模块化反思（HMR）方法，其中，代理不是对整个轨迹进行反思，而是将任务目标替换为中间目标，让代理针对较短的轨迹进行反思，以提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果显示，在5个执行回合中，与强大的基于上下文学习的基线相比，HCRL能实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工智能通用（AGI）。然而，在这些基于LLM的代理在实际世界中的规划任务中的行为、潜在失败原因及改进方法方面的研究还较为匮乏。为了填补这一空白，我们通过一个现实的基准测试——TravelPlanner，来展开研究。在此基准测试中，代理必须满足多重约束以生成准确的计划。我们利用这一基准来探讨四个关键研究问题：(1) LLM代理在涉及长篇幅和嘈杂背景信息的推理与规划任务中是否足够健壮？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化策略来改进计划质量？以及(4) 通过结合正面和负面反馈对LLM进行微调能否带来进一步的性能提升？  我们的综合实验结果显示：首先，尽管LLMs能够处理大量的参考信息和少样本示例，但在处理长上下文时，它们常常未能关注到关键信息；其次，它们在分析长篇计划时仍面临挑战，无法为计划的细化提供精确的反馈；最后，我们提出了一种反馈感知微调（FAFT）方法，该方法利用正负反馈结合的方式，相比仅使用监督微调（SFT），实现了显著的性能提升。我们的发现为关于真实世界规划应用的多个方面提供了深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大方法，它通过结合叙事技巧与可视化和文本传达洞察。这些故事融入了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释洞察的文本注释。然而，创建此类故事需要对数据有深刻理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种NLP任务上表现出色，但它们生成连贯、全面的数据故事的能力尚未得到充分探索。在本工作中，我们提出了一项新颖的数据故事生成任务及一个包含1,449个来自多样来源的故事的基准测试集。为应对构建连贯数据故事的挑战，我们设计了一个多智能体框架，采用两个LLM智能体来模拟人类讲故事的过程：一个负责理解和描述数据（反思），生成大纲和叙述，另一个则负责每一步的验证。尽管我们的智能体框架在基于模型和人类评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成的独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|深度学习（DL）模型，尤其是基于变换器架构的模型，已经彻底改变了众多DL应用领域，如大型语言模型（LLMs）、视觉变换器、音频生成和时间序列预测。这些进展很大程度上得益于分布式训练，然而，分布式通信仍然是训练进度的一个重大瓶颈。本文考察了变换器模型的通信行为，即在多节点/多GPU深度学习训练中，针对变换器架构使用不同的并行方案时如何进行数据通信。我们以基于GPT的语言模型作为变换器架构的案例研究，因为它们的普遍性。我们利用通信日志中的实证结果，并通过分析模型进行验证。总体而言，我们的分析揭示了进一步优化小型消息点对点通信的需求、序列长度、每GPU吞吐量、模型大小及所采用优化措施之间的关联，以及在框架和高性能计算中间件设计与优化中潜在的进一步优化方向。|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|序列推荐系统通过分析用户的过往交互来预测其下一个感兴趣项目，从而使推荐内容与个人偏好相吻合。近期方法利用大语言模型（LLMs）在知识理解和推理上的优势，通过语言生成范式将LLMs应用于序列推荐中。这些方法将用户行为序列转化为提示，以供LLM微调，并采用低秩自适应（LoRA）模块来优化推荐。然而，对不同用户行为统一应用LoRA有时无法捕捉个体差异性，导致性能欠佳及在迥异序列间产生负面迁移。针对这些挑战，我们提出了实例级LoRA（iLoRA），它将LoRA与专家混合（MoE）框架相结合。iLoRA创建了多样化的专家集合，每个专家捕获用户偏好的特定方面，并引入了由序列表示引导的门函数。该门函数处理历史交互序列以生成丰富表征，进而指导门网络输出定制化的专家参与权重。这一量身定制的方法缓解了负面迁移问题，并能动态适应多样的行为模式。在三个基准数据集上的广泛实验验证了iLoRA的有效性，特别强调了其在捕捉用户特定偏好和提升推荐准确性方面的优越表现。|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|近期的大型语言模型（LLMs）在以多种语言响应查询方面展现了非凡的能力，但它们处理长多语言上下文的能力尚未得到探索。因此，系统性地评估LLMs在多语言环境下的长上下文处理能力，特别是在信息检索的背景下，变得至关重要。为填补这一空白，我们引入了MultiLingual Needle-in-a-Haystack (MLNeedle)测试，旨在评估模型从多语言干扰文本（干草堆）集合中检索相关信息（针）的能力。该测试是对多语言问答任务的扩展，涵盖了单语和跨语言检索。我们在MLNeedle上对四种最先进的LLMs进行了评估。研究发现，模型性能会随着语言和针的位置显著变化。具体来说，我们观察到当针（相关信息）处于（i）英语语系之外的语言中以及（ii）输入上下文的中间位置时，模型的表现最差。此外，尽管某些模型声称其上下文大小为8000个令牌或更多，但随着上下文长度的增加，没有模型展现出令人满意的跨语言检索性能。我们的分析为理解LLMs在多语言设置下的长上下文行为提供了关键见解，以指导未来的评估协议。据我们所知，这是首次研究探索LLMs在多语言环境下的长上下文行为。|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|本研究展示了一种通过预训练大型语言模型（LLMs）的指令微调方法，以自动化生成AI研究排行榜，从文章中抽取（任务，数据集，指标，分数）四元组。该研究旨在通过从传统的手动社区整理或受分类约束的自然语言推理（NLI）模型，转向自动化的、基于LLM的生成方法，来加速AI研究成果的传播。利用FLAN-T5模型，此研究增强了LLMs在信息提取方面的适应性和可靠性，提供了一种结构化知识表示的新方法。|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|**分子性质预测是药物发现的重要基础。近年来，预训练深度学习模型已被广泛应用于这一任务。一些方法通过将先验生物学领域知识融入预训练框架，取得了显著成果。然而，这些方法严重依赖于生物化学专家，并且收集和归纳大量领域知识文献既耗时又昂贵。大型语言模型（LLMs）在理解和高效提供通用知识方面表现出了卓越性能。尽管如此，它们有时会出现幻觉，并且在生成领域特定知识时缺乏精确性。相反，领域特定小型模型（DSMs）拥有丰富的领域知识，能够准确计算与分子领域相关的指标。但由于其模型规模有限且功能单一，它们缺乏进行综合性表示学习所需的广泛知识。为了在分子性质预测中结合这两种方法的优势，我们提出了一种新颖的分子图表示学习框架，该框架融合了大型语言模型和领域特定小型模型（MolGraph-LarDo）。技术上，我们设计了一个两阶段提示策略，其中DSMs被引入以校准LLMs提供的知识，增强了领域特定信息的准确性，从而使LLMs能够为分子样本生成更精确的文本描述。随后，我们采用多模态对齐方法来协调不同模态，包括分子图及其对应的描述文本，以指导分子表示的预训练。广泛的实验验证了所提方法的有效性。**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|在多模态语言模型（MLMs）中，为了微调和对齐而手动标注高质量的图像-文本配对数据成本极高。现有的多模态数据增强框架虽提出了解决方案以增加图像-文本配对，但它们要么在文本与图像之间存在语义不一致性，要么生成不真实的图像，从而导致与现实世界示例之间的知识鸿沟。为解决这些问题，我们提出了基于属性的多模态数据增强方法（ARMADA），这是一种新颖的数据增强方法，通过在知识引导下操作提及实体的视觉属性来实现。具体而言，我们从原始文本数据中提取实体及其视觉属性，然后在知识库（KBs）和大型语言模型（LLMs）的指导下搜索这些视觉属性的替代值。随后，我们利用图像编辑模型根据提取出的属性来编辑图像。ARMADA作为一种新颖的多模态数据生成框架，其特点包括：(i) 从符号KBs中抽取知识支撑的属性以实现语义上一致且各具特色的图像-文本对生成，(ii) 利用KB层次结构中的相邻实体生成不同类别但视觉相似的图像，以及(iii) 利用LLMs的常识知识调节如背景等辅助视觉属性，以实现原始实体的更稳健表示。我们在四个下游任务上的实证结果证明了我们的框架能够生成高质量数据并提升模型性能，这同时也强调了为增强可解释性和现实世界联系而利用外部知识代理的重要性。|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|隐私研究因个人担忧其敏感数据在与智能设备、社交平台及AI应用交互中易遭泄露而广受关注。计算机科学领域研究者常通过针对特定领域的隐私攻击与防护来探究隐私问题。隐私研究覆盖多个子领域，如计算机视觉（CV）、自然语言处理（NLP）及计算机网络，各领域中隐私问题的表述各异。尽管先驱性工作揭示了敏感的隐私问题，但这些研究往往局限且未能全面涵盖人们实际的隐私忧虑。因此，关于综合性和以人为本的隐私研究仍待深入探索。  本文将隐私问题构型为推理问题，而非简单的模式匹配。我们基于情境完整性（Contextual Integrity, CI）理论，该理论认为人们对隐私的认知与相应社会情境紧密相关。基于此假设，我们制定了首个综合检查清单，涵盖了社会身份、私人属性及现行隐私法规。有别于以往CI研究仅限于有限的专家标注规范或模拟不完全的社会情境，我们提出的隐私检查清单以1996年《健康保险流通与责任法案》（HIPAA）为例，展示可通过大型语言模型（LLMs）全面覆盖HIPAA规定。此外，我们的检查清单还汇总了跨多个本体的专家注释，以确定包括但不限于个人识别信息（PII）在内的私人信息。我们利用对HIPAA的初步研究成果，为未来以情境为中心的隐私研究提供启示，旨在涵盖更多隐私法规、社会规范与标准。|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|GPU内存容量的增长速度未能跟上大型语言模型（LLMs）规模扩增的步伐，这对模型训练过程构成了阻碍。尤其是激活值——前向传播期间产生的中间张量，并在反向传播中被重用——在GPU内存使用中占主导地位。为了解决这一挑战，我们提出了TBA方法，该方法能高效地将激活值卸载到大容量的NVMe SSD上。TBA通过自适应地将数据传输与计算重叠，减少了GPU内存占用，同时不影响性能。它与PyTorch、Megatron和DeepSpeed等流行深度学习框架兼容，并采用张量重复数据删除、前传以及自适应卸载等技术进一步提高效率。我们在GPT、BERT和T5上进行了广泛的实验。结果显示，TBA有效减少了47%的激活值峰值内存使用。同时，TBA完美地将I/O操作与计算重叠，带来的性能开销可忽略不计。我们引入了重计算-卸载-保留（ROK）曲线，以比较TBA卸载策略与其他两种张量放置策略（保持激活值在内存中和逐层全重计算）的效果。我们发现，TBA在实现比逐层全重计算更好的内存节省的同时，还保持了将激活值保留在内存中的性能水平。|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|本研究探索了大型语言模型ChatGLM在自动生成国家教师资格考试（NTCE）结构化问题方面的应用潜力。通过精心设计的提示工程，我们引导ChatGLM生成了一系列模拟试题，并与过往考生回忆的真题进行了全面对比。为确保评估的客观性和专业性，我们邀请了教育领域的专家对这些问题及其评分标准进行评审。研究结果显示，ChatGLM生成的题目在大多数评价标准下展现了与真实考试题目的高度合理性、科学性和实用性相似的水平，彰显了该模型在题目生成上的准确性和可靠性。然而，研究也揭示了模型在生成题目时对某些评价维度考虑的局限性，表明还需进一步优化和调整。此项研究不仅验证了ChatGLM在教育测评领域的应用可能性，也为未来开发更高效、智能化的教育自动化生成系统提供了重要实证支持。|
|**2024-08-19**|**Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models**|Jiao Chen et.al.|[2408.09972](http://arxiv.org/abs/2408.09972)|null|大型语言模型（LLMs）在自动驾驶中的融合增强了开放世界场景下的个性化和适应性。然而，传统的边缘计算模型在处理复杂的驾驶数据时仍面临重大挑战，特别是在实时性能和系统效率方面。针对这些挑战，本研究引入了EC-Drive，一种新颖的具备数据漂移检测能力的边缘-云协同自动驾驶系统。EC-Drive利用漂移检测算法有选择地上传关键数据（如新障碍物和交通模式变化）至云端，由GPT-4进行处理，而常规数据则由边缘设备上的较小LLMs高效管理。这一方法不仅减少了推理延迟，还通过优化通信资源使用提升了系统效率。实验验证确认了该系统在真实驾驶条件下的强大处理能力和实际应用可行性，证明了这一边缘-云协作框架的有效性。我们的数据与系统演示将在https://sites.google.com/view/ec-drive公布。|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-04-02**|**LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**|Zhiyuan He et.al.|[2404.01617](http://arxiv.org/abs/2404.01617)|null|我们介绍了LLM-ABR系统，这是首个利用大型语言模型（LLMs）的生成能力来自行设计适应性比特率（ABR）算法的系统，旨在满足多样化的网络特性需求。LLM-ABR在强化学习框架内运作，使LLMs能够设计包括状态和神经网络架构在内的ABR算法关键组件。我们针对宽带、卫星、4G及5G等多种网络环境对LLM-ABR进行了评估。结果显示，LLM-ABR持续超越默认的ABR算法表现。|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-19**|**Carbon Footprint Accounting Driven by Large Language Models and Retrieval-augmented Generation**|Haijin Wang et.al.|[2408.09713](http://arxiv.org/abs/2408.09713)|null|碳足迹核算对于量化温室气体排放及实现碳中和至关重要。由于过程、核算规则、碳相关政策以及能源供应结构的动态变化性，对碳足迹核算（CFA）实施实时更新极为必要。传统生命周期评估方法严重依赖人类专业知识，使得近乎实时的更新面临挑战。本文提出了一种创新方法，该方法融合了大型语言模型（LLMs）与检索增强生成技术，旨在提升碳足迹信息检索与分析的实时性、专业性和经济性。通过利用LLMs的逻辑与语言理解能力，结合RAG的高效检索功能，所提出的LLMs-RAG-CFA方法能更有效地检索到有助于LLMs的专业信息，增强了模型的生成能力。此方法具备广泛的专业覆盖范围，能够高效实时地获取碳足迹信息并进行核算，且在不频繁更新LLMs参数的前提下实现了成本效益的自动化。跨五个行业（原铝、锂电池、光伏、新能源汽车及变压器）的实验结果表明，LLMs-RAG-CFA方法较传统方法及其他LLMs有显著优势，达到了更高的信息检索率，同时信息偏差与碳足迹核算偏差大幅降低。该经济可行的设计借助RAG技术平衡了实时更新与成本效益，为实时碳排放管理提供了高效、可靠且节省成本的解决方案，从而加强了环境可持续实践。|
|**2024-08-17**|**Developing a Llama-Based Chatbot for CI/CD Question Answering: A Case Study at Ericsson**|Daksh Chaudhary et.al.|[2408.09277](http://arxiv.org/abs/2408.09277)|null|本文介绍了我们在爱立信开发基于Llama的聊天机器人的经验，该机器人旨在回答关于持续集成和持续交付（CI/CD）的问题。爱立信是一家跨国电信公司，我们的聊天机器人针对爱立信CI/CD文档的具体特点进行设计，采用检索增强生成（RAG）模型来提高回答的准确性和相关性。通过在工业界CI/CD相关问题上的实证评估，我们发现结合了BM25和嵌入式检索器的集成检索器表现最佳。在针对爱立信的72个CI/CD问题及答案组成的地面真实数据集上进行评估时，我们最准确的聊天机器人配置能够为61.11%的问题提供完全正确的答案，为26.39%的问题提供部分正确的答案，而对于12.50%的问题提供了不正确的答案。通过对部分正确和不正确答案的错误分析，我们讨论了不准确性的根本原因并提供了进一步改进的见解。同时，我们也反思了学到的经验教训，并对未来如何进一步提升聊天机器人的准确性提出了方向。|
|**2024-08-17**|**TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems**|Xinke Jiang et.al.|[2408.09199](http://arxiv.org/abs/2408.09199)|null|在提升针对特定领域的大型语言模型（LLMs）性能的过程中，检索增强生成（RAG）作为一种有前景的解决方案，旨在缓解诸如虚构信息、知识陈旧及处理高度专业查询时专业知识有限等问题。然而，现存的RAG方法忽略了系统状态变量的重要性，这些变量对于实现自适应控制、检索终止及系统收敛至关重要。本论文通过严密论证，引入了TC-RAG这一创新框架，它通过整合图灵完备系统来管理状态变量，从而有效应对上述挑战，实现了更高效且精准的知识检索。TC-RAG利用带有自适应检索、推理及规划功能的内存堆栈系统，不仅确保了检索过程的可控终止，还通过Push和Pop操作减少了错误知识的累积。在医疗领域的案例研究中，我们在真实世界的医疗数据集上进行了大量实验，结果显示TC-RAG相比于现有方法，在准确性上提高了超过7.20%。我们的数据集和代码已开源，可访问https://github.com/Artessay/SAMA.git获取。|
|**2024-08-16**|**A Primer on Generative AI for Telecom: From Theory to Practice**|Xingqin Lin et.al.|[2408.09031](http://arxiv.org/abs/2408.09031)|null|生成式人工智能（GenAI）的兴起正在深刻改变电信行业。其中，大型语言模型（LLMs）作为GenAI的重要组成部分，已经崭露头角，成为推动创新、提升效率及优化客户服务的强大工具。本文从理论到实践，全面概述了GenAI在电信领域的应用。我们回顾了GenAI模型，并探讨了其在电信行业的实际应用场景。同时，文中阐述了有效实施GenAI于电信领域的关键技术促进因素与最佳实践。特别强调了检索增强生成（RAG）技术在连接LLMs与电信领域特定数据源方面的重要性，以此提升LLMs回应的准确性。文章通过一个基于RAG的聊天机器人实例，展示了其能有效解答开放无线接入网络（O-RAN）相关问题的能力。该聊天机器人在O-RAN联盟中的演示引发了业界的极大兴趣。为进一步推动技术共享，我们已将O-RAN RAG聊天机器人的源代码公开至GitHub平台。|
|**2024-08-16**|**Meta Knowledge for Retrieval Augmented Large Language Models**|Laurent Mombaerts et.al.|[2408.09017](http://arxiv.org/abs/2408.09017)|null|检索增强生成（Retrieval Augmented Generation，简称RAG）是一种技术，它通过添加上下文相关、时间敏感或领域特定信息来增强大型语言模型（Large Language Models，LLMs），而无需改变底层模型参数。然而，构建能够有效综合来自庞大且多样的文档集信息的RAG系统仍是一个重大挑战。我们介绍了一种针对LLMs的新型数据驱动的RAG工作流程，将传统的“先检索后阅读”系统转变为更先进的“先准备-再改写-再检索-后阅读”框架，以实现对知识库的更高层次的领域专家级理解。我们的方法依赖于为每份文档生成元数据和合成的问题与答案（QA），以及引入基于元数据的文档集群的新型概念——元知识摘要（Meta Knowledge Summary，MK摘要）。所提出的创新使用户查询个性化及深入信息检索横跨知识库成为可能。我们的研究做出了两大重要贡献：通过使用LLMs作为评估器并采用新的比较性能指标，我们证明了(1) 使用带有合成问题匹配的增强查询显著优于依赖于文档分块的传统RAG管道（p < 0.01），以及(2) 基于元知识的增强查询进一步显著提高了检索的准确性和召回率，以及最终答案的广度、深度、相关性和特异性。我们的方法成本效益高，使用Claude 3 Haiku处理2000篇研究论文的成本不到20美元，并且可以通过对语言模型或嵌入模型进行微调以进一步提升端到端RAG管道的性能。|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-16**|**Extracting polygonal footprints in off-nadir images with Segment Anything Model**|Kai Li et.al.|[2408.08645](http://arxiv.org/abs/2408.08645)|null|在非垂直视角的航拍图像中，建筑物足迹提取（BFE）通常依赖于屋顶分割和屋顶到足迹的偏移量预测，随后通过该偏移量将屋顶转换为足迹。然而，这种多阶段推断的结果在数据生产中并不适用，主要原因是预测给出的掩码质量较低。为了解决这一问题，本文提出了OBMv2方法，它支持端到端及可提示的多边形足迹预测。与OBM不同，OBMv2采用了一种新提出的自偏移注意力（SOFA）机制，旨在弥合平房与摩天大楼之间性能差距，实现了无需后处理的真实端到端足迹多边形预测。%为充分利用屋顶掩码、建筑掩码和偏移量中蕴含的信息，我们设计了多层次信息系统（MISS）用于足迹预测，使OBMv2即使在预测不足的情况下也能预测足迹。此外，为了从同一模型中榨取更多信息，我们受到自然语言处理领域中的检索增强生成（RAG）启发，提出了“BFE中的RAG”问题。为了验证所提方法的有效性，我们在开放数据集BONAI和OmniCity-view3上进行了实验，并在惠州测试集上进行了泛化能力测试。代码将可在\url{https://github.com/likaiucas/OBM}获得。|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535](http://arxiv.org/abs/2408.08535)|null|尽管大型语言模型（LLMs）和检索增强生成（RAG）系统取得了进展，但它们在事实核查中的有效性常受到限制，主要原因是对实体关系和社群结构的整合不足，从而影响了提供丰富上下文和准确信息检索的能力。我们引入了CommunityKG-RAG（社群知识图谱-检索增强生成）这一创新的零样本框架，它将知识图谱（KG）中的社群结构与RAG系统相结合，以增强事实核查过程。CommunityKG-RAG能够适应新领域和查询，无需额外训练，通过利用KG中社群结构的多跳特性，显著提高了信息检索的准确性和相关性。实验结果表明，CommunityKG-RAG相比传统方法表现更优，标志着在事实核查领域的一大进步，提供了一个强大、可扩展和高效解决方案。|
|**2024-08-16**|**MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering**|Zhengyuan Zhu et.al.|[2408.08521](http://arxiv.org/abs/2408.08521)|null|近期，在检索增强生成（RAG）领域取得的进展已在问答（QA）任务中展示了令人瞩目的性能。然而，大多数先前的工作主要集中在基于文本的答案上。尽管有些研究涉及多模态数据，但它们在生成全面的多模态答案方面仍显不足，尤其是在解释概念或提供如何完成特定目标的分步教程时。这种能力对于企业聊天机器人应用及客户服务体系、教育系统等场景尤为重要，其中答案来源于多模态数据。在本文中，我们引入了一个简单而有效的框架，名为MuRAR（多模态检索与答案精炼）。MuRAR通过检索相关多模态数据并精炼响应来增强基于文本的答案，从而创造连贯的多模态答案。该框架可轻松扩展，以支持企业聊天机器人的多模态回答，仅需最少的修改。人类评估结果表明，MuRAR生成的多模态答案相比纯文本答案更为有用和易于阅读。|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444](http://arxiv.org/abs/2408.08444)|**[link](https://github.com/jmnian/weak_label_for_rag)**|**在诸如开放领域问答（OpenQA）等知识密集型任务中，大型语言模型（LLMs）往往难以仅依赖其内部（参数化）知识生成事实性答案。为了解决这一局限性，检索增强生成（RAG）系统通过从外部来源检索相关信息来加强LLMs，从而使检索器成为关键组件。尽管密集检索展现出最先进的性能，但其训练由于缺乏地面真实证据而面临挑战，这主要归因于人工标注的高昂成本。在本文中，我们提出了W-RAG，利用LLMs的排序能力创建用于训练密集检索器的弱监督数据。具体而言，我们通过评估基于问题和每篇文档LLMs生成正确答案的概率，对BM25检索出的排名前-K的文档进行重排序。排名最高的文档随后被用作密集检索的正向训练样本。我们在四个公开可用的OpenQA数据集上的全面实验表明，我们的方法相比基线模型能同时提升检索和OpenQA性能。**|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422](http://arxiv.org/abs/2408.08422)|null|尽管大型语言模型（LLMs）在医学领域的整体能力令人印象深刻，但它们在诊断罕见疾病方面的表现仍存在疑问。为了回答这一问题，我们旨在评估LLMs在罕见疾病诊断中的性能，并探索提升其在这一领域有效性的方法。在此工作中，我们引入了一个罕见疾病问答（ReDis-QA）数据集，用于评估LLMs在诊断罕见疾病方面的表现。具体而言，我们收集了1360个高质量的问答对，涵盖了205种罕见疾病。此外，我们为每个问题添加了元数据注释，便于根据特定疾病及其属性提取子集。基于ReDis-QA数据集，我们对几种开源LLMs进行了基准测试，揭示了这些模型在诊断罕见疾病方面仍面临重大挑战。  为了促进针对罕见疾病诊断的检索增强生成，我们收集了首个罕见疾病语料库（ReCOP），该语料库源自国家罕见疾病组织（NORD）数据库。具体来说，我们将每种罕见疾病的报告分成多个部分，每部分代表疾病的不同属性，包括概述、症状、成因、影响、相关疾病、诊断和标准疗法。这种结构确保了各部分内容与问题的一致对应。实验结果表明，ReCOP能有效提高LLMs在ReDis-QA数据集上的平均准确率8%。尤为重要的是，它显著引导LLMs生成可信赖的答案及解释，这些答案和解释均可追溯至现有文献。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|**[link](https://github.com/hkustdial/nl2sql_handbook)**|**翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对LLM驱动的NL2SQL技术的全面回顾，从以下四个方面覆盖其整个生命周期：（1）模型：解决NL的模糊性和规范不足的同时，适当映射NL与数据库模式和实例的NL2SQL翻译技术；（2）数据：从训练数据的收集，到因训练数据稀缺而进行的数据合成，再到NL2SQL基准测试；（3）评估：使用不同指标和粒度从多个角度评估NL2SQL方法；以及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进化。此外，我们为开发NL2SQL解决方案提供了一条经验法则。最后，我们讨论了LLMs时代NL2SQL的研究挑战和开放问题。**|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现完全自动化——包括数据查询、分析、可视化及报告制作——仍是一个复杂的挑战。本研究介绍了一款名为SageCopilot的先进工业级系统，该系统通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用了一个双阶段设计：在线阶段利用上下文学习（ICL）细化用户输入为可执行脚本并运行这些脚本以报告结果及生成可视化内容；离线阶段则根据在线阶段ICL的需求准备演示。该系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格的测试和与基于提示的解决方案的比较分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面能实现端到端的卓越性能，其验证基于真实世界数据集。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证实能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器来动态检索示例，但外部检索器与LLMs之间的表征能力存在固有差异。此外，优化示例选择并非易事，因为缺少直接方法在不进行成对推断的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们设计了一种代理评分，根据输出查询间的相似性来估算示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为解答这一问题，我们提出了一种多角度NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。借助NL2SQL360，我们在不同的应用情景下（例如，不同的数据领域和SQL特性）对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别出针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下鉴别出了一种有效的NL2SQL方法——SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现了竞争力强的性能。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术让不熟悉数据库的非专业用户也能利用SQL进行数据分析。将自然语言转换为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项综合且高效的解决方案ChatBI，专门应对NL2BI任务。首先，我们分析了交互模式这一关键模块，这是NL2SQL与NL2BI在应用中的主要区别之处，并设计了一个更精简、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而难以进行。BI场景中更高比例的列义模糊性也加剧了模式链接的难度。ChatBI结合了数据库领域现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列作为所需列输入到LLM中进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，使ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其融入多条产品线中，进行了大规模生产任务的评估。所获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，在我们的真实BI场景数据表和查询下，与当前主流NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进转换过程，重点在于增强对用户意图的理解。然而，由于在组织复杂逻辑运算符组合方面的知识欠缺，LLMs有时无法生成合适的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含了来自不同数据库的已知NL2SQL转换。LLMs能够从输入的示例中学习如何为当前任务组织逻辑运算符组合。在本文中，我们提出了PURPLE（利用预训练模型检索提示以进行逻辑增强），该方法通过检索包含所需逻辑运算符组合的示例来改善NL2SQL任务的准确度，从而指导LLMs产生更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了新的最佳性能，实现了80.5%的精确集匹配准确率和87.8%的执行匹配准确率。PURPLE在不同的基准、预算限制及多种LLMs上保持了高准确度，展现出其稳健性和成本效益性。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取实例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性，是一个不小的挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来精确估计它。为了实现这一目标，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。全面的评估显示，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到了证实。尤其值得一提的是，我们的模型胜过了来自OpenAI和Cohere的强竞争力的嵌入式模型。此外，与这些竞争模型相比，我们提出的编码器在1次射击的情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期文本到SQL（Text2SQL）领域的进步着重于利用大语言模型（LLM）的上下文学习能力，取得了显著成效。然而，这些方法在处理冗长的数据库信息和复杂用户意图时仍面临挑战。本文提出了一种两阶段框架，旨在提升基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示方式——参考增强表示法，该方法整合了架构信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以执行架构链接，此步骤能有效浓缩有用信息。进入第二阶段，借助已链接的架构，我们简化提示中的架构信息，并指示LLM产出最终SQL。最后，作为后处理优化模块，我们建议采用跨LLM的一致性校验，取代单一LLM内部的自一致性策略。我们的方法在Spider基准测试上达到了新的最佳状态，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们借助ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，该方法能够从查询的自然语言中抽取相关模式作为输入上下文，以此引导LLMs生成准确的GQL语句。我们在两个构建于金融和医疗领域的图数据库——FinGQL和MediGQL上对该方法进行了评估。实验结果显示，相较于一系列基线方法，我们的方法显著提高了性能，分别在精确匹配（EM）指标上提升了5.90和6.36绝对百分点，在 existence 匹配（EX）指标上提升了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资源。访问控制跨越两个领域：策略（组织级原则，定义谁应具有访问权限）和流程（数据库级原语，实际实施策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式——面向数据库的意图驱动访问控制（Intent-Based Access Control for Databases，简称IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix，NLACM）得以更精确地表达。数据库访问控制原语会根据这些NLACMs自动生成。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（称为LLM4AC），以及评估此类系统准确性和覆盖范围的初步基准。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC极大地超越了其他基线，在我们的初始Dr. Spider基准测试中达到了高准确度和F1分数。在所有系统上，我们发现扩展基准测试的整体性能优异，这些测试包括需要外部知识的最先进NL2SQL数据，以及来自Amazon Access数据集的真实世界角色层次结构。|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Federated Frank-Wolfe Algorithm**|Ali Dadras et.al.|[2408.10090](http://arxiv.org/abs/2408.10090)|null|近年来，联邦学习（FL）因能构建隐私保护的协同学习系统而备受关注。然而，针对受约束的机器学习问题的FL算法仍有限，特别是在投影步骤成本较高时。针对这一挑战，我们提出了一种联邦Frank-Wolfe算法（FedFW）。FedFW具有数据隐私保护、每迭代步成本低以及通信信息稀疏等特点。在确定性设置下，FedFW对于光滑凸目标能在 $O(\varepsilon^{-2})$次迭代内达到$\varepsilon$-次优解，而对于光滑非凸目标，则需$O(\varepsilon^{-3})$次迭代。此外，我们还提出了一种随机变体的FedFW，并证明在凸设定下，该算法能在$O(\varepsilon^{-3})$ 次迭代内找到解。我们通过多个机器学习任务的实验验证了FedFW的实用性。|
|**2024-08-19**|**Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing**|Vinit Hegiste et.al.|[2408.10024](http://arxiv.org/abs/2408.10024)|null|在联邦学习（FL）领域，特别是在制造业中，为服务器聚合选择客户端权重的策略对于模型性能至关重要。本研究考察了两种权重选择策略的相对有效性：最终轮权重选择（FEWS）和最优轮权重选择（OEWS）。针对制造业合作通常涉及有限合作伙伴（两到四个客户端）的场景，我们的研究聚焦于联邦图像分类任务。采用EfficientNet、ResNet和VGG等多种神经网络架构，评估这些权重选择策略对模型收敛性和鲁棒性的影响。研究旨在确定在通信轮次（CR）中，FEWS或OEWS哪一种能更有效地提升全局FL模型的性能。通过实证分析和严谨实验，我们力求为优化制造业中的FL实施提供宝贵见解，确保协作努力能产生最有效和可靠的模型，并且参与客户端数量有限。本研究的发现预计将显著改进制造业中的FL实践，从而增强这一关键领域中协作机器学习努力的效率和性能。|
|**2024-08-19**|**Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets**|Xingrun Yan et.al.|[2408.09762](http://arxiv.org/abs/2408.09762)|null|在实际的联邦学习（FL）系统中，客户端与参数服务器（PS）间传递模型参数的通信开销常常成为瓶颈。层次化联邦学习（HFL）通过在客户端与PS之间设置多级边缘服务器（ESs）部分缓解了这一问题，但仍需在PS处聚合来自多个ES的模型参数。为了进一步降低通信开销，我们首次将顺序联邦学习（SFL）引入HFL中，该方法取消了中心PS，使得模型训练可通过每轮迭代时仅在两个相邻ES间传递全局模型来完成，并提出了一种适应此组合框架的新型算法，称为Fed-CHS。在不同数据异质性设定下，针对强凸和非凸损失函数，我们推导了收敛性结果，表明其收敛性能可与仅采用HFL或SFL的算法相媲美。实验结果进一步证实了所提Fed-CHS算法在节省通信开销和提高测试精度方面相对于基线方法的优越性。|
|**2024-08-18**|**Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment**|Tatjana Legler et.al.|[2408.09556](http://arxiv.org/abs/2408.09556)|null|联邦学习（FL）作为一种在保护数据隐私的同时跨分散数据源训练机器学习模型的有前景方法，尤其在制造业和共享生产环境中的应用日益凸显。然而，不同客户端和生产场所间存在的数据异质性——包括数据分布、质量和数量上的差异——对FL的有效性和效率构成了重大挑战。本文针对制造业背景下的FL，全面概述了异质性的各类表现及来源，涉及非独立同分布（non-IID）数据、不平衡数据、可变数据质量和统计异质性等。我们探讨了这些异质性类型对模型训练的影响，并回顾了当前缓解其负面影响的方法论，如个性化与定制化模型、健壮的聚合技术以及客户端选择策略。通过综合现有研究并提出新的策略，本文旨在为有效管理FL中的数据异质性提供洞见，增强模型的鲁棒性，并确保在多样化的环境下实现公平且高效的训练。同时，本文也指出了未来研究方向，强调了开发适应性强和可扩展解决方案的需求，以进一步提升FL范式在工业4.0背景下的应用效果。|
|**2024-08-18**|**Seamless Integration: Sampling Strategies in Federated Learning Systems**|Tatjana Legler et.al.|[2408.09545](http://arxiv.org/abs/2408.09545)|null|联邦学习（Federated Learning, FL）在机器学习领域标志着一种范式转变，它提供了一种分散训练模型的方法，使模型能够在保持本地数据隐私的同时，跨多设备进行学习。然而，FL系统的动态特性，特别是持续纳入具有潜在多样性数据分布和计算能力的新客户端，对这些分布式学习网络的稳定性和效率构成了重大挑战。无缝融入新客户端对于维持和提升FL系统的性能及鲁棒性至关重要。本文深入探讨了将新客户端整合进现有FL系统所面临的复杂性，以及它们之间的数据异质性和不同数据分布（非独立同分布）如何影响模型训练、系统效率、可扩展性和稳定性。尽管存在这些挑战，新客户端的整合也为FL系统带来了增强数据多样性、提升学习性能及利用分布式计算能力的机遇。与最初应用于诸如Gboard上的单词预测分布式优化等场景不同，生产环境中的客户端数量通常较少，这使得每个新客户端的信息变得更加宝贵。本文概述了有效的客户端选择策略及确保系统可扩展性和稳定性的解决方案，并以光学质量检验图像为例，提供了实践方法的见解。总之，本文提出，应对新客户端整合带来的挑战对于分布式学习网络的进展和效率至关重要，从而为联邦学习在生产环境中的应用铺平道路。|
|**2024-08-18**|**Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets**|Shiyuan Zuo et.al.|[2408.09539](http://arxiv.org/abs/2408.09539)|null|在实际的联邦学习（FL）系统中，恶意拜占庭攻击和数据异质性的存在常常给学习过程引入偏见。然而，现有的拜占庭鲁棒方法通常只在适应不同损失函数类型（包括强凸和非凸）与对抗数据异质性之间取得折衷，但存在非零最优性差距。此外，这种折衷往往以聚合时高计算复杂性为代价，极大地减慢了训练速度。为了解决这一挑战，我们提出了一种称为联邦规范化梯度算法（Fed-NGA）的联邦学习方法。Fed-NGA简单地将上传的局部梯度规范化为单位向量后再进行聚合，实现了 $\mathcal{O}(pM)$的时间复杂度，其中$p$代表模型参数的维度，$M$是参与客户端的数量。这一复杂度水平在所有现有的拜占庭鲁棒方法中达到最优。此外，通过严格的证明，我们展示Fed-NGA超越了现有文献中关于适应损失函数类型与数据异质性之间的折衷以及非零最优性差距的限制。具体而言，Fed-NGA能同时适应非凸损失函数和非独立同分布（non-IID）数据集，并以$\mathcal{O} (1/T^{\frac{1}{2} - \delta})$的速率实现零最优性差距，其中$T$是迭代次数，$\delta \in (0,\frac{1}{2})$ 。当损失函数为强凸时，实现零最优性差距的速率可提升至线性。实验结果进一步证实了我们提出的Fed-NGA在时间复杂度和收敛性能上相对于基线方法的优越性。|
|**2024-08-18**|**Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover**|Dong-Jun Han et.al.|[2408.09522](http://arxiv.org/abs/2408.09522)|null|偏远地区的设备通常缺乏来自完善地面通信基础设施的覆盖，这不仅限制了它们享受高质量通信服务的能力，也阻碍了在偏远地区提供机器学习服务。本文针对这一问题，提出了一种新的联邦学习（FL）方法论，该方法特别适用于天、空、地一体化网络（SAGINs）。我们的方法巧妙利用空间与空中层的节点作为（i）边缘计算单元和（ii）联邦学习过程中的模型聚合器，从而解决了地面设备计算能力有限以及目标区域缺少地面基站的挑战。本方法论的核心思想是采用适应性数据卸载和切换流程，该流程融入了SAGINs中的多种网络动态特性，包括移动性、异构计算能力以及过顶卫星不稳定的覆盖时间。我们分析了方案的延迟，并开发了一个适应性数据卸载优化器，同时刻画了所提算法的理论收敛界。实验结果验证了我们提出的SAGIN辅助联邦学习方法在训练时间和测试准确性方面相对于多种基线的优势。|
|**2024-08-18**|**Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training**|Huitong Jin et.al.|[2408.09478](http://arxiv.org/abs/2408.09478)|null|预训练利用公开数据集对先进机器学习模型进行预先训练，以便该模型能更容易地调整以适应各种下游任务。预训练已被广泛探索，以缓解计算和通信资源的消耗。受这些优势的启发，我们首次探讨了模型预训练如何减轻差分隐私联邦学习（DPFL）中的噪声损害。DPFL是从联邦学习（FL）升级而来，FL是当在拥有私人数据的多个客户端间训练模型时保护隐私的实际标准。DPFL通过引入差分隐私（DP）噪声来混淆FL中暴露的模型梯度，但这可能会显著损害模型准确性。在我们的工作中，通过全面的实证研究，我们将基于预训练的头部微调（HT）和全微调（FT）与从零开始训练（ST）在DPFL中的表现进行了比较。实验使用在ImageNet-1K上预训练获得的模型，并通过CIFAR-10、CHMNIST和Fashion-MNIST（FMNIST）数据集分别进行了调优。结果表明，HT和FT能够通过减少梯度暴露次数显著减轻噪声影响。特别是，在隐私预算紧张或模型尺寸较大时，HT的表现优于FT。可视化和解释性研究进一步证实了我们的发现。我们的开创性研究为增强DPFL及其实际应用的扩展引入了新的视角。|
|**2024-08-18**|**Federated Graph Learning with Structure Proxy Alignment**|Xingbo Fu et.al.|[2408.09393](http://arxiv.org/abs/2408.09393)|**[link](https://github.com/xbfu/fedspray)**|**联邦图学习（FGL）旨在对分布于多个数据持有者中的图数据学习图学习模型，已被应用于社交推荐和金融欺诈检测等多种场景。FGL继承了通用联邦学习（FL）的特点，同样面临数据异质性问题，即分布式图数据在不同客户端上的标签分布可能有显著差异。例如，某个客户端的图节点可能大多属于某一类别，而另一个客户端中属于同一类别的节点却很少。这一问题导致了分歧的局部优化目标，并妨碍了FGL在节点级任务上，尤其是节点分类任务的收敛性。此外，FGL还面临着一个独特的挑战：在客户端中属于少数类别的节点更可能拥有偏差性的邻域信息，这阻碍了FGL利用图神经网络（GNNs）学习到具有表达力的节点嵌入。为应对这一挑战，我们提出了FedSpray，一种新颖的FGL框架，它在潜在空间中学习局部类别-wise结构代理，并将其对齐以获得全局结构代理。我们的目标是获取对齐的结构代理，用作节点分类中可靠、无偏见的邻域信息。为了实现这一目标，FedSpray训练了一个全局特征-结构编码器，并利用结构代理生成无偏软目标，以个性化的方式规范各客户端GNN模型的本地训练。我们在四个数据集上进行了广泛实验，实验结果验证了FedSpray相比其他基线方法的优越性。代码可于https://github.com/xbfu/FedSpray获取。**|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227](http://arxiv.org/abs/2408.09227)|null|本研究提出了一项名为“联邦医学知识注入”（FEDMEKI）的平台新基准，旨在应对在隐私限制下将医学知识整合到基础模型的独特挑战。通过采用跨机构的联邦学习方法，FEDMEKI绕过了集中式数据收集的问题，这类收集方式常因健康法规（如美国的《健康保险流通与责任法案》即HIPAA）而受到禁止。该平台精心设计以处理多站点、多模态和多任务的医学数据，涵盖了7种医学模态，包括图像、信号、文本、实验室检测结果、生命体征、输入变量和输出变量。用于验证FEDMEKI的精选数据集涵盖了8项医学任务，包括6个分类任务（肺部不透明度检测、COVID-19检测、心电图（ECG）异常检测、死亡预测、败血症预测和心包纵隔扩大的检测）和2个生成任务（医学视觉问答（MedVQA）和ECG噪声澄清）。这一综合数据集被划分至多个客户端，以便在16种基准方法下促进去中心化的训练过程。FEDMEKI不仅保护了数据隐私，还通过允许基础模型从更广泛的医学知识中学习而不直接暴露数据，增强了其在医疗领域的功能，从而在医疗领域应用基础模型方面设立了新的基准。|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

