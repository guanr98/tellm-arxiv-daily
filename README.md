[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.19
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、视线聚焦和XR环境中的情境记忆中隐式提取上下文。这最大限度地减少了对人工设计的明确提示的依赖，促进了根植于实际情境且直观的交互，从而为聊天机器人提供用户的深入洞察。用户研究证明了我们方法的即将实现的可行性和变革潜力，它能简化XR中与聊天机器人的用户交互，同时为未来XR融合型LLM代理的设计提供了启示。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计师往往需要掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使得设计过程复杂化，并阻碍了AEC（建筑、工程和施工）行业对BIM及基于模型设计的采纳。为更直观地表达设计意图，我们提出了Text2BIM，一个基于LLM（大型语言模型）的多智能体框架，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作和推理，将用户的文本输入转化为调用BIM创作工具API的指令性代码，直接在软件中生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，框架的工作流程中融入了一套基于规则的模型检查器，利用预定义的领域知识引导LLM智能体解决生成模型中的问题，并通过迭代改进模型质量。我们进行了广泛实验，比较和分析了在所提框架下三种不同LLM的表现。评估结果显示，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入所指定的抽象概念相吻合。最后，开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个重大挑战。传统的静态数据监督预训练无法赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往通过在专家演示的监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为了克服这些挑战，我们提出了一种框架，该框架结合了引导式的蒙特卡洛树搜索（MCTS）、自我批判机制及利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，它在此持续超越了行为克隆和强化微调基线，并在配备在线搜索功能时超过了人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升到单日数据收集后的81.7%（相对增长340%），并通过在线搜索进一步提升至95.4%。我们相信，这代表了自主代理能力的重大飞跃，为现实世界环境中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的表现各异，有些任务表现出色，而在其他任务上则表现不佳。为了充分利用这些代理的独特优势，我们提出了多样性赋能智能（DEI）框架，它能利用它们的专业知识。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果表明，由DEI引导的代理委员会能够大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上的最大个人解决问题率为27.3%，而通过DEI可以达到34.3%的解决问题率，实现了25%的提升，并超过了大多数闭源解决方案。我们表现最佳的代理组合以55%的问题解决率，在SWE-Bench Lite上取得了领先地位。我们的发现为协作AI系统研究领域做出了贡献，进一步证明了其解决复杂软件工程挑战的潜力。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到分层强化学习（HRL）的启发，我们提出了一种新颖的框架——分层上下文强化学习（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即动态地将复杂任务分解为由低层策略完成的、以目标定义的子任务。一旦LLM代理判定目标达成，便会提出新的目标。为了提升代理在多回合执行中的性能，我们提出了“事后模块化反思”（HMR）方法，该方法不是对完整轨迹进行反思，而是将任务目标替换为中间目标，让代理对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了所提出的HCRL在决策能力上的表现。结果显示，在5个执行回合中，HCRL相比于强大的基于上下文学习的基线，能实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工通用智能（AGI）。然而，在这些基于LLM的代理在实际世界中的规划任务中的行为、潜在失败原因及改进方法方面的研究还较为匮乏。为了填补这一空白，我们通过一个现实的基准测试——TravelPlanner进行研究，其中代理必须满足多重约束以生成准确的计划。我们利用此基准测试来探讨四个关键研究问题：(1) LLM代理在涉及长期和嘈杂上下文的推理和规划任务中是否足够稳健？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的性能？(3) 我们能否依靠细化来改进计划，以及(4) 通过正负反馈相结合的微调方法是否能进一步提升LLM的表现？  我们的综合实验表明，首先，尽管LLMs能够处理大量参考信息和少样本示例，但它们往往未能关注到长上下文中的关键部分；其次，它们在分析长计划时仍面临挑战，无法为细化提供精确的反馈；第三，我们提出了一种反馈感知微调（FAFT）方法，该方法利用正负反馈结合，相较于监督微调（SFT）展现出显著的性能提升。我们的发现为涉及真实世界规划应用的多个方面提供了深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大的表达方式，它通过结合叙述技巧与可视化和文本传达深刻见解。这类故事融合了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释这些见解的文本注释。然而，创建这样的故事需要对数据有深入的理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种自然语言处理任务上表现出色，但它们生成连贯、全面的数据故事的能力尚未得到充分探索。在本工作中，我们引入了一项新颖的数据故事生成任务，并建立了一个包含1,449个来自不同来源的故事的基准数据集。为应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体，旨在模拟人类讲故事的过程：一个负责理解并描述数据（反思），生成大纲和叙述，另一个则负责每一步的验证。尽管我们的智能体框架在基于模型和人工评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成中的一些独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收到关于目标位置相对于知名地标语言描述的信息；仅依据对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间并无具体指引。该问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，其中地标往往不可见。在缺乏导航指示的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs针对每次观察做出“反应”并据此做出决策。然而，该基线表现欠佳，代理常反复访问同一位置，并做出短视、不连贯的决策。为解决这些问题，本文引入了一种新颖的代理工作流程，其特点是具备感知、反思与规划的能力。具体而言，我们发现LLaVA-7B模型可通过微调达到足够准确地感知地标的方向和距离，以支持城市导航。此外，通过一种记忆机制实现反思，过往经验得以存储，并能与当前感知结合，以便进行有效的决策论证。规划环节则利用反思结果来制定长期计划，从而避免在远距离导航中的短视决策。研究结果显示，设计的这一工作流程显著提升了基于LLM的代理相较于前沿基线的导航能力。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，各有显著缺点。基于相似性的检索在复杂任务中往往召回率低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的泛用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口集成。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索和代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个实际的编程应用场景。凭借统一的图数据库模式，CodexGraph在学术和现实世界环境中展示了竞争性的性能和潜力，彰显了其在软件工程中的多样性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法既费时又需要在通信、网络和优化领域具有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程方面，网络优化将迎来革新性途径。这一途径通过精心设计的提示来注入人类经验和知识到这些复杂的LLMs中，并部署自主智能体作为沟通桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合体现了未来人工智能（AI）即服务和AI促进简化操作的范式。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa）以及协同多LLM基底的自主BSS智能体（CLaBa）。通过实际数据的评估，实验表明，辅助提示的LLMs与基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提高了BSS优化的效率并减少了不必要的手动参与。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常颇具挑战性，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们迈出了一步，转向一个新任务：关注符号图形程序，这是图形内容的一种流行表示形式，可以程序化生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过它们回答与图形内容相关的问题的能力来表征LLMs对符号程序的理解。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过验证的人类实验表明，从相应的图形内容回答这些问题将很容易。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这项任务通过创建一个关于符号图形程序语义理解的大规模基准来评估LLMs，该基准通过程序-图形对应构建，因此需要最少的人力投入。我们在该基准上评估当前的LLMs，以初步揭示它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令调优（SIT）来提高这种能力。具体而言，我们向GPT4-o提出问题并使用符号程序生成的图像，这些数据随后被用来微调LLM。我们还发现，SIT数据能提升LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|高质量的数据对于大型语言模型的预训练性能至关重要。然而，现有的质量过滤方法依赖于已知的高质量数据集作为参考，这可能会引入潜在偏差并损害多样性。本文提出了一种名为ScalingFilter的新方法，该方法根据在同一数据上训练的两个语言模型之间的困惑度差异来评估文本质量，从而在过滤过程中消除了参考数据集的影响。理论分析表明，ScalingFilter等价于对规模法则的一种逆向利用。通过使用13亿参数的模型在同一数据源上，经由不同质量过滤器处理后的数据进行训练，我们发现ScalingFilter能够提升预训练模型在下游任务上的零样本性能。为了评估质量过滤引入的偏差，我们引入了语义多样性这一指标，利用文本嵌入模型进行语义表示。广泛实验揭示，语义多样性是数据集多样性的可靠指标，而ScalingFilter在下游性能与语义多样性之间实现了最优平衡。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理和控制问题样本。该数据集被人类专家用来评估各种商业及开源LLMs的表现，尤其是它们在解决交通运输工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致性行为。我们的研究标志着迈向利用人工通用智能应对复杂交通运输挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量假阳性，从而掩盖真实的异常。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能和成本效益日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前对日志进行聚类，从而使查询成本降低几个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|人类与模型的对话为我们提供了用户现实场景、行为和需求的窗口，因此是模型开发和研究的宝贵资源。尽管营利公司通过其模型的API收集用户数据，并将其用于内部改进自有模型，开源和研究社区在这方面的发展却相对滞后。我们推出了ShareLM集合，这是一组统一的人类与大型语言模型的对话数据集，以及一个配套的插件——一个允许用户自愿贡献与模型对话的网络扩展。鉴于少数平台会分享他们的聊天记录，ShareLM插件增加了这一功能，从而使得用户能够从大多数平台上分享对话。该插件允许用户在对话及其响应级别进行评级，并可在对话离开用户本地存储之前删除他们希望保持私密的对话。我们把插件收集到的对话作为ShareLM集合的一部分发布，并呼吁在开放的人机对话数据领域投入更多社区力量。代码、插件及数据均已公开。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时在多模态输入的分析判断与决策方面展现出可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低层次执行，同时观察并纠正任务执行过程中可能出现的失败。为了系统地评估该框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”和“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|混合专家（Mixture of Experts, MoE）框架因其在大型语言模型上表现出的优越性能而变得日益流行，相较于密集型模型具有明显优势。然而，在大规模环境下从零开始训练MoE模型成本高昂。现有的方法通过先独立预训练多个密集专家模型，并利用这些模型来初始化MoE以缓解这一问题。具体实现时，将各专家的前馈网络（Feed-Forward Network, FNN）用于初始化MoE中的专家层，同时合并其他参数。但这种方法仅限于复用密集模型的FNN层参数，限制了将这些模型“升级循环”为MoE时所能获得的优势。我们提出了一种简单而高效的方法BAM（Branch-Attend-Mix），旨在解决这一不足。BAM充分利用特化的密集模型，不仅利用其FNN来初始化MoE层，还通过将注意力参数全盘利用，将它们初始化到注意力混合（Mixture of Attention, MoA）层的一个软变体中，以此充分发挥前期训练的投资效益。  我们探索了两种升级循环注意力参数的方法：1) 从密集模型中单独初始化注意力专家，包括所有注意力参数，以实现最佳模型性能；2) 在所有专家间共享键（key）和值（value）参数，从而提高推理效率。为了进一步提升效率，我们采纳了并行注意力变换器架构应用于MoE中，使得注意力专家与FNN专家能够并行计算。我们在规模从5.9亿至20亿参数的种子模型上的实验表明，BAM不仅在困惑度上超越基线，在下游任务性能上同样表现更优，且在相同的计算资源和数据限制下达成此成就。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明了直接对LLMs与协同模型的表示进行对齐以增强下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效地在协同模型与LLMs之间对齐语义表示的问题仍未得到妥善解决。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享成分。随后，在共享表示上执行全局和局部结构对齐，以促进知识转移。此外，我们理论上证明了特定和共享表示含有更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于现有的先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法在七项上超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一套理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下可以计算出PN和PS的合适近似值。本研究标志着朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力常常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够以程序方式生成视觉数据。尽管LLMs在程序合成方面已展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过提问与图形内容相关的问题来衡量LLMs对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，如果直接查看对应的图形内容，人类可以轻松作答，我们通过实验对此进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染出的视觉内容。我们利用这项任务创建了一个针对符号图形程序语义理解的大规模基准测试，该测试通过程序-图形对应构建，因此需要最少的人力投入。我们在这一基准上评估了当前的LLMs，以初步揭示它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有LLMs，并且在推理方面表现良好的模型在此任务上的表现更佳。最后，我们引入了符号指令调优（SIT）来提升这一能力。具体而言，我们向GPT4-o提出问题并展示由符号程序生成的图像。此类数据随后被用于微调LLM。我们还发现，SIT数据能增进LLMs的通用指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新一代大型语言模型（LLMs），包括GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3以及Llama 3.1，在解决选定的本科层次交通工程问题方面的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通工程问题样本，这些问题涉及交通系统的规划、设计、管理和控制。该数据集被人类专家用来评估各种商业及开源LLMs的能力，特别是它们在解决交通工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，我们的分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致性行为。我们的研究标志着迈向利用人工通用智能应对复杂交通挑战这一激动人心的首步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排除和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量误报，掩盖真实的异常情况。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能、成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前聚类日志，从而使查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，定期更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并且在针对多模态输入进行分析性判断与决策方面展现出可用性。为了借助LLMs的力量促进人形移动操作，我们提出了一种基于语言模型的新型框架，使机器人能够根据给定的文字指令自主规划行为及低级执行过程，并在任务执行过程中观察及纠正可能出现的失败。为了系统地评估该框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用价值。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐对于增强下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效对齐两者间的语义表示仍是一个未解的挑战。受此观点启发，我们提出了一种新颖的即插即用对齐框架，用于LLMs与协同模型的结合。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享的成分。随后，在共享表示上执行全局和局部结构对齐，以促进知识转移。此外，我们理论上证明了特定和共享表示包含更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于现有最先进的算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了仅使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，目前了解尚少。为了探究针对某一观点的偏见程度，我们通过两项下游任务评估了隐性和显性社会群体知识的使用情况。首先，我们通过极端偏见场景下的压力测试评估，采用了一个带有偏见的模型。随后，我们评估了当面对与既有观点相冲突的情境时，大型语言模型（LLMs）在处理隐性和显性观点时的语言校准情况。研究发现，模型在识别隐性观点与显性观点上存在差异，且普遍倾向于放大与之对立的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比未经对齐（零样本）的基础模型显得更为谨慎。未对齐模型的直接且不加小心的回应表明，在处理高度主观且社会敏感的话题时，有必要通过融入不确定性标记来进一步优化其决断性的准确性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一套理论与实践相结合的框架，旨在评估LLMs在利用这些概率测度复制现实世界推理机制方面的有效性。通过将LLMs视作经由自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着我们朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，并通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即使经过微调，LLM的输出可靠性仍然存疑，特别是考虑到任务的复杂性和LLMs固有的幻象问题。为应对这些挑战，我们提出了LLM4DSR，一种使用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型上。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转化为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转换为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并汇总以形成层次LTL规范。这些规范继而被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过模拟及涉及人类参与者的实际实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成方面达到了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs 观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验对此进行了验证。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个针对符号图形程序语义理解的大规模基准测试。该基准测试通过程序-图形对应关系构建，因此需要最少的人力投入。我们使用此基准测试评估当前的LLMs，以初步了解它们根据程序推理视觉场景的能力。我们发现，这一任务能区分现有的LLMs，并且在推理方面表现较好的模型在此任务上表现更佳。最后，我们引入了符号指令微调（SIT）来提升这一能力。具体而言，我们向GPT4-o提出问题，并使用由符号程序生成的图像，这些数据随后被用于微调LLM。我们还发现，SIT数据能增进LLMs的通用指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理与控制问题样本。该数据集被人类专家用来评估各种商用及开源LLM在解决交通运输工程问题时的能力，特别是它们的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致行为。我们的研究标志着利用人工智能通用解决复杂交通运输挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排查和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量假阳性，从而掩盖真实的异常。为了解决这些挑战，我们提出了HELP，一种基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能且成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前对日志进行聚类，从而使查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时在多模态输入的分析判断与决策方面展现出可用性。为了利用LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够根据给定的文字指令自主规划行为及低级执行，同时观察并纠正任务执行过程中可能出现的失败。为了系统地评估该框架在衔接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中开展了移动操作任务与实验，验证了这一方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本研究证明，直接对LLMs与协同模型的表征进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解难题。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表征正则化，将LLMs与协同模型的潜在表征分解为特定和共享成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表征含有更多相关且较少无关的信息，这能增强对下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作有瑕疵的数据标注员以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法在七项上超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，我们仍知之甚少。为了考察针对某一观点的偏见程度，我们通过两项下游任务评估了两种情况：一是语言模型在使用时对社会群体的隐性和显性知识的运用。首先，我们通过在极端偏见场景下使用有偏模型进行压力测试评估。随后，我们评估了当面对与既有观点相冲突的情境时，语言模型如何在语言上校准，以应对来自显性和隐性观点的挑战。研究发现，语言模型在识别隐性观点与显性观点方面存在差异，且普遍倾向于放大与之立场相反的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比之下，未对齐（零样本）的基础模型则产生了直接而不够谨慎的回答。这些基础模型的直接且欠考虑的反应提示我们，为进一步提升在高度主观且社会敏感话题上的可靠性，有必要通过融入不确定性标记来细化其决断性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性概率（PN）与充分性概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出一个理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了在何种条件下可以计算出PN和PS的合适近似值。本研究标志着朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有希望的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即使经过微调，LLM的输出可靠性仍然存疑，尤其是考虑到任务的复杂性和LLMs固有的幻觉问题。    为了解决这些挑战，我们提出了LLM4DSR，一种使用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅利用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总，形成层次化的LTL规范。这些规范继而被用于现有规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成方面实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常面临挑战，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们探索了一个新任务：关注符号图形程序，这是一种流行的表现形式，能够通过程序生成视觉数据。尽管LLMs在程序合成方面展现出令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换成图形内容。在这里，我们通过让LLMs回答与图形内容相关的问题来衡量它们对符号程序的理解能力。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过对应的图形内容回答则相对容易，我们通过人类实验验证了这一点。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这一任务创建了一个大规模的基准测试，用于评估LLMs对符号图形程序的语义理解能力。该基准测试通过程序-图形对应构建，因此需要最少的人力投入。我们在这一基准上评估当前的LLMs，以初步揭示它们根据程序推断视觉场景的能力。我们发现，此任务能区分现有LLMs，并且在推理方面表现良好的模型在此任务上表现更佳。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们使用由符号程序生成的问题和图像查询GPT4-o。此类数据随后被用来微调LLM。我们还发现，SIT数据能提升LLMs的通用指令遵循能力。|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理和控制问题样本。该数据集被人类专家用来评估各种商业及开源LLMs的性能，特别是它们在解决交通运输工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致行为。我们的研究标志着利用人工智能通用解决方案应对复杂交通运输挑战这一领域的激动人心的初步尝试。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排除和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特征和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。最后，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量误报，掩盖真实的异常。为了解决这些挑战，我们提出了HELP，一个基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能且成本效益高的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调，以便在解析前对日志进行聚类，从而将查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公开数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，并利用多模态感知执行任务与高层规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，同时在多模态输入的分析判断与决策方面展现出实用性。为了利用LLMs的力量促进人形移动操作，我们提出了一种新颖的语言模型框架，使机器人能够在给定文本指令下自主规划行为及低层执行，并在任务执行过程中观察及纠正可能出现的失败。为了系统性地评估该框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了利用LLMs增强协同过滤模型，已有多种尝试通过对比学习等技术进行表示对齐以转移知识。然而，本研究证明，直接对齐LLMs与协同模型的表示对于提升下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效对齐两者间的语义表示仍是一个未解挑战。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局和局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表示包含更多相关且较少无关的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于现有最先进的算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等问题给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但关于隐性语言（即未明确表达观点的语言）如何影响大型语言模型中偏见放大的理解尚不充分。为了考察对某一观点的偏见程度，我们通过两项下游任务评估了两种情况：一是语言模型在使用时对社会群体的隐性和显性知识的运用。首先，我们通过极端偏见场景下的压力测试评估来展示偏见模型的表现。随后，我们评估了当语言模型面对与既有观点相冲突的观点时，在处理隐性和显性意见时的语言校准情况。研究发现，模型在识别隐性和显性观点方面存在差异，普遍倾向于放大与之对立的显性观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比于未经调整（零样本）的基础模型而言，显得更为谨慎。未经调整模型的直接且不够谨慎的回应表明，在处理高度主观性和社会敏感性话题时，有必要通过融入不确定性标记来进一步细化其决断性，以增强其可靠性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这场辩论的核心围绕两个关键的概率概念展开，这两个概念对于建立原因与其结果之间的联系至关重要：必要性的概率（PN）与充分性的概率（PS）。本论文提出一个兼具理论与实践意义的框架，旨在评估LLMs运用这些概率测度模拟现实世界推理机制的有效性。通过将LLMs视作经由自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着我们朝着深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例对此进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即便经过微调，LLM的输出可靠性仍然存疑，尤其是考虑到任务的复杂性和LLMs固有的幻象问题。    为了解决这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总形成层次LTL规范。这些规范继而用于借助现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过模拟及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成方面实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常颇具挑战性，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们迈出了一步，转向了一个新任务：关注符号图形程序，这是图形内容的一种流行表示形式，可以程序化生成视觉数据。尽管LLMs在程序合成方面展示了令人振奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过它们回答与图形内容相关的问题的能力来表征LLMs对符号程序的理解。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过验证我们发现，如果直接访问相应的渲染视觉内容，这些问题将很容易回答。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染的视觉内容。我们利用这项任务通过创建一个大规模的基准来评估LLMs在符号图形程序语义理解方面的能力。该基准是通过程序-图形对应关系构建的，因此只需要最少的人力努力。我们在该基准上评估当前的LLMs，以初步揭示它们根据程序推理视觉场景的能力。我们发现，此任务能区分现有LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令微调（SIT）来提升这种能力。具体而言，我们使用由符号程序生成的问题和图像查询GPT4-o。这些数据随后被用来微调LLM。我们还发现，SIT数据能够提高LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理与控制问题样本。该数据集被人类专家用来评估各种商用及开源LLM的能力，特别是它们在解决交通运输工程问题时的准确性、一致性和推理行为。我们的综合分析揭示了每个LLM的独特优势和局限性，例如，分析显示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致行为。我们的研究标志着利用人工通用智能应对复杂交通运输挑战这一领域的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排除和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于规则的日志解析器需要手工特性和领域知识，这很难大规模泛化。其次，现有的基于大型语言模型的日志解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，轻微的日志变化会产生误报，掩盖了真实的异常。为了解决这些挑战，我们提出了HELP，一个基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能和成本效益日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前对日志进行聚类，从而使查询成本降低数个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，定期更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务理解与处理语义信息方面展示了强大的规划与推理能力，并且在针对多模态输入进行分析性判断与决策方面展现出可用性。为了借助LLMs的力量促进人形机器人移动操作，我们提出了一种新颖的、基于语言模型的框架，使机器人能够在给定文本指令下自主规划行为及低级执行方案，并在任务执行过程中观察并纠正可能出现的失败。为了系统地评估这一框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并采用CENTAURO机器人在模拟及真实环境中进行了移动操作任务实验，验证了该方法在具有自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，已有多种尝试旨在从LLMs中提炼知识，采用如对比学习等技术进行表示对齐。然而，本研究证明，直接对LLMs与协同模型的表示进行对齐以增强下游推荐任务的表现是次优的，这一结论基于信息理论。因此，如何有效地在协同模型与LLMs之间对齐语义表示的问题仍未得到妥善解决。受此观点启发，我们提出了一种针对LLMs与协同模型的新型即插即用对齐框架。具体而言，我们首先通过投影层和表示正则化，将LLMs和协同模型的潜在表示分解为特定和共享组件。随后，在共享表示上执行全局和局部结构对齐，以促进知识迁移。此外，我们从理论上证明了特定和共享表示包含了更多相关且较少无关的信息，这能增强对下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法超越了现有的一流算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类非结构化自然语言数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了仅使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合到许多行业应用场景中特定的、监督学习模型的设计与部署中。|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不直接表达观点的语言）如何影响大型语言模型中的偏见放大效应，目前了解尚少。为了考察对某一观点的偏见程度，我们通过两项下游任务评估了两种情况：一是语言模型在使用对社会群体的隐性和显性知识时的表现。首先，我们通过构建极端偏见场景的测试，利用存在偏见的模型进行压力测试评估。随后，我们评估了当面对观点冲突时，语言模型如何在处理隐性和显性观点时进行语言上的校准。研究发现，语言模型在识别隐性与显性观点上存在差异，且普遍倾向于放大显性对立观点的偏见。此外，与偏见立场一致的模型在生成回应时采用了更多表示不确定性的词汇，相比未对齐（零样本）的基础模型显得更为谨慎。未对齐模型的直接且不加小心的回应暗示了在处理高度主观性和社会敏感性话题时，有必要通过融入不确定性标记来进一步细化其决断性，以增强其可靠性。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性的概率（PN）与充分性的概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一套理论与实践相结合的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着我们朝着深入了解LLMs何时能够进行推理迈出了重要一步，研究中通过一系列数学实例对此进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有前景的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即使经过微调，LLM的输出可靠性仍然存疑，特别是考虑到任务的复杂性和LLMs固有的幻觉问题。为应对这些挑战，我们提出了LLM4DSR，一种利用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅使用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型上。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总以形成层次化的LTL规范。这些规范随后被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次化推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成上实现了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|评估大型语言模型（LLMs）的能力通常颇具挑战性，部分原因在于很难找到它们在训练过程中未接触过的任务。为应对这一挑战，我们迈出了一步，转向了一个新任务：关注符号图形程序，这是图形内容的一种流行表示形式，可以程序化生成视觉数据。尽管LLMs在程序合成方面展示了令人兴奋的潜力，但它们是否理解符号图形程序呢？与传统程序不同，符号图形程序可以转换为图形内容。在这里，我们通过它们回答与图形内容相关的问题的能力来表征LLMs对符号程序的理解。这项任务具有挑战性，因为仅从符号程序本身很难回答这些问题——然而，通过人类实验验证，从相应的图形内容回答这些问题会很容易。为了理解符号程序，LLMs可能需要具备想象相应图形内容外观的能力，而无需直接访问渲染后的视觉内容。我们利用这一任务创建了一个关于符号图形程序语义理解的大规模基准测试。该基准测试通过程序-图形对应关系构建，因此只需要最少的人力投入。我们在该基准上评估当前的LLMs，以初步揭示它们从程序中推断视觉场景的能力。我们发现，此任务能够区分现有LLMs，并且被认为擅长推理的模型表现更佳。最后，我们引入了符号指令调整（SIT）来提升这种能力。具体而言，我们使用由符号程序生成的问题和图像来查询GPT4-o。此类数据随后被用于微调LLM。我们还发现，SIT数据能提高LLMs的通用指令遵循能力。|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|在本论文中，我们探究了最新大型语言模型（如GPT-4、GPT-4o、Claude 3.5 Sonnet、Claude 3 Opus、Gemini 1.5 Pro、Llama 3及Llama 3.1）在解决选定的本科层次交通运输工程问题上的能力。我们引入了TransportBench这一基准数据集，它包含了广泛主题的交通运输系统规划、设计、管理与控制问题样本。该数据集被人类专家用来评估各种商业化及开源语言模型在解决交通运输工程问题时的能力，特别是它们的准确性、一致性和推理行为。我们的综合分析揭示了每个模型的独特优势和局限性，例如，我们的分析展示了Claude 3.5 Sonnet在解决TransportBench问题时展现出的令人印象深刻的准确度以及一些未预期的不一致性行为。我们的研究标志着利用人工智能通用解决复杂交通运输挑战的激动人心的第一步。|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|日志是软件维护和故障诊断的第一手信息来源。日志解析，即将半结构化的日志消息转换为结构化模板，是自动化日志分析任务（如异常检测、故障排除和根本原因分析）的先决条件。然而，现有日志解析器在实际系统中存在三个主要问题：首先，传统的基于启发式的解析器需要手工特性和领域知识，这很难大规模推广。其次，现有的基于大型语言模型的解析器依赖于定期的离线处理，限制了它们在实时应用场景中的有效性。第三，现有的在线解析算法易受日志漂移影响，轻微的日志变化会引发大量误报，掩盖真实的异常。为了解决这些挑战，我们提出了HELP，一个基于层次嵌入的日志解析器。HELP是首个利用LLMs进行高性能且成本效益高的日志解析的在线语义解析器。我们通过一个新颖的层次嵌入模块实现这一目标，该模块对文本嵌入模型进行微调以在解析前对日志进行聚类，从而使查询成本降低多个数量级。为了应对日志漂移，我们还开发了一个迭代再平衡模块，周期性地更新现有的日志分组。我们在14个大规模公共数据集上对HELP进行了广泛评估，结果显示HELP在加权分组和解析准确性方面显著高于当前最先进的在线日志解析器。我们还将HELP集成到Iudex的生产可观测性平台中，证实了HELP在生产环境中的实用性。我们的结果表明，HELP对于高吞吐量的实际日志解析是有效且高效的。|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|在非结构化环境中实现人形机器人自主移动操作对于达成实体智能至关重要且极具挑战性。这要求机器人能够在长时段任务中规划其行动与行为，同时利用多模态感知执行任务与高级规划之间的偏差。近期，大型语言模型（LLMs）在通过机器人控制任务展示强大的规划与推理能力、以及在多模态输入的分析判断与决策方面的能力方面取得了进展。为了借助LLMs的力量促进人形机器人移动操作，我们提出了一种创新的语言模型基框架，使机器人能够根据给定的文字指令自主规划行为与低级执行，并在任务执行过程中观察并纠正可能发生的失败。为了系统地评估这一框架在链接LLMs方面的效能，我们创建了用于任务规划的机器人“动作”与“感知”行为库，并使用CENTAURO机器人在模拟及真实环境中进行了移动操作任务与实验，验证了该方法在具备自主行为规划的机器人任务中的有效性和应用性。|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|得益于强大的推理能力，大型语言模型（LLMs）在推荐系统中展示了卓越的性能。为了提升协同过滤模型的能力，人们已尝试从LLMs中提炼知识，采用如对比学习等技术进行表征对齐。然而，本工作中我们证明了直接对LLMs与协同模型的表征进行对齐对于增强下游推荐任务性能是次优的，这一结论基于信息理论。因此，如何有效实现LLMs与协同模型间语义表征的对齐仍是一个未解的挑战。  受此观点启发，我们提出了一种新颖的即插即用对齐框架，用于连接LLMs与协同模型。具体而言，我们首先通过投影层和表征正则化手段，将LLMs与协同模型的潜在表征分解为特定和共享的成分。随后，在共享表征上执行全局与局部结构对齐，以促进知识迁移。此外，我们理论上证明了特定和共享表征含有更多相关且较少冗余的信息，这能增强下游推荐任务的有效性。在基准数据集上的广泛实验结果表明，我们的方法优于当前的先进算法。|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|大型语言模型（LLMs）极大提升了我们快速分析和分类自然语言非结构化数据的能力。然而，成本、网络限制以及安全约束等因素给它们融入工作流程带来了挑战。本研究采用系统设计方法，将LLMs用作不完美数据标注器以辅助下游监督学习任务，并引入了旨在提升分类性能的创新系统干预措施。在八项测试中，我们的方法有七项超越了直接使用LLM生成的标签，展示了一种有效策略，即如何将LLMs整合进许多行业应用场景中特定的、监督学习模型的设计与部署。|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|尽管近期已有多项研究探讨了偏见识别的不同方法，但对于隐性语言（即不明确表达观点的语言）如何影响大型语言模型中的偏见放大效应，目前了解尚少。为了考察对某一观点的偏见程度，我们通过两项下游任务评估了模型在使用涉及社会群体的隐性和显性知识时的表现。首先，我们通过在极端偏见情境下应用有偏模型进行压力测试评估。随后，我们评估了当语言模型面对与既有观点相冲突的观点时，其在处理隐性和显性意见时的语言校准情况。研究发现，模型在识别隐性和显性观点上存在差异，普遍趋向于对反对立场的显性观点表现出更大偏见。此外，与偏见立场一致的模型在生成回应时采用了更多体现不确定性的表述，相比之下，未对齐（零样本）的基础模型则产生了更直接、不太谨慎的回应。这些未经对齐模型的直接且缺乏谨慎的回应暗示，有必要通过融入不确定性标记来进一步优化其决断性的准确性，特别是在处理高度主观性和社会敏感性话题时。|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|近期人工智能领域的重大进展在很大程度上得益于大型语言模型（LLMs）的能力，这些模型能以类似人类思维的方式解决复杂问题。然而，关于LLMs是否真正具备推理能力的问题，学术界仍存在争议。这一争论的核心涉及两个关键的概率概念，即必要性概率（PN）与充分性概率（PS），这两个概念对于建立原因与其结果之间的联系至关重要。本文提出了一种理论与实践并重的框架，旨在评估LLMs在利用这些概率度量复制现实世界推理机制方面的有效性。通过将LLMs视作通过自然语言接口处理信息的抽象机器，我们探讨了计算PN和PS合适近似值的条件。本研究标志着我们朝着更深入理解LLMs在何时能够进行推理的方向迈出了重要一步，研究中通过一系列数学实例进行了说明。|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|序列推荐系统本质上依赖于用户的历史交互序列，而这些序列经常受到噪声交互的污染。在缺乏明确监督信号指示噪声的情况下，准确识别这些噪声交互尤为困难。大型语言模型（LLMs），凭借其广泛的开放知识和语义推理能力，为弥补这一信息缺口提供了有希望的途径。然而，利用LLMs进行序列推荐中的去噪任务引入了显著的挑战：1）直接应用预训练的LLMs可能不胜任去噪任务，常常产生无意义的响应；2）即使经过微调，LLM的输出可靠性仍然存疑，尤其是考虑到任务的复杂性和LLMs固有的幻象问题。    为了解决这些挑战，我们提出了LLM4DSR，一种使用LLMs进行序列推荐去噪的定制化方法。我们构建了一个自监督微调任务，以激活LLMs识别噪声项目并提出替换的能力。此外，我们开发了一个不确定性估计模块，确保仅利用高置信度的响应来进行序列修正。值得注意的是，LLM4DSR具有模型无关性，允许修正后的序列灵活应用于各种推荐模型中。广泛实验验证了LLM4DSR在三个数据集和三种推荐模型骨干上的优越性。|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|长期规划面临的挑战包括不确定性累积、计算复杂性、延迟奖励及信息不完全等。本研究提出一种方法，利用人类指令中的任务层次结构来促进多机器人规划。我们借助大型语言模型（LLMs），提出了一个两步法，将多句指令转换为结构化语言——层次线性时序逻辑（LTL），作为规划的正式表示。首先，LLMs将指令转化为一个定义为层次任务树的层次化表示，捕捉任务间的逻辑与时间关系。随后，通过领域特定的LLM微调，将每个任务的子任务转化为平面LTL公式，并加以汇总以形成层次化的LTL规范。这些规范继而被用于利用现成规划器进行规划。我们的框架不仅弥合了指令与算法规划之间的差距，还展示了LLMs在利用层次推理自动化多机器人任务规划方面的潜力。通过仿真及涉及人类参与者的现实世界实验评估，我们证明该方法能处理比现有方法更复杂的指令。结果显示，我们的方法在多机器人任务分配和计划生成上达到了更高的成功率和更低的成本。演示视频可于https://youtu.be/7WOrDKxIMIs观看。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|null|翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对LLM驱动的NL2SQL技术的全面回顾，从以下四个方面覆盖其整个生命周期：（1）模型：处理NL的模糊性和规范不足的NL2SQL翻译技术，以及恰当映射NL与数据库模式和实例；（2）数据：从训练数据的收集、因训练数据稀缺而进行的数据合成，到NL2SQL基准测试；（3）评估：使用不同指标和粒度从多角度评估NL2SQL方法；及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进化。此外，我们为开发NL2SQL解决方案提供了一套实用指南。最后，我们讨论了LLMs时代NL2SQL的研究挑战和开放问题。|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现完全自动化——包括数据查询、分析、可视化及报告制作——仍是一个复杂的挑战。本研究介绍了一种先进的、行业级系统SageCopilot，该系统通过整合大型语言模型（LLMs）、自动代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用了一个双阶段设计：在线阶段利用情境学习（ICL）精炼用户输入为可执行脚本并运行这些脚本以生成结果报告与可视化；离线阶段则准备ICL在线阶段所需演示。系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格测试和与基于提示解决方案的比较分析，SageCopilot已被实证验证在生成或执行脚本及提供带有可视化的结果方面能实现端到端的优越性能，并由真实世界数据集支持。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证明能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的演示示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器来动态检索示例，但外部检索器与LLMs之间的表征能力存在固有差异。此外，优化示例选择并非易事，因为缺少直接方法在不进行成对推断的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的演示检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们提出了一种代理分数，根据输出查询之间的相似性来估计示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为解答这一问题，我们提出了一种多角度NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情景下，如不同数据领域和SQL特性，对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下识别出了一种有效的NL2SQL方法，即SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现出竞争优势。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术使不熟悉数据库的非专业用户能够使用SQL进行数据分析。将自然语言转化为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项名为ChatBI的综合且高效的技术，旨在解决NL2BI任务。首先，我们分析了交互模式这一关键模块，这是NL2SQL与NL2BI在应用中的主要区别之处，并设计了一个更小巧、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行架构链接的现有NL2SQL方法因令牌限制而无法进行。BI场景中更高比例的列义模糊性也使得架构链接变得困难。ChatBI结合了数据库社区现有的视图技术，首先将架构链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列作为所需列输入到LLM中进行架构链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，这使得ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其整合进多条产品线中，进行了大规模生产任务评估。所获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，在我们的真实BI场景数据表和查询下，与当前主流NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进翻译，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而未能生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含来自不同数据库的已知NL2SQL转换。LLMs可以从输入的示例中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（用于逻辑增强的预训练模型检索提示），通过为手头的NL2SQL任务检索包含必要逻辑运算符组合的示例，从而引导LLMs产生更佳的SQL转换，以此提升准确率。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的精确集匹配准确率和87.8%的执行匹配准确率，树立了新的state-of-the-art性能标准。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确率，展现出其鲁棒性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取实例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性是一项重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为此，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。全面的评估表明，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到证明。尤其值得注意的是，我们的模型超越了来自OpenAI和Cohere的强大竞争性嵌入模型。此外，与这些竞争模型相比，我们提出的编码器在1-shot情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期文本到SQL（Text2SQL）领域的进步着重于利用大型语言模型（LLM）的上下文学习能力，取得了显著成效。然而，它们在处理冗长的数据库信息和复杂用户意图时仍面临挑战。本文提出了一种两阶段框架，旨在提升当前基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示方式，称为参考增强表示，该表示融合了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，借助已链接的模式，我们简化提示中的模式信息，并指示LLM产出最终SQL。最后，作为后处理优化模块，我们建议采用跨LM的一致性而非单一LM内部的自一致性作为评判标准。我们的方法在Spider基准测试上达到了新的SOTA成果，执行准确率达到了87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们使用ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们提出一种方法，即从查询的自然语言中提取相关模式作为输入上下文，以此指导LLMs更准确地生成GQL。我们在源自金融领域和医疗领域的两个构建数据集——FinGQL和MediGQL上评估了我们的方法。实验结果表明，相较于一系列基线方法，我们的方法显著提升了性能，分别在精确匹配（EM）上提高了5.90和6.36的绝对分数，在 existence（EX）上提高了6.00和7.09的绝对分数。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资产。访问控制跨越两个领域：策略（组织级原则，定义谁应拥有访问权限）和流程（数据库级原语，实际实现该策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式——面向数据库的意图型访问控制（Intent-Based Access Control for Databases, IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（NLACM）得以更精确地表达。数据库访问控制原语自这些NLACMs自动合成。这些原语可用于生成新的数据库配置和/或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初步实现（我们称之为LLM4AC），以及评估此类系统准确性与范围的初步基准。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC在我们的初始Dr. Spider基准测试中大幅超越了其他基线，达到了高准确率和F1分数。在所有系统上，我们发现对于扩展的基准测试，包括需要外部知识的最先进NL2SQL数据和来自Amazon Access数据集的真实世界角色层次结构，整体性能均表现优异。|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|在AIOps（面向IT运营的人工智能）时代，准确预测系统状态至关重要。在微服务系统中，这一任务面临着动态和复杂的空间-时间关系挑战，这主要归因于动态部署、多样的调用路径以及实例间的级联效应。当前的时间序列预测方法主要关注内在模式，在空间关系至关重要的环境中显得不足。同样，空间-时间图方法经常忽视时间趋势的本质，更多地集中在节点间的消息传递上。此外，微服务领域的现有研究往往低估了网络指标和拓扑结构在捕捉系统动态变化中的重要性。本文介绍了一种针对微服务环境中的系统状态预测而设计的模型STMformer，该模型能够处理多节点和多变量时间序列。我们的方法利用动态网络连接数据和拓扑信息来帮助建模系统内部复杂的时空关系。此外，我们集成了PatchCrossAttention模块以全局计算级联效应的影响。我们基于一个微服务系统构建了一个数据集，并对STMformer进行了全面的实验对比领先方法。在短期和长期预测任务中，我们的模型持续实现了8.6%的MAE（平均绝对误差）降低和2.2%的MSE（均方误差）减少。源代码可于https://github.com/xuyifeiiie/STMformer获取。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|**AIOps算法在微服务系统的维护中发挥着关键作用。许多先前的基准性能排行榜为选择合适的算法提供了有价值的指导。然而，现有的AIOps基准主要利用离线数据集来评估算法，无法持续使用实时数据集评估算法性能，并且评估的操作场景是静态的，这不足以有效选择算法。为了解决这些问题，我们提出了一种评估一致性和面向场景的评估框架，名为MicroServo。其核心思想是构建一个实时微服务基准，以生成实时数据集，并在其上持续模拟特定操作场景。MicroServo通过根据操作场景选择特定算法和数据集来支持不同的排行榜。它还支持多种类型算法的部署，实现了算法的热插拔。最后，我们通过三个典型的微服务操作场景测试了MicroServo，以展示其效率和可用性。**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|大型语言模型（LLMs）和AI代理在软件开发与部署中的迅速应用正在革新信息技术领域。尽管代码生成受到广泛关注，但AI代理在云服务运营韧性方面的应用具有更高的影响力，目前这类工作仍需大量人力投入及专业知识。AIOps（AI for IT Operations）作为新兴趋势，旨在通过自动化复杂运维任务如故障定位和根本原因分析，减少人工介入并减轻对客户的影响。然而，通往自治和自愈合云的AIOps愿景受阻于缺乏构建、评估及改进AIOps代理的标准框架。  本论文旨在奠定此类框架的基础，首先明确需求，随后探讨满足这些需求的设计决策。我们提出了AIOpsLab原型实现，它利用代理-云接口来编排应用程序，通过混沌工程实时注入故障，并与代理交互以实现故障的定位与解决。实验结果显示了良好前景，为构建、评估及提升自治云所需的模块化、健壮框架奠定了基础。|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|**日志分析对于确保信息系统有序、稳定运行至关重要，尤其在人工智能运维（AIOps）领域。大型语言模型（LLMs）在自然语言处理任务中展现出巨大潜力。在AIOps领域，它们在异常检测、故障根本原因分析、运维脚本生成及告警信息摘要等任务上表现出色。然而，当前LLMs在日志分析任务中的性能尚缺乏充分验证。为解决这一缺口，我们引入了LogEval，这是一个全面的基准测试套件，首次旨在评估LLMs在各种日志分析任务中的能力。该基准涵盖了日志解析、日志异常检测、日志故障诊断和日志摘要等任务。LogEval利用4,000条公开的日志数据条目对每个任务进行评估，并为每个任务采用15种不同的提示，以确保评估的深入与公正。通过严格评估领先LLMs，我们展示了不同LLM技术对日志分析性能的影响，特别关注自我一致性与少量样本的上下文学习。同时，我们也讨论了模型量化、中英文问答评估及提示工程的相关发现。这些发现揭示了多语言环境下LLMs的优势与不足，以及不同提示策略的有效性。针对不同任务采用多种评估方法，以准确衡量LLMs在日志分析中的表现，实现全面评估。LogEval的评估洞察揭示了LLMs在日志分析任务中的强项与局限，为研究人员和实践者提供了宝贵的指导。**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|随着软件系统的日益复杂化，人工智能运维（AIOps）方法已被广泛应用于软件系统故障管理中，以确保大型分布式软件系统的高可用性和可靠性。然而，这些方法仍面临一些挑战，比如跨平台通用性不足和跨任务灵活性欠缺。幸运的是，大型语言模型（LLMs）的最新进展能显著解决这些难题，已有众多研究探索这一领域。但目前尚无全面的综述讨论基于LLM的AIOps与传统AIOps方法之间的差异。因此，本文提供了面向LLM时代的AIOps技术在故障管理方面的综合调查。内容涵盖AIOps故障管理任务的详细定义、AIOps的数据来源，以及采用的LLM基AIOps方法。此外，本综述深入探讨了AIOps子任务、适用于不同AIOps子任务的具体LLM基方法，以及该领域的挑战与未来发展方向，旨在促进其进一步发展和应用。|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|**动态图中的异常边检测旨在识别与正常模式显著偏离的边，可应用于网络安全、金融交易和AIOps等多个领域。随着时间的推移，异常边的类型不断涌现，而针对每种类型的标记异常样本却十分有限。现有方法要么旨在检测随机插入的边，要么需要大量标记数据进行模型训练，这限制了它们在实际应用中的适用性。本文针对这一问题，通过利用大型语言模型（LLMs）中蕴含的丰富知识，提出了一种名为AnomalyLLM的方法。为了使动态图与LLMs协调工作，AnomalyLLM首先预训练了一个动态感知编码器，用于生成边的表示，并利用词嵌入原型重编程边。与编码器相配套，我们设计了一个基于上下文学习的框架，该框架整合了少量标记样本的信息，以实现少样本异常检测。在四个数据集上的实验表明，AnomalyLLM不仅能显著提升少样本异常检测的性能，还能在无需更新模型参数的情况下，对新型异常取得优异的检测结果。**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|我们推出了一款基于机器学习的异常检测产品——AI检测与响应（AIDR），它能够实时监控沃尔玛的业务和系统健康状况。在为期3个月的验证期间，该产品为超过25个应用、平台和运营团队提供了来自3000多个模型的预测，覆盖了63%的重大事件，并将平均检测时间（MTTD）缩短了超过7分钟。与以往的异常检测方法不同，我们的解决方案结合使用了统计学、机器学习及深度学习模型，同时继续融入基于规则的静态阈值，以吸纳领域特定知识。为了实现可扩展性和高可用性，我们通过分布式服务部署并维护了单变量和多变量机器学习模型。AIDR具备反馈机制，利用漂移检测算法和客户反馈来评估模型质量，并且提供自服务接入和定制化功能。AIDR已成功应用于多个内部团队，实现了较短的检测时间和更少的误报，相比以往方法有所提升。展望未来，我们旨在扩大事件覆盖范围和预防能力，减少噪音，并进一步整合根本原因推荐（RCR），以实现端到端的AIDR体验。|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|在云原生技术中，微服务架构日益增长的复杂性给维持系统稳定性和效率带来了重大挑战。为了对告警事件进行根本原因分析（RCA）及解决，我们提出了一种开创性的框架——面向微服务架构的根本原因分析多智能体区块链启发式协作（mABC），旨在革新人工智能运维（AIOps）领域。该框架下，多个基于强大大型语言模型（LLMs）的智能体依据智能体工作流程中的标准化任务和查询处理程序，采用区块链启发式的投票机制达成最终共识。具体而言，根据Agent Workflow设计的七大专业智能体，各自依托其专长及LLMs内在的软件知识，以去中心化链条的方式开展合作，共同为根本原因分析提供宝贵见解。为应对LLMs潜在的稳定性问题，并充分利用去中心化结构固有的透明和平等优势，mABC采纳了借鉴区块链治理原则的决策过程，同时考虑每个智能体的贡献指数和专业指数。实验结果表明，在公共基准AIOps挑战数据集与我们创建的火车票数据集上，相比以往的强势基线，mABC在准确识别根本原因及制定有效解决方案方面展现出更优越的性能。进一步的消融研究突显了mABC各组成部分的重要性，其中智能体工作流程、多智能体协作及区块链启发式投票对于达到最佳性能至关重要。mABC为微服务架构提供了一个全面的自动化根本原因分析与解决框架，在AIOps领域相较于现有基线实现了显著提升。|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|**大型语言模型（LLMs）在众多领域推动了新一轮的交互式AI应用浪潮。然而，由于生成模型的自回归特性，有效服务于LLM推理请求极具挑战性，因为它们的执行时间不可预测。现有的LLM服务系统采用先来先服务（FCFS）调度策略，这会遭受队头阻塞问题的影响。为了应对LLM的非确定性本质并实现高效的交互式LLM服务，我们提出了一种推测式最短作业优先（SSJF）调度器，它使用一个轻量级代理模型来预测LLM输出序列的长度。我们的开源SSJF实现无需对内存管理或批处理策略进行修改。在真实世界数据集和生产工作负载跟踪上的评估显示，与FCFS调度器相比，SSJF在无批处理、动态批处理和连续批处理设置下，分别减少了平均作业完成时间30.5%-39.6%，并提高了2.2-3.6倍的吞吐量。**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|现代IT系统的管理带来了独特的挑战，要求在处理大量数据流时具备可扩展性、可靠性和效率。传统的依赖手动任务和基于规则方法在应对IT系统产生的大量数据量和警报时显得效率低下。为解决这一问题，人工智能操作系统（AIOps）应运而生，它利用机器学习和大数据等高级分析技术来增强事件管理能力。AIOps能够检测和预测事件、识别根本原因，并自动化执行修复动作，从而提升服务质量并降低运营成本。然而，尽管潜力巨大，AIOps领域仍处于初级阶段，分散于多个行业且缺乏统一的标准规范。目前，研究与产业界的贡献分布在各处，缺乏一致的数据管理框架、目标问题定义、实施细节、需求及能力标准。  本研究提出了一套AIOps的术语和分类法，旨在建立一个结构化的事件管理流程，并为构建AIOps框架提供指导。研究还根据事件管理任务、应用领域、数据源和技术方法等标准对相关贡献进行了分类。其目的在于全面回顾AIOps在事件管理中的技术与研究方面，旨在组织知识体系、识别研究空白，并为该领域的未来发展奠定基础。|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|针对移动键盘应用中设备端语言模型训练的最新技术，结合了联邦学习（FL）与差分隐私（DP），通过DP-Follow-the-Regularized-Leader（DP-FTRL）算法实现。实践中使用的DP-FTRL有两种变体，即树聚合和矩阵分解。然而，树聚合在隐私与效用的权衡上表现不佳，而矩阵机制则需要依赖于难以预先准确估计的常数进行昂贵的优化，并且运行时内存成本高。本文将最近引入的Buffered Linear Toeplitz（BLT）机制扩展至多参与场景。我们的BLT-DP-FTRL保持了树聚合的易用性优势，同时几乎在实用性和隐私保护方面达到了矩阵分解的水平。我们在StackOverflow数据集上进行了评估，作为可复现的模拟基准，并在生产环境的联邦学习系统中的四个设备端语言模型任务上进行了测试。实验结果突显了BLT机制的优势，提升了DP在现实世界场景中的实用性和有效性。|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|工业物联网（IIoT）对数据隐私和网络安全威胁高度敏感。联邦学习（FL）作为解决方案应运而生，旨在保护隐私，使得本地IIoT客户端的数据得以保留在本地，同时协同训练模型以检测网络异常。然而，无论是同步还是异步的FL架构都存在局限性，尤其是在处理因数据异质性和资源限制而导致速度各异的客户端时。同步架构会受到拖尾效应的影响，而异步方法则遇到通信瓶颈的问题。此外，FL模型还容易受到旨在披露私人训练数据的对抗性推理攻击。为了解决这些挑战，我们提出了一种针对异构IIoT环境中的异常检测、融合了同态加密的缓冲联邦学习（BFL）框架。BFL采用了一种新颖的加权平均时间方法，以缓解拖尾效应和通信瓶颈，通过与基于缓冲区的服务器协作，确保了处理速度不同客户端之间的公平性。基于两组数据集的性能结果显示，BFL相比于先进的FL方法具有优越性，展现了在提高准确率和收敛速度的同时增强隐私保护的能力。|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|联邦学习（FL）是一种有前景的隐私保护分布式学习框架，能够在移动电话、桌面电脑及配备CPU或GPU的设备等各种装置上部署。在基于服务器的联邦学习即服务（FLaaS）场景下，FL使中央服务器能够协调多个设备上的训练过程，无需直接访问本地数据，从而增强隐私和数据安全性。低秩自适应（LoRA）是一种高效微调模型的方法，通过专注于模型参数的低维子空间来实现。与从头开始微调所有参数相比，这种方法显著降低了计算和内存成本。当LoRA与FL结合，特别是在FLaaS环境中，通过调整局部模型的秩，允许在具有不同计算能力的多样化硬件上灵活且高效地部署。然而，在启用LoRA的FL中，不同的客户端可能会使用不同秩来训练模型，这对服务器端的模型聚合提出了挑战。当前聚合不同秩模型的方法需要对权重进行填充以统一形状，这可能损害全局模型的性能。为了解决这一问题，我们提出了基于秩的LoRA聚合（RBLA），这是一种针对异构LoRA结构设计的新颖模型聚合方法。RBLA保留了不同秩模型的关键特征。本文分析了当前填充方法在FLaaS环境下重塑模型以进行聚合存在的问题，随后引入了RBLA，该方法维持了低秩与高秩特征。最后，我们通过与先进方法的对比实验展示了RBLA的有效性。|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|联邦学习通过消除数据共享的需要，为AI应用带来了革命性的变化。然而，研究表明，在训练过程中仍可提取信息，因此需要额外的隐私保护措施，如差分隐私。为了实现现实世界的联邦学习应用，从性能公平分配到非歧视行为，公平性都是必须考虑的因素。特别是在高风险应用领域（如医疗健康），避免重复过去歧视性错误至关重要。近期研究表明，隐私与公平之间存在固有的紧张关系，为此，我们进行了多声部文献回顾，以考察当前在联邦学习中整合隐私与公平的方法。我们的分析揭示了隐私与公平之间的关系被忽视的问题，这对现实世界的应用构成了重大风险。我们强调了探索隐私、公平与性能之间关系的必要性，并倡导创建综合性的联邦学习框架。|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|联邦学习能够在遵守隐私要求的前提下，让多个客户端在服务器的总体规划下协同训练机器学习模型。然而，服务器无法直接监督局部训练过程，这为恶意客户端植入后门提供了可乘之机。现有研究表明，后门攻击会在受感染的模型中激活特定神经元，而这些神经元在处理干净数据时则保持休眠状态。基于这一发现，我们提出了一种名为“低激活输入神经元权重更新反转”（FLAIN）的方法来防御联邦学习中的后门攻击。具体而言，在完成全局训练后，我们利用一个辅助数据集来识别低激活输入神经元，并反转与之相关的权重更新。我们逐步提高低激活输入的阈值，并迭代地进行权重更新的反转，直至在辅助数据上的性能衰退达到不可接受的程度。广泛的实验验证了我们的方法能在包括非独立同分布数据或高错分类率等不同攻击场景下，有效将后门攻击的成功率降低至较低水平，同时对干净数据的性能影响保持在最小范围。|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|为保护数据隐私，联邦学习（FL）范式应运而生，其中客户端仅公开模型梯度而非原始数据进行模型训练。为了进一步增强联邦学习中模型梯度的保护，提出了差分隐私联邦学习（DPFL），通过引入差分隐私（DP）噪声对梯度进行混淆后再暴露。然而，DPFL中一个基本但常被忽视的问题是客户端隐私需求的异质性，这一需求在不同客户端间可能有显著差异，极大地复杂化了DPFL中的客户端选择问题。换句话说，在选择客户端时，既要考虑数据质量，也要考虑DP噪声的影响。为解决这一问题，我们针对具有异构隐私设置的DPFL进行了收敛性分析，考虑了一般的客户端选择策略、流行的DP机制及凸损失函数。基于收敛性分析，我们将目标设定为最小化DPFL中带有异构隐私设置下损失函数的值，这是一个凸优化问题，可以高效求解。据此，我们提出了DPFL-BCS（偏差客户端选择）算法。广泛的实验结果，包括使用真实数据集及凸与非凸损失函数的情况，表明DPFL-BCS能显著提升模型效用，与当前最优基线相比表现出色。|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|随着联网和自动驾驶车辆的普及，控制器区域网络（CAN）总线已成为车内通信的主要标准，这得益于其速度与效率。然而，CAN总线缺乏基本的安全措施，如认证和加密，使其极易受到网络攻击。为了确保车内安全，入侵检测系统（IDS）必须能检测已知攻击，并对新的、未见过的攻击提供强大的防御能力，同时保持轻量级以利于实际部署。以往的研究仅依赖CAN标识符特征，或采用传统机器学习（ML）方法配合手动特征提取。这些方法忽视了其他可被利用的特征，使得适应新出现的攻击变种变得困难，从而影响安全性。本文提出了一种创新的、轻量级的车载IDS解决方案，该方案利用深度学习（DL）算法来应对这些局限性。所提议的IDS采用多阶段方法：第一阶段使用人工神经网络（ANN）来检测已知攻击，第二阶段则采用长短期记忆（LSTM）自编码器来检测新的、未见过的攻击。  为了理解并分析不同的驾驶行为，及时更新模型以涵盖最新的攻击模式，并保护数据隐私，我们提出了一种理论框架，用于在分级联邦学习（H-FL）环境中部署我们的IDS。实验结果显示，我们的IDS对已知攻击的F1分数超过0.99，对新型攻击的F1分数超过0.95，检测率达到99.99%。此外，误报率（FAR）极低，仅为0.016%，有效减少了误报。尽管采用了在识别复杂和零日攻击方面表现出色的深度学习算法，但该IDS依然保持轻量级，确保了其在真实世界中的可部署性。|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|联邦学习（FL）理论上在保护个体客户端数据隐私的同时能够生成高质量的机器学习模型。然而，诸如深度梯度泄露（DLG）等攻击严重质疑了FL的实际应用性。本文通过实证评估了对抗DLG的四种防御方法的有效性：屏蔽（Masking）、裁剪（Clipping）、修剪（Pruning）和噪声注入（Noising）。屏蔽技术此前仅作为参数传输过程中信息压缩的一种方式被研究，但出人意料地展现出相比其他三种已确立方法更强大的防御实用性。  我们的实验分为两部分。首先，我们跨MNIST、CIFAR-10和lfw数据集评估每种方法的最低超参数阈值。随后，我们使用各方法及其最低阈值训练FL客户端，以探究DLG防御与训练性能之间的权衡。结果揭示，屏蔽和裁剪在几乎不影响性能的同时，能有效混淆足够信息以对抗DLG。|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|**联邦学习（Federated Learning, FL）是一种增强隐私的分布式机器学习技术。通过本地训练模型并聚合更新，联邦能够在不集中收集数据的情况下协同学习。FL在医疗、金融和个人计算领域日益受到欢迎。然而，它继承了经典机器学习中的公平性挑战，并引入了新的问题，这些问题源于数据质量差异、客户端参与度、通信限制、聚合方法以及基础硬件的差异。公平性仍然是FL中一个未解决的问题，社区已识别出缺乏简明定义和度量标准来量化公平性的问题；为应对这一挑战，我们提出了联邦公平性分析方法论——一种衡量公平性的方法。我们的公平性定义包括四个概念，并对应有新颖的度量指标。这些定义是针对问题症状提出的，并利用了源自可解释人工智能（XAI）、合作博弈论和网络工程的技术。  我们在不同的实验设置下测试了该方法，包括改变FL实现方式、机器学习任务和数据配置。结果显示，统计异质性和客户端参与度会影响公平性，而诸如Ditto和q-FedAvg等注重公平性的方法仅在一定程度上改善了公平性与性能之间的权衡。借助我们的技术，FL从业者能够在其系统的不同粒度级别上揭示以往难以获得的公平性洞察，从而应对FL中的公平性挑战。我们已将此工作开源，访问地址为：https://github.com/oscardilley/federated-fairness。**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|分布式太阳能发电系统的快速增长给配电系统规划和调度带来了挑战，主要原因是这类系统背后的太阳能发电难以观测。为了解决集中式机器学习方法在估算用户侧（BTM）太阳能发电量时的数据泄露问题，联邦学习（FL）方法因具备分布式学习能力而受到研究者的关注。然而，传统的联邦学习方法面临着异构性、通信故障以及恶意隐私攻击等多种挑战。为了克服这些挑战，本研究提出了一种针对异构社区级BTM太阳能发电量的通信稳健且隐私安全的分布式估计算法。具体而言，本研究采用多任务联邦学习作为主体框架，旨在学习所有社区间的共同特征与独特特性。同时，研究中嵌入了一种更新参数估计算法至多任务联邦学习中，能够自动识别任意两个客户端之间的相似性，并为无法通信的客户端估计更新参数，从而减轻通信故障带来的负面影响。最后，本研究在动态隐私预算分配策略下采用了差分隐私机制，以抵御恶意隐私攻击并提升模型训练效率。案例研究表明，在存在异构性和通信故障的情况下，所提出的算法相比于传统联邦学习和局部化学习方法展现出更佳的估测精度和收敛性能，同时提供了更强大的隐私保护。|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|联邦学习是一种高效框架，旨在促进跨多个分布式设备的协作模型训练，同时保护用户数据隐私。联邦学习面临的一个主要挑战是数据层面的异质性，即私人数据的偏斜或长尾分布。尽管已提出多种方法来应对这一挑战，但大多数方法假设全局数据在所有客户端上呈均匀分布。本文研究了数据层面异质性的联邦学习，并通过简要回顾重新定义了一个更为实际且具有挑战性的场景，称为偏斜异质联邦学习（Skewed Heterogeneous Federated Learning，简称SHFL）。相应地，我们提出了一种新颖的联邦原型校正与个性化方法，该方法包含两部分：联邦个性化和联邦原型校正。前者旨在基于私人数据，在优势类和少数类之间构建平衡的决策边界，而后者则利用类别间辨别性和类别内一致性来校正经验原型。在三个流行基准上的实验表明，所提出的方案优于当前最先进的方法，并在个性化与泛化性能上均实现了均衡。|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|住房与无家可归者关爱系统（HHSC）的首要任务是将无家可归者与支持性住房连接起来。该系统通常包含众多服务于相同人群的机构，但这些机构之间的信息技术平台在类型和质量上存在差异，导致数据在各机构间通常是孤立的。较大的机构可能拥有足够的数据来训练和测试人工智能（AI）工具，而较小的机构通常不具备这样的条件。为了解决这一差距，我们引入了一种联邦学习（FL）方法，使所有机构能够在不共享其敏感数据的情况下协同训练预测模型。我们展示了如何在HHSC内部使用FL，以使所有机构都能平等地获取高质量的AI资源，并进一步辅助人类决策者在系统内更合理地分配资源。这一过程同时保护了数据中个体的隐私，确保在未获得同意的情况下不跨机构共享个人识别信息。利用来自加拿大阿尔伯塔省卡尔加里的真实世界HHSC数据进行的实验结果显示，我们的FL方法在性能上可与理想情况相媲美，即在机构间完全共享并链接数据来训练预测模型。|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|联邦学习（FL）通过协同训练机器学习模型，为个人数据提供了更好的隐私保护。当FL参与者行使被遗忘权，即脱离已参与的FL框架并移除其对全局模型的过往贡献时，FL解决方案应执行所有必要步骤以实现该目标，同时不牺牲全局模型的整体性能，而当前最先进的相关方案尚不支持这一功能。本文提出了一种名为FedQUIT的新算法，利用知识蒸馏技术从FL全局模型中清除待遗忘数据的贡献，同时保持其泛化能力。FedQUIT直接在客户端设备上运行，与常规FL过程相比，无需共享额外信息，也不假设公开可获取的代理数据的存在。我们的解决方案高效、有效，并适用于集中式和联邦式两种设置。实验结果表明，平均而言，FedQUIT在撤销后恢复泛化性能所需的额外通信轮次不到2.5%，得到的已消毒全局模型预测效果可与从未接触待遗忘数据的全局模型相媲美。|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|物联网（IoT）设备在多个领域的迅速普及引发了严重的网络安全问题，这促使了基于机器学习（ML）的入侵检测系统（IDS）在网络安全攻击分类方面的持续研究。传统ML模型需要将数据从IoT设备传输到集中式服务器进行流量分析，这引发了严重的隐私担忧。为解决这一问题，研究人员已探究了联邦学习（FL）基IDS，该系统能在保持数据本地化的同时，在IoT设备间训练模型。然而，由于设备的不同漏洞和攻击向量的复杂性导致的数据异质性，对FL模型的有效性构成了重大挑战。当前研究虽聚焦于在FL框架内调整各种ML模型，但未能有效应对设备间攻击类别不平衡的问题，这一问题显著降低了少数攻击的分类准确性。为克服这一挑战，我们引入了FedMADE，一种新颖的动态聚合方法，它根据流量模式对设备进行聚类，并根据各设备对整体性能的贡献度来聚合局部模型。我们通过与针对非独立同分布（non-IID）数据设计的其他FL算法对比评估了FedMADE，观察到了少数攻击分类准确率高达71.07%的提升。此外，我们还展示了FedMADE对中毒攻击具有鲁棒性，并且相比FedAvg，每轮通信仅增加4.7%（5.03秒）的延迟开销，同时未增加IoT设备的计算负担。|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|卫星任务设计正经历着从传统的单一大型卫星向由多个小型卫星组成的分布式任务配置的范式转变。随着越来越多的这类卫星被部署到轨道上，每颗卫星都收集了大量的数据，对星上轨道边缘计算的兴趣日益增长。联邦学习是一种有前景的分布式计算方法，在此背景下，可使多颗卫星高效协作，进行星上机器学习模型的训练。尽管近期关于在轨道边缘计算中使用联邦学习的研究主要集中在同构卫星星座上，但联邦学习同样可以应用于让异构卫星形成临时协作的场景中，例如由不同运营商运营的通信卫星。此类应用在联邦学习范式中带来了额外挑战，这些挑战主要源自系统的异构性。在这篇立场论文中，我们针对跨运营商应用场景，系统地回顾了这些挑战，对每一项挑战给出了当前研究状态的简要概述，并为深入探讨每个问题提供了切入点。|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|分布式联邦学习（FL）范式基于区块链架构构建，利用分布式节点集群替代单一服务器执行FL模型聚合。这一范式解决了原始FL中集中式恶意服务器的脆弱性问题，并继承了区块链所提供的可信和健壮特性。然而，现有的区块链支持方案面临着模型保密性不足及区块链计算资源有限、难以处理大规模FL计算的挑战。在本文中，我们提出了Voltran，一个创新的混合平台，旨在通过结合可信执行环境（TEE）与区块链技术，为联邦学习实现信任、保密性和健壮性。我们将FL聚合计算卸载到TEE中，提供一个隔离的、可信且可定制的链下执行环境，并随后确保聚合结果在区块链上的真实性和可验证性。此外，我们通过引入多SGX并行执行策略来分摊大规模FL工作负载，从而为多种FL场景提供了强大的可扩展性。我们实现了Voltran的原型，并进行了全面的性能评估。广泛的实验结果表明，Voltran在保证信任、保密性和真实性的同时，仅带来最小的额外开销，并且相比最先进的密文聚合方案，显著加速了计算过程。|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|联邦学习（FL）是一种分布式机器学习方法，它使设备能够在不共享本地数据的情况下协作训练模型，从而确保用户隐私和可扩展性。然而，将FL应用于现实世界的数据面临着挑战，特别是因为现有的大多数FL研究集中在单模态数据上。多模态联邦学习（MFL）应运而生，旨在解决这些挑战，利用模态特定的编码器模型来处理多样化的数据集。当前的MFL方法通常统一地分配所有模态的计算频率，这对于资源有限的物联网设备而言效率低下。在本文中，我们提出了FlexMod，这是一种新颖的方法，通过根据各模态编码器的重要性和训练需求自适应地分配训练资源，以增强MFL中的计算效率。我们采用原型学习来评估模态编码器的质量，使用Shapley值来量化每个模态的重要性，并采纳深度强化学习中的深度确定性策略梯度（DDPG）方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化模型性能和资源利用。在三个真实世界数据集上的实验结果表明，我们提出的方法显著提高了MFL模型的性能。|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|分布式健康智能网络（DHIN）是一个理论框架，旨在解决因医疗数据在各提供者与机构间碎片化而导致的健康数据主权和人工智能在医疗领域应用的重大挑战。该框架首先确立了医疗服务的主权架构作为主权健康网络的前提条件，随后通过克服访问多样化医疗数据源的障碍来促进人工智能的有效利用。这一综合框架利用以下三个核心要素：1）结合个人健康记录（PHR）的自我主权身份架构，作为实现健康数据主权的基础；2）在公共区块链上实施的可扩展联邦学习（FL）协议，用于去中心化的医疗人工智能训练，其中健康数据保留在参与者手中，仅共享模型参数更新；3）一个可扩展且无需信任的奖励机制，激励参与并确保奖励公平分配。该框架确保没有任何实体能够阻止或控制对参与者提供的健康数据进行训练的访问，或决定经济利益分配，因为这些过程都在具有不可篡改记录的公共区块链上操作，无需第三方介入。它支持在医疗领域进行有效的人工智能训练，使患者能够保持对其健康数据的控制，获得经济利益，并为利用集体人工智能开发有益于医疗健康的算法贡献于一个去中心化、可扩展的生态系统。作为参与联邦学习协议的激励，患者会收到数字钱包中的奖励，其长期规划旨在为去中心化保险解决方案提供资金支持。这一方法引入了一种新颖的自筹资金医疗模式，该模式适应个人需求，补充现有体系，并重新定义了全民医疗覆盖的概念。它突显了变革医疗数据管理和人工智能应用的潜力，同时赋予患者更多权力。|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|null|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

