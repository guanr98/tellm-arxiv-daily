[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.15
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个重大挑战。传统的静态数据监督预训练无法赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往通过在专家演示的监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为了克服这些挑战，我们提出了一种框架，该框架结合了引导式的蒙特卡洛树搜索（MCTS）与自我批评机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和强化微调基线，并在具备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升到81.7%（相对增长340%），仅经过一天的数据收集后，进一步提升至95.4%配合在线搜索。我们认为，这标志着自主代理能力的重大飞跃，为现实世界环境中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际软件工程（SWE）问题上显示出了巨大潜力。目前最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的能力各异，有的任务表现优异，而在其他任务上则不尽人意。为了充分利用这些代理的独特专长，我们提出了多样性赋能智能（DEI）框架，它能够利用代理们各自的优势。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上最大个体解决率为27.3%，而通过DEI协调后，该解决率可提升至34.3%，实现了25%的性能提升，并超过了大多数闭源解决方案。我们表现最优的代理组合更以55%的解决率，在SWE-Bench Lite上取得了领先地位。我们的研究发现为协作式AI系统在解决复杂软件工程挑战方面的潜力提供了重要贡献。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到分层强化学习（HRL）的启发，我们提出了一种新颖的框架——分层上下文强化学习（HCRL），该框架利用基于LLM的高层策略将复杂任务实时分解为子任务。具体而言，复杂任务通过高层策略分解成由目标定义的子任务，这些子任务再分配给低层策略完成。一旦LLM代理判定目标达成，便会提出新的目标。为了提升代理在多回合执行中的性能，我们提出了“事后模块化反思”（HMR）方法，与反思整个轨迹不同，HMR通过用中间目标替换任务目标，让代理对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果表明，在5轮执行中，相比于强大的基于上下文学习的基线，HCRL能实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工通用智能（AGI）。然而，在这些模型基于的代理行为、潜在失败原因及改进方法，尤其是在高要求的真实世界规划任务中的研究还较为匮乏。为了填补这一空白，我们通过一个现实主义基准测试——TravelPlanner进行研究，其中代理必须满足多重约束以生成准确的计划。我们利用此基准测试来解答四个关键研究问题：(1) LLM代理在涉及长期和嘈杂上下文的推理和规划中是否足够稳健？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化来改善计划，以及(4) 通过正负反馈相结合的微调方法能否促使LLM进一步提升？我们的综合实验显示，首先，尽管LLM能够处理大量参考信息和少样本示例，但在面对长上下文时，它们往往未能关注到关键部分；其次，它们在分析长篇计划时仍面临挑战，无法为细化提供精确的反馈；第三，我们提出的反馈感知微调（FAFT）方法，利用正负反馈结合的方式，相比监督式微调（SFT）实现了显著的性能提升。我们的发现为社区提供了关于真实世界规划应用各方面的深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大方法，它通过结合叙事技巧与可视化和文本传达洞察。这些故事融入了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释洞察的文本注释。然而，创建此类故事需要对数据有深入理解及精细的叙事规划，这通常需要人工介入，既耗时又费神。尽管大型语言模型（LLMs）在多种NLP任务上表现出色，但它们生成连贯、全面的数据故事的能力仍未得到充分探索。在本工作中，我们引入了一项新颖的数据故事生成任务及一个包含1,449个来自多样来源的故事的基准数据集。为应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体来模拟人类讲故事的过程：一个负责理解并描述数据（反思），生成概要和叙述，另一个则负责每一步的验证。尽管我们的智能体框架在基于模型和人工评估中普遍优于非智能体对应物，但结果也揭示了数据故事生成的独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收关于目标位置相对于知名地标语言描述的信息；仅凭对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间不提供具体指引。这一问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，而地标在该环境中往往并非始终可见。在缺乏导航指示的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs根据每次观察“反应”并相应地做出决策。然而，该基线性能较差，代理往往会重复访问同一位置，并做出短视且不连贯的决策。为解决这些问题，本文引入了一种新颖的代理工作流程，其特点是具有感知、反思和规划的能力。具体而言，我们发现LLaVA-7B模型可以通过微调来准确识别地标的方向和距离，足以支持城市导航需求。此外，通过记忆机制实现反思，过往经验得以存储，并能与当前感知信息结合，以便进行有效的决策论证。规划阶段利用反思结果来制定长期计划，从而避免在长距离导航中的短视决策。我们的研究表明，设计的这一工作流程显著提高了基于LLM的代理的导航能力，相比于当前最先进的基线方法有明显提升。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，各有显著缺点。基于相似性的检索在复杂任务中往往召回率低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的泛用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口集成。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索和代码导航。我们使用三个基准：CrossCodeEval、SWE-bench和EvoCodeBench来评估CodexGraph，并开发了五个实际的编程应用场景。凭借统一的图数据库模式，CodexGraph在学术和现实世界环境中展示了竞争力和潜力，彰显了其在软件工程中的多样性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法不仅劳动强度大，而且需要在通信、网络和优化领域具有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程领域，网络优化将迎来革新性的方法。这种方法通过精心设计的提示策略，将人类的经验和知识融入这些复杂LLMs中，并部署自主智能体作为通信桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这一整合体现了AI即服务的未来模式，以及AI使工作更简便的趋势。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa），以及协同多LLM基自主BSS智能体（CLaBa）。通过实际数据的评估，实验表明，辅助提示的LLMs与基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提高了BSS优化的效率并减少了不必要的手动操作参与。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|大型语言模型（LLMs）在处理含有不完美信息的简单游戏及促进多智能体协作方面已展示出成效，但它们在复杂、不完美信息环境下的实际协同能力，尤其是在非英语环境中的应用，仍有待探索。本研究旨在考察开源与API驱动的LLMs在要求智能体在不完美信息下进行复杂文本游戏合作时所获取知识的应用性，并将其性能与采用其他类型智能体的既定基线进行对比。我们提出了一种心理理论（Theory of Mind, ToM）规划技术，使得LLM智能体能够仅依据游戏规则、当前状态和历史背景作为输入，针对不同对手调整策略。为应对该卡牌游戏中动态且庞大的行动空间挑战，引入了一种外部工具。研究结果显示，尽管现有LLMs与最先进的强化学习（RL）模型之间存在性能差距，但在该游戏设定中，LLMs展现出了ToM能力。这持续提升了它们对抗对手智能体时的表现，表明它们能够理解盟友与对手的行为并能与盟友建立合作。为了促进进一步的研究和理解，我们已公开了代码库。|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|随着大型语言模型（LLMs）的兴起，研究人员正日益探索其在多个垂直领域的应用，软件工程便是其中之一。LLMs在代码生成和漏洞检测等领域取得了显著成就。然而，它们也表现出许多局限性和缺点。基于LLM的智能体作为一种新兴技术，具有实现人工智能通用（AGI）的潜力，通过将LLMs作为决策制定和行动执行的核心，缓解了LLMs固有的某些限制，如缺乏自主性和自我改进能力。尽管有大量的研究和调查探讨了在软件工程中使用LLMs的可能性，但目前在LLMs与基于LLM的智能体之间仍缺乏明确的区分。对于统一标准和基准测试来界定一个LLM解决方案是否能成为其领域内的基于LLM的智能体，这一领域还处于初级阶段。  本调查广泛研究了软件工程中LLMs及基于LLM的智能体当前的实践与解决方案。具体而言，我们总结了六个关键主题：需求工程、代码生成、自主决策、软件设计、测试生成以及软件维护。我们从这六个方面回顾并区分了LLMs与基于LLM的智能体的工作，考察了它们在任务、基准及评估指标上的异同。最后，我们讨论了所使用的模型和基准，对它们在软件工程中的应用及其有效性进行了全面分析。我们期待，这项工作能够为推动基于LLM的智能体在软件工程领域的未来发展提供新的视角。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够跳过模式链接环节，直接将完整的数据库模式传递给LLM，从而避免了信息缺失的风险。此外，作为模式链接的替代方案，我们提出了在不牺牲关键模式信息的前提下提升文本到SQL准确性的技术。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在各领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入地回顾这些技术的研究尚存较大空白。本调查文章旨在提供对模型融合方法及理论的综合概述，它们在多种领域及环境下的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，加剧了迫切需要解决这些偏见的问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型展现出的偏见极小，但某些模型仍表现出轻微的刻板印象或反刻板印象的倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。尽管之前的防御方法通过扰动或检查输入来缓解这些风险，但它们忽略了竞争目标这一对齐失败的根本原因。在本文中，我们提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新型防御方法，该方法利用自适应解码技术来解决越狱问题的根本原因。首先，我们定义了“竞争指数”来量化对齐失败，并利用自我评估的反馈来计算后对齐概率分布。随后，AED自适应地将AED和后对齐概率与原始概率结合，以获得无害且有益的概率分布。因此，我们的方法在保持有用性的同时增强了安全对齐。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，识别出的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效验证已识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗计划和资源分配等关键领域展现了强劲性能。   我们的多智能体CDSS显示了在支持全面紧急护理管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作对急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在语言模型领域，就地学习（In-context Learning，ICL）作为一种重要能力，随着大型语言模型（Large Language Models，LLMs）的发展而得到显著提升。通过采用少量示例作为演示，ICL使得LLMs能够在无需调整数百万参数的情况下，完成多样化任务。本论文介绍了一种针对LLMs的统一框架，该框架使模型能够自我挑选出构建上下文的关键在地示例、对不同演示组合的候选进行自排名，并通过强化学习来自我优化示例的选择及排序过程。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过由LLM自身偏好决定的奖励训练后，生成优化后的演示示例。实验结果验证了所提方法在提升ICL性能方面的确切效用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索过程中纳入更多多样性。|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的需求问题。我们通过实证发现，较新的模型在生成过程中能有效识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程可以完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了在不牺牲关键模式信息的前提下提升文本到SQL准确性的技术。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不涉及昂贵的计算成本。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然匮乏。本调查旨在提供对模型融合方法及理论、其在多种领域与场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的本质，常常展现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现出来，这凸显了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型如何回应来自不同人口群体的语音，我们旨在识别这些偏见。实验揭示了关于模型表现及偏见程度的重要见解。研究发现，尽管大多数模型显示出的偏见最小，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御手段通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一根本性对齐失败的原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本原因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率分布。随后，AED动态地将AED产生的概率分布与后对齐概率及原始概率分布相结合，从而获得既无害又有助益的输出分布。因此，我们的方法在保持有用性的同时增强了安全对齐。我们在五个模型上针对四种常见的越狱攻击进行了实验，结果验证了我们方法的有效性。相关代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|无人驾驶航空器（UAV）已成为下一代无线网络的关键组成部分，特别是在灾难恢复场景下，因其灵活性、移动性和快速部署能力而显得尤为重要。本文聚焦于利用太赫兹（THz）链路优化UAV轨迹，以确保灾区通信的有效性。我们面对的挑战包括能量消耗、用户优先级划分以及在复杂的城市场景中导航以保持视线（LoS）连接，同时规避三维障碍物。我们的贡献主要体现在三个方面：开发了基于在线三维地图数据的详细建模方法，提出了最优轨迹优化问题的数学模型，并设计了一种基于遗传算法（GA）的方法及一种增强型启发式算法以加速收敛过程。通过三维仿真，我们展示了在最小化总服务时间和优先保障更高权重节点之间的权衡，揭示了不同优先级权重因子对轨迹时间的影响。提出的算法采用卡塔尔多哈West Bay区域的真实世界数据进行评估，证明了其在紧急响应中优化UAV轨迹的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也极具挑战性。通过对评估结果的分析，我们识别出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏明确的完成标准，这意味着已识别的威胁需要经过验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项对照实验，旨在与从业者合作，探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们还分享了通过对41名理学硕士学生的初步试验所获得的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初始的复制包，包含了实验材料和数据分析脚本，并计划根据与从业者进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面的准确性表现出色。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强大的性能。   我们的多智能体CDSS显示了在支持全面紧急护理管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升文本到SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述性回顾尚存较大空白。本研究旨在通过一项综合调查来填补这一空缺，全面概述模型融合方法与理论、它们在不同领域及环境中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多种机器学习子领域的应用。最后，我们强调了模型融合仍面临的挑战，并讨论了未来的研究路径。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这迫切需要我们解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型如何响应来自不同人口群体的语音，我们旨在识别这些偏见。实验揭示了它们在性能和偏见程度上的重要见解。研究发现，虽然大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。尽管之前的防御方法通过扰动或检查输入来缓解这些风险，但它们忽略了竞争目标，这是对齐失败的根本原因。在本文中，我们提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新型防御方法，该方法利用自适应解码技术来解决越狱问题的根源。首先，我们定义了“竞争指数”来量化对齐失败，并利用自我评估的反馈来计算后对齐概率分布。随后，AED自适应地结合AED及后对齐概率与原始概率分布，以获得无害且有益的概率分布。因此，我们的方法在保持有用性的同时增强了安全对齐。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这削弱了其可靠性，对实际场景部署构成了严峻挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效路径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG接着利用领域特定知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，改善了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法评估MLLMs的理论理解与应用能力。我们对11个先进MLLMs进行了多维度评估，揭示即便对最复杂的模型而言，我们的基准测试也颇具挑战性。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，存在的一个问题是“完成定义”不明确，这导致已识别的威胁需要验证，从而减缓了分析过程。现有文献主要关注威胁分析的整体效能，却未曾探究分析师在验证所识别安全威胁之前，必须深入研究材料到何种程度。我们提出一项与从业者合作的控制实验，旨在研究某些分析材料（如LLM生成的建议）是否优于完全没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们分享了41名硕士研究生参与先导研究的关键发现，这些发现被用来改进实验设计。最后，我们提供了一个初步的复制包，包含了实验材料和数据分析脚本，并计划根据最终的从业者数据收集活动扩展其内容（例如，增加预筛选问题）。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及在重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的集成为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体应急护理管理。    我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。    模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强劲性能。    我们的多智能体CDSS显示了在支持全面应急照护管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤状况并提升患者结局。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大型语言模型（LLMs）的发展中，即时学习（ICL）展现出了重要的能力。通过采用少量示例作为演示，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文介绍了一个针对LLMs的统一框架，该框架使模型能够自我挑选有影响力的即时示例来构建其上下文；对不同演示组合的候选进行自排名；并通过强化学习来自我优化演示的选择及排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过由LLM自身偏好产生的奖励训练后，生成优化的演示。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中包含更多多样性。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在Text-to-SQL转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所必需的列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需明确的模式链接。这一发现使得Text-to-SQL管道能够完全绕过模式链接步骤，直接将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，能在不牺牲关键模式信息的前提下提升Text-to-SQL的准确性。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的技术综述存在较大空白。本调查旨在提供对模型融合方法及理论、其在多种领域与场景中的应用，以及未来研究方向的综合概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的本质，常常展现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现，突显了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，专门用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究结果表明，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效情况，并利用自我评估的反馈来计算后对齐概率分布。随后，AED通过自适应结合AED产生的概率分布、后对齐概率与原始概率分布，从而获得既无害又有助益的输出分布。因此，我们的方法在提升安全对齐的同时，保持了模型的有用性。我们在五个模型上针对四种常见的越狱攻击进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。增强LLMs的一种有效途径是结合外部数据库和信息检索机制。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，它将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过将知识图谱的结构化表示与密集向量检索的灵活性相结合，提高了LLM响应的准确性和可靠性。WeKnow-RAG随后利用领域特定的知识图谱应对多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还探讨了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现，并突出了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法评估MLLMs的理论理解与应用能力。我们对11个先进MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏明确的完成定义，这意味着已识别的威胁需要经过验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项对照实验，与从业人员合作，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初始复制包，包含实验材料和数据分析脚本，并计划根据与从业人员进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性给全球医疗系统带来了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急救护管理。   我们开发了一种多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急救护管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在语言模型领域，就地学习（In-context Learning，ICL）作为一种重要能力，随着大型语言模型（Large Language Models，LLMs）的发展而得到证实。通过采用少量示例进行演示教学，ICL使得LLMs能够在无需调整数百万参数的情况下，完成多样化任务。本论文介绍了一种针对LLMs的统一框架，该框架使模型能够自我挑选有影响力的在例示例来构建其上下文；对不同示范组合的候选进行自排名；并通过强化学习来自我优化示范选取与排序过程。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在LLM自身偏好的奖励训练后，生成最优化的示范。实验结果验证了所提方法在提升ICL性能方面的确切效用。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索中融入更多多样性。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的需求问题。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这让文本到SQL的处理流程能够完全绕过模式链接步骤，而是将完整的数据库模式传递给LLM，从而消除了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了在不牺牲关键模式信息的前提下提升文本到SQL准确性的技术。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|在不断进步的数字通信系统领域，复值神经网络（CVNN）已成为基石，尤其在均衡、信道估计、波束成形和解码等任务中展现出卓越性能。在众多CVNN架构中，相位传递径向基函数神经网络（PT-RBF）尤为突出，尤其在诸如5G MIMO系统这类噪声环境中表现优异。尽管其功能强大，但在多层、多输入多输出的PT-RBF中实现收敛仍是一大挑战。针对这一难题，本文提出了一种新颖的深度PT-RBF参数初始化技术。通过遵循3GPP TS 38标准的严格仿真，我们的方法不仅超越了传统初始化策略，如随机、K-均值和星座基方法，而且是唯一能在深度PT-RBF架构中实现成功收敛的方法。这些发现为复杂数字通信系统中更加稳健和高效的神经网络部署铺平了道路。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的技术综述存在较大空缺。本调查报告旨在提供对模型融合方法及理论、其在多种领域与环境中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，该方法详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多项机器学习子领域的应用。最后，我们指出了模型融合仍面临的挑战，并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往会表现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，这突显了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset这一数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了关于模型性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出的偏见最小，但某些模型仍表现出轻微的刻板印象或反刻板印象的倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。尽管先前的防御手段通过扰动或检查输入来缓解这些风险，但它们忽略了竞争目标这一根本性对齐失败原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”来量化对齐失效，并利用自我评估的反馈计算后对齐概率值。随后，AED灵活地将AED及后对齐概率值与原始概率值结合，以获得无害且有助的分布结果。因此，我们的方法在保持有用性的同时增强了安全对齐性能。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库与信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进一步利用领域特定知识图谱应对多样查询和领域需求，借助稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的表现。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评价其生成答案的可信度。广泛离线实验与在线提交证明了我们方法的杰出效能。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括不同类型的网络攻击和该领域常用的数据库背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和基于LLMs的IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题。最后，结论总结了发现成果，突出了Transformer和LLMs在网络威胁检测能力增强方面的重要性，并概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次化方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过分析评估结果，我们指出了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，识别出的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效验证已识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（系统数据流图与LLM生成的建议）是否优于少量材料。此外，我们分享了与41名理学硕士学生的试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一种多智能体CDSS，利用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型使用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急医疗服务管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的必要性。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了一些技术改进，旨在提升文本到SQL的准确性，同时确保不丢失重要的模式信息。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然匮乏。本调查旨在提供对模型融合方法与理论、其在多种领域及场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少量样本学习等在内的10多个机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于其训练数据的特性，往往展现出偏见。近期，更多的语音大型语言模型（SLLMs）涌现出来，强调了迫切需要解决这些偏见问题。本研究引入了Spoken Stereoset数据集，它专门设计用于评估SLLMs中的社会偏见。通过考察不同模型如何回应来自不同人口统计群体的语音，我们旨在识别这些偏见。实验揭示了它们的性能和偏见程度的重要见解。研究发现，尽管大多数模型显示出最小的偏见，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率分布。随后，AED通过自适应结合AED及后对齐概率与原始概率分布，以获得无害且有益的概率分布。因此，我们的方法在提升安全对齐的同时保持了帮助性。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）对自适应智能体的发展做出了巨大贡献，并被视为实现人工智能通用智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并经常生成“虚幻”内容，这严重削弱了其可靠性，对于在现实场景中的部署构成了重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种名为WeKnow-RAG的新方法，该方法将网络搜索和知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提高了LLM响应的准确性和可靠性。接着，WeKnow-RAG利用领域特定的知识图谱来满足多种查询和领域需求，通过采用稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理和复杂推理任务的性能。我们的方法有效平衡了信息检索的效率与准确性，从而改善了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其所生成答案的可信度。在广泛的离线实验和在线提交中，我们的方法证明了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对此领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及运用复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用。MathScape旨在评估基于照片的数学问题场景，通过分类层次化的方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|## 背景 在21世纪的乌干达，中学教育质量低下仍是面临的主要挑战之一，特别是在农村地区。研究揭示了多个问题，其中包括教师教案准备不足或缺失。随着政府推动实施新课程，现有的教案变得过时，问题愈发严重。针对这一情况，我们采用了一种检索增强生成的方法，开发了一个原型系统，能够根据政府认可的教科书生成定制化的教案。这有助于教师更高效、更高质量地制定教案，确保与新课程及能力本位学习方法完全接轨。  ## 方法 该原型系统利用Cohere大规模语言模型、句子嵌入技术以及LangChain框架开发，并公开发布于网站上。我们针对新课程的三本教科书（信息技术、数学、历史），均以中学一年级水平，训练了向量存储库。遵循教科书中建议的课时安排，通过伪随机生成协议，生成了24份教案。之后，依据Ndihokubwayo等人（2022）设计的适用于东非及能力本位课程的教案分析协议（LPAP），由三位独立评价员对这些教案的技术质量进行了分析。  ## 结果 运用LPAP对24份教案进行评估后，其平均质量达到了75%至80%，相当于“非常优秀的教案”。没有一份教案得分低于65%，尽管有一份教案的主题内容可能存在争议。总的来说，生成的教案质量至少与人工编写的教案相当，甚至更优。这从卢旺达的一项研究中得到印证，在该研究中，没有任何教案能达到50%的基准分数。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏一个明确的完成标准，这意味着已识别的威胁需要验证，这减缓了分析过程。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项对照实验，与从业人员合作，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们还分享了对41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含了实验材料和数据分析脚本，并计划根据与从业人员的最终数据收集活动（例如，预先筛选问题）来扩展该包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及在重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助急诊科医生和护士进行患者分诊、治疗规划及整体紧急护理管理。    我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫度量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。    模型使用Asclepius数据集进行评估，性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面表现出高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域展现了强劲性能。    我们的多智能体CDSS显示了在支持全面紧急医疗服务管理方面的巨大潜力。通过利用先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有前景的方向。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的元素（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本工作中，我们重新审视了在使用最新一代大型语言模型（LLMs）时，模式链接的需求。我们通过实证发现，较新的模型在生成过程中能自发识别相关的模式元素，无需明确的模式链接。这一发现使得文本到SQL的处理流程能够跳过模式链接环节，直接将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了若干技术改进，旨在提升文本到SQL的准确性，同时确保关键模式信息无损。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是一种高效的增强技术，在机器学习领域中日益受到重视，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在多个领域的应用愈发广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的技术综述存在较大空白。本研究旨在通过一项综合调查来填补这一空白，全面概述模型融合方法与理论、它们在不同领域及场景中的应用，以及未来的研究方向。具体而言，我们首先提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多种机器学习子领域的应用。最后，我们指出了模型融合存在的剩余挑战，并讨论了未来的研究路径。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在各类任务中取得了显著的性能，包括涉及多模态数据如语音的任务。然而，这些模型由于训练数据的特性，往往会表现出偏见。近期，更多针对语音的大型语言模型（SLLMs）涌现，加剧了迫切需要解决这些偏见的问题。本研究引入了Spoken Stereoset这一数据集，专门用于评估SLLMs中的社会偏见。通过考察不同模型对来自不同人口统计群体的语音的反应，我们旨在识别这些偏见。实验揭示了它们在表现和偏见程度上的重要见解。研究发现，尽管大多数模型展现出的偏见较小，但某些模型仍显示出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。首先，我们定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED产生的概率值、后对齐概率值与原始概率值，从而获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时增强了安全对齐。我们在五个模型和四种常见的越狱攻击上进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库与信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过结合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM回答的准确性和可靠性。WeKnow-RAG进一步利用领域特定知识图谱应对多样查询和领域需求，通过稀疏和密集检索方法的多阶段网页检索技术，提高了事实信息处理及复杂推理任务的表现。我们的方法有效平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评价其生成答案的可信度。广泛离线实验与在线应用证明了我们方法的卓越成效。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大型语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对这一领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次化方法来评估MLLMs的理论理解与应用能力。我们对11个先进的MLLMs进行了多维度评估，揭示即使对最复杂的模型而言，我们的基准测试也颇具挑战性。通过分析评估结果，我们识别了MLLMs的局限性，为提升模型性能提供了有价值的见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，由于缺乏“完成定义”，已识别的威胁需要验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效地验证所识别的安全威胁。  我们提出了一项基于实践者的控制实验，旨在探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（系统数据流图和LLM生成的建议）是否优于少量材料。此外，我们分享了与41名理学硕士学生的试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初步的复制包，包含实验材料和数据分析脚本，并计划根据与实践者进行的最终数据收集活动（例如，预筛选问题）来扩展其内容。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出潜力，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助ED医生和护士进行患者分诊、治疗规划及整体紧急护理管理。   我们开发了一种多智能体CDSS，使用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫性评估量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型采用Asclepius数据集进行评估，其性能由临床急诊医学专家评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现强劲。   我们的多智能体CDSS显示了在支持全面紧急护理管理方面的巨大潜力。通过利用先进的人工智能技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用领域的扩展做出了贡献，并为未来的研究和临床实施指明了有前景的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在大规模语言模型（LLMs）的发展中，情境学习（ICL）展现了显著的能力。通过采用少量示例的演示方法，ICL使LLMs能够在无需更新数百万参数的情况下，执行各种任务。本文介绍了一个针对LLMs的统一框架，使它们能够自选有影响力的示范性例句来构建上下文；对不同示范组合的候选进行自我排名；并通过强化学习来自我优化示范选取与排序。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过由LLM自身偏好产生的奖励训练后，生成优化的示范示例。实验结果验证了所提方法在提升ICL性能方面的作用。此外，我们的方法能有效识别并选取当前任务最具代表性的例子，并在检索中融入更多多样性。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|在文本到SQL的转换管道中，模式链接是关键步骤之一，该过程将自然语言查询转化为SQL。模式链接的目标是从中筛选出相关表格和列（信号），同时排除不相关的部分（噪声）。然而，不完美的模式链接常导致遗漏生成准确查询所需的关键列。本研究重新审视了在使用最新一代大型语言模型（LLMs）时，进行模式链接的需求。我们通过实证发现，较新的模型在生成过程中能熟练识别相关的模式元素，无需明确的模式链接。这使得文本到SQL的处理流程可以完全跳过模式链接步骤，而是将完整的数据库模式传递给LLM，从而避免了排除必要信息的风险。此外，作为模式链接的替代方案，我们提出了在不牺牲关键模式信息的前提下提升文本到SQL准确性的技术。我们的方法在BIRD基准测试上达到了71.83%的执行准确率，在提交时排名首位。|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|**模型融合是机器学习领域中一种高效的增强技术，它无需收集原始训练数据，也不需要昂贵的计算资源。随着模型融合在众多领域的应用日益广泛，全面理解现有的模型融合技术变得尤为重要。然而，目前在这一领域的文献中，系统且深入的综述工作仍然缺失。本调查文章旨在提供对模型融合方法及理论、其在各类领域与场景中的应用，以及未来研究方向的全面概述。首先，我们提出了一种新的分类方法，详尽地讨论了现有的模型融合技术。其次，我们探讨了模型融合技术在大型语言模型、多模态大型语言模型以及包括持续学习、多任务学习、少样本学习等在内的10多种机器学习子领域的应用。最后，我们指出了模型融合存在的挑战并讨论了未来的研究方向。关于模型融合的综合论文列表可参见\url{https://github.com/EnnengYang/Awesome-Model-Merging-Methods-Theories-Applications}。**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|null|警告：本文档可能包含令人不适的内容。大型语言模型（LLMs）在包括涉及多模态数据（如语音）的各种任务中取得了显著的性能，但由于其训练数据的特性，这些模型往往展现出偏见。近期，更多针对语音的大型语言模型（SLLMs）的出现，突显了迫切需要解决这些偏见问题。本研究引入了“口语刻板印象集”（Spoken Stereoset），这是一个专门设计来评估SLLMs中社会偏见的数据集。通过考察不同模型对来自不同人口群体的语音的反应，我们旨在识别这些偏见。实验揭示了关于它们的性能和偏见程度的重要见解。研究发现，虽然大多数模型显示出最少的偏见，但某些模型仍表现出轻微的刻板印象或反刻板印象倾向。|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|**大型语言模型易受到越狱攻击的影响，这可能导致生成有害内容。以往的防御方法通过扰动或检查输入来缓解这些风险，但忽略了竞争目标这一对齐失败的根本原因。本文提出了一种名为“对齐增强解码”（Alignment-Enhanced Decoding, AED）的新颖防御方法，该方法利用自适应解码技术来解决越狱问题的根本成因。我们首先定义了“竞争指数”以量化对齐失效，并利用自我评估的反馈来计算后对齐概率值。随后，AED通过自适应结合AED及后对齐概率值与原始概率值，以获得无害且有助益的概率分布。因此，我们的方法在保持有用性的同时，增强了安全对齐能力。我们在五个模型和四种常见的越狱攻击中进行了实验，结果验证了我们方法的有效性。代码可于https://github.com/GIGABaozi/AED.git获取。**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|大型语言模型（LLMs）极大地推动了自适应智能体的发展，并作为实现通用人工智能（AGI）的重要途径。然而，LLMs倾向于产生事实性错误信息，并常创造出“虚幻”内容，这严重削弱了其可靠性，对实际场景部署构成重大挑战。通过结合外部数据库和信息检索机制来增强LLMs是一条有效途径。针对上述挑战，我们提出了一种新方法——WeKnow-RAG，该方法将网络搜索与知识图谱融入“检索增强生成（RAG）”系统中。首先，通过整合知识图谱的结构化表示与密集向量检索的灵活性，提升LLM响应的准确性和可靠性。WeKnow-RAG进而利用领域特定知识图谱应对多种查询和领域需求，借助稀疏和密集检索方法的多阶段网页检索技术，改善事实信息处理和复杂推理任务的性能，有效地平衡了信息检索的效率与准确性，从而优化了整体检索过程。最后，我们还为LLM集成了自我评估机制，以评估其生成答案的可信度。我们的方法在广泛的离线实验和在线提交中验证了其卓越的有效性。|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|随着Transformer语言模型的显著进步，自然语言处理（NLP）因其在文本生成和用户交互方面的增强能力，已扩展到许多研究领域。网络安全是受益于这些进展的领域之一。在网络安全中，许多需要保护和在发送方与接收方之间交换的参数以文本和表格数据形式存在，这使得NLP成为加强通信协议安全措施的宝贵工具。本调查论文全面分析了Transformer和大规模语言模型（LLMs）在网络威胁检测系统中的应用。论文概述了论文选择和文献计量分析的方法论，以建立评估现有研究的严格框架。讨论了Transformer的基础知识，包括各种网络攻击和该领域常用数据集的背景信息。该调查着重探讨了Transformer在入侵检测系统（IDS）中的应用，关注了不同的架构，如基于注意力的模型、BERT和GPT等LLMs、CNN/LSTM-Transformer混合体，以及ViT等新兴方法。此外，它还研究了Transformer和LLMs基于IDS在多种环境和应用中的实施情况，涵盖计算机网络、物联网设备、关键基础设施保护、云计算、软件定义网络（SDN），以及自动驾驶汽车等领域。论文还针对该领域的研究挑战和未来方向进行了探讨，识别了诸如可解释性、可扩展性和对不断演变威胁的适应性等关键问题，以及其他要点。最后，结论总结了研究发现，并突显了Transformer和LLMs在增强网络威胁检测能力方面的重要性，同时概述了进一步研究和开发的潜在途径。|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|随着多模态大型语言模型（MLLMs）的发展，对多模态模型在数学问题情境下的评估已成为一个宝贵的研究领域。多模态视觉-文本数学推理能力是衡量MLLMs理解及进行复杂多步骤定量推理能力的关键指标。然而，以往的多模态数学基准测试并未充分融合视觉与文本信息。针对这一不足，我们提出了MathScape，一个新基准测试，着重于检验结合视觉与文本信息的理解与应用能力。MathScape旨在评估基于照片的数学问题场景，通过分类层次方法来评估MLLMs的理论理解与应用能力。我们对11个先进MLLMs进行了多维度评估，揭示即使是最复杂的模型也面临挑战。通过对评估结果的分析，我们指出了MLLMs的局限性，为提升模型性能提供了宝贵见解。|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|近期网络安全标准的出台提高了组织安全评估的门槛，但现有技术在扩展性上并不总是表现良好。威胁分析和风险评估被用于识别新系统或重构系统中的安全威胁。然而，目前缺乏明确的完成标准，这意味着已识别的威胁需要经过验证，这减缓了分析速度。现有文献主要关注威胁分析的整体效能，但尚未有研究探讨分析师必须深入到何种程度，才能有效验证所识别的安全威胁。  我们提议通过一项对照实验，与从业人员合作，来探究某些分析材料（如LLM生成的建议）是否优于没有材料，以及更多材料（包括系统数据流图和LLM生成的建议）是否优于较少材料。此外，我们分享了与41名硕士研究生进行试点研究的关键发现，这些发现被用来改进研究设计。最后，我们提供了一个初始复制包，包含实验材料和数据分析脚本，并计划根据与从业人员的最终数据收集活动（例如，预先筛选问题）来扩展该包，纳入新材料。|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|急诊科（ED）的过度拥挤以及重症监护环境中快速决策的复杂性对全球医疗系统构成了重大挑战。尽管临床决策支持系统（CDSS）已显示出前景，但大型语言模型（LLMs）的整合为提高分诊准确性和临床决策提供了新的可能。本研究介绍了一种由LLM驱动的CDSS，旨在辅助急诊科医生和护士进行患者分诊、治疗规划及整体应急护理管理。   我们开发了一个多智能体CDSS，采用Llama-3-70b作为基础LLM，通过CrewAI和Langchain进行协调。该系统包括四个模拟关键ED角色的AI代理：分诊护士、急诊医师、药剂师和ED协调员。它融入了韩国分诊与急迫度量表（KTAS）进行分诊评估，并与RxNorm API集成以支持药物管理。   该模型利用Asclepius数据集进行了评估，其性能由一名临床急诊医学专家进行了评定。与单智能体系统基线相比，CDSS在分诊决策方面展现了高准确性。此外，该系统在主要诊断、关键发现识别、处置决策、治疗规划和资源分配等关键领域表现出色。   我们的多智能体CDSS显示了在支持全面应急护理管理方面的巨大潜力。通过利用最先进的AI技术，该系统提供了一个可扩展和适应性强的工具，有可能改善急诊医疗服务的提供，缓解ED拥挤并提升患者预后。此项工作为急诊医学中AI应用的不断增长领域做出了贡献，并为未来的研究和临床实施指明了有希望的方向。|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|在语言模型领域，就地学习（In-context Learning，ICL）作为一种重要能力，随着大型语言模型（Large Language Models，LLMs）的发展而凸显其价值。通过采用少量示例进行演示教学，ICL使得LLMs能够在无需调整数百万参数的情况下，执行多样化的任务。本论文介绍了一个针对LLMs的统一框架，该框架使模型能够自我挑选出对其构成上下文有重大影响的示例，对不同示范组合的候选者进行自我排序，并通过强化学习自我优化示范选取及排序过程。具体而言，我们的方法设计了一个参数高效的检索头部，该头部在经过由LLM自身偏好产生的奖励训练后，生成优化后的示范示例。实验结果证实了所提方法能有效提升ICL的表现。此外，我们的方法能有效识别并选取当前任务最具代表性的示例，并在检索过程中融入更多多样性。|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|联邦学习（FL）通过协同训练机器学习模型，为个人数据提供了更好的隐私保护。当联邦学习参与者行使被遗忘权，即脱离已参与的FL框架并移除其对全局模型的过往贡献时，FL解决方案应执行所有必要步骤以实现该目标，同时不牺牲全局模型的整体性能，而当前最先进的相关方案尚不支持这一功能。本文提出了一种名为FedQUIT的新算法，利用知识蒸馏技术从FL全局模型中清除待遗忘数据的贡献，同时保持其泛化能力。FedQUIT直接在客户端设备上运行，与常规FL过程相比，无需共享额外信息，也不假设公开可用代理数据的存在。我们的解决方案高效、有效，适用于集中式和联邦式两种设置。实验结果表明，平均而言，FedQUIT在撤销后恢复泛化性能所需的额外通信轮次不到2.5%，得到的已消毒全局模型其预测效果可与从未接触待遗忘数据的全局模型相媲美。|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|物联网（IoT）设备在多个领域的迅速普及引发了严重的网络安全问题，这促使了针对网络攻击分类的基于机器学习（ML）的入侵检测系统（IDS）的持续研究。传统ML模型需要将数据从IoT设备传输到集中式服务器进行流量分析，这引发了严重的隐私担忧。为了解决这一问题，研究人员已探索使用联邦学习（FL）构建IDS，该方法能在保持设备数据本地化的同时，在IoT设备间训练模型。然而，由于设备的不同漏洞和攻击向量的复杂性导致的数据异质性，对FL模型的有效性构成了重大挑战。当前研究虽聚焦于在FL框架内调整各种ML模型，但未能有效应对设备间攻击类别不平衡的问题，这一问题显著降低了少数攻击的分类准确性。为克服这一挑战，我们引入了FedMADE，一种新颖的动态聚合方法，它根据设备的流量模式对其进行聚类，并根据其对整体性能的贡献来聚合局部模型。我们在实验中将FedMADE与其他针对非独立同分布（non-IID）数据设计的FL算法进行对比，观察到少数攻击分类准确率提高了高达71.07%。此外，我们还展示FedMADE对中毒攻击具有鲁棒性，并且相比FedAvg，每轮通信仅增加4.7%（5.03秒）的延迟开销，同时不增加IoT设备的计算负担。|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|联邦学习（FL）旨在解决由隐私、安全法规及所有权顾虑所导致的数据孤岛问题。尽管存在这些障碍，FL仍能使这些孤立的数据存储库在不损害隐私或安全的前提下参与协同学习。同时，区块链技术的进步以及Web 3.0时代中去中心化应用（DApps）的发展，为网络开发带来了变革性的可能。因此，将FL融入Web 3.0为通过协同学习克服数据孤岛限制铺平了道路。然而，鉴于以太坊（ETH）等核心区块链的交易速度限制及智能合约的延迟，采用一次性联邦学习（one-shot FL）——即将传统FL中的客户端-服务器交互减少到单次交换——更适合Web 3.0环境。本文提出了一种针对Web 3.0实用的一次性联邦学习系统，称为OFL-W3。OFL-W3利用区块链技术，通过智能合约管理交易，同时结合使用星际文件系统（IPFS）与Flask通信，以支持后端服务器操作并采用现有的一次性FL算法。通过集成激励机制，OFL-W3展示了一种在Web 3.0上有效实施一次性联邦学习的方法，为AI与Web 3.0结合的研究提供了宝贵见解及未来方向。|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|卫星任务设计正经历从传统的单一大型卫星向由多颗小型卫星组成的分布式任务配置的范式转变。随着目前轨道上部署的这类卫星数量迅速增加，每颗卫星都在收集大量数据，对轨上边缘计算的兴趣日益增长。联邦学习是一种有前景的分布式计算方法，在此背景下，可使多颗卫星高效协作，进行船上机器学习模型的训练。尽管近期关于在轨道边缘计算中使用联邦学习的研究主要集中在同质卫星星座上，但联邦学习同样可以应用于异构卫星之间形成临时协作的场景，例如由不同运营商运营的通信卫星。此类应用向联邦学习范式提出了额外挑战，这些挑战主要源自系统的异构性。在这篇立场论文中，我们针对跨供应商应用场景，系统地回顾了这些挑战，对每一项挑战的现状进行了简要概述，并为深入探讨每个问题提供了入口。|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|分布式联邦学习（FL）范式基于区块链架构构建，利用分布式节点集群替代单一服务器执行FL模型聚合。这一范式解决了原始FL中集中式恶意服务器的脆弱性问题，并继承了区块链所提供的可信度与韧性。然而，现有的区块链支持方案在模型保密性和区块链执行大规模FL计算的有限计算资源方面面临挑战。本文提出了Voltran，一个创新的混合平台，旨在通过可信执行环境（TEE）与区块链技术的结合，为基于FL的学习实现信任、保密性和韧性。我们将在TEE中卸载FL聚合计算以提供一个隔离的、可信的和可定制的链下执行环境，并确保聚合结果在区块链上的真实性和可验证性。此外，我们通过引入多SGX并行执行策略来分摊大规模FL工作负载，从而为多种FL场景提供了强大的可扩展性。我们实现了Voltran的原型并进行了全面的性能评估。广泛的实验结果表明，Voltran在保证信任、保密性和真实性的同时，仅带来极小的额外开销，并且相比最先进的密文聚合方案显著加速。|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|联邦学习（FL）是一种分布式机器学习方法，它使设备能够在不共享本地数据的情况下协作训练模型，从而确保用户隐私和可扩展性。然而，将FL应用于现实世界数据面临着挑战，特别是因为现有的大多数FL研究集中在单模态数据上。多模态联邦学习（MFL）应运而生以应对这些挑战，利用模态特定的编码器模型来处理多样化的数据集。当前的MFL方法通常统一地分配所有模态的计算频率，这对于资源有限的IoT设备而言效率低下。在本文中，我们提出了FlexMod，这是一种新颖的方法，通过根据各模态编码器的重要性和训练需求自适应地分配训练资源，来增强MFL中的计算效率。我们采用原型学习来评估模态编码器的质量，使用Shapley值来量化每个模态的重要性，并采纳深度强化学习中的深度确定性策略梯度（DDPG）方法来优化训练资源的分配。我们的方法优先考虑关键模态，优化模型性能和资源利用。在三个真实世界数据集上的实验结果表明，我们提出的方法显著提高了MFL模型的性能。|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|分布式健康智能网络（DHIN）是一个理论框架，旨在解决因医疗数据在各提供者与机构间碎片化而导致的健康数据主权和人工智能在医疗领域应用的重大挑战。该框架首先确立了医疗服务的主权架构作为构建主权健康网络的前提，随后通过克服访问多样化医疗数据源的障碍来促进人工智能的有效利用。这一综合框架利用以下三个核心要素：1）结合个人健康记录（PHR）的自我主权身份架构，作为实现健康数据主权的基础；2）在公共区块链上实施的可扩展联邦学习（FL）协议，用于去中心化的医疗人工智能训练，其中健康数据保留在参与者手中，仅共享模型参数更新；3）一个可扩展且无需信任的奖励机制，激励参与并确保奖励公平分配。该框架确保没有任何实体能够阻止或控制对参与者提供的健康数据进行训练的访问，或决定经济利益分配，因为这些过程都在具有不可篡改记录的公共区块链上操作，无需第三方介入。它支持在医疗领域进行有效的人工智能训练，使患者能够保持对其健康数据的控制，获得经济利益，并为利用集体智能开发有益于医疗健康的算法贡献于一个去中心化、可扩展的生态系统。作为参与联邦学习协议的激励，患者会收到数字钱包中的奖励，其长期规划旨在为去中心化保险解决方案提供资金支持。这种方法引入了一种新颖的自筹资金医疗模式，该模式适应个人需求，补充现有体系，并重新定义了全民医疗覆盖的概念。它强调了转变医疗数据管理和人工智能应用潜力的同时，增强了患者的自主权。|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|在金融和医疗等高度受监管的行业领域，数据治理面临严峻挑战，数据的交换与利用尤为困难。联邦学习（FL）作为一种创新的分布式机器学习范式，能够在多个机构间进行协作式模型训练，同时保持数据分散，从而缓解了这一难题。尽管FL具有诸多优势，但它在模型聚合阶段（通常由中心服务器管理）易受到对抗性威胁，尤其是中毒攻击。此外，神经网络模型仍可能无意中记忆并潜在暴露个别训练实例，这构成了重大的隐私风险，攻击者可能利用模型内部蕴含的信息重建私人数据。现有解决方案未能提供一个既完全防止信息泄露又兼具计算效率的实用化隐私保护联邦学习系统。针对这些顾虑，我们提出了Lancelot这一创新且计算高效的增强型联邦学习框架，它利用全同态加密（FHE）技术来防御恶意客户端行为，同时确保数据隐私。通过在医疗影像诊断和广泛使用的公开图像数据集上的大量测试，我们证明Lancelot显著超越现有方法，处理速度提升超过二十倍，同时确保了数据隐私的安全。|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|null|心血管疾病是全球范围内导致死亡的主要原因，强调了准确诊断方法的重要性。本研究利用UCI数据集，该数据集包含来自美国、匈牙利和瑞士四家医院的920份患者记录，对心脏疾病分类中的集中式和联邦机器学习算法进行了基准测试。该基准测试得到了Shapley值可解释性分析的支持，以量化特征在分类中的重要性。在集中式设置中，使用多种二元分类算法对汇总数据进行训练，其中支持向量机（SVM）达到了最高的测试准确率83.3%，超过了使用逻辑回归建立的78.7%的基准。此外，考虑到数据集的自然划分，我们还探索了联邦学习算法，以四个客户端（医院）的形式存在，旨在增强隐私保护的同时不牺牲准确性。其中，联邦SVM作为一种文献中少见的方法，达到了73.8%的最高测试准确率。我们的可解释性分析与现有的心脏病指标医学知识相吻合。总的来说，本研究为高效且可解释的心脏病预筛查工具建立了基准，同时维护了患者的隐私。|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|**联邦学习（FL）在面临拜占庭攻击时变得尤为脆弱，这种情况下，部分参与者通过发送恶意模型更新以损害模型的效用或阻碍模型的收敛。以往的研究提出采用鲁棒性规则来聚合参与者的更新，以抵御不同类型的拜占庭攻击；然而，攻击者也能针对已知的具体聚合规则设计更高级的拜占庭攻击算法。实际上，联邦学习系统可能包含一个黑盒服务器，该服务器使得所采用的聚合规则对参与者不可访问，这自然能防御或削弱某些拜占庭攻击。本文深入探讨了配备黑盒服务器的联邦学习系统的拜占庭健壮性。我们的研究显示，采用动态防御策略的黑盒服务器能显著提升对抗拜占庭攻击的鲁棒性。我们通过实证证据和理论分析揭示，黑盒服务器能够将最坏情况下的攻击影响从最大级别缓解至预期级别，这一成效归因于黑盒服务器固有的不可访问性和随机性所提供的保护。为了促进社区内的进一步研究，相关源代码已开源，可于https://github.com/alibaba/FederatedScope/tree/Byzantine_attack_defense获取。**|

<p align=right>(<a href=#updated-on-20240815>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

