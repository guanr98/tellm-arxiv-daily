[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.22
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|**大型语言模型（LLMs）在视觉与语言导航（VLN）任务中展现出潜力，但当前应用面临挑战。尽管LLMs在一般对话场景中表现出色，它们在专门的导航任务上表现挣扎，相比专门的VLN模型，其性能次优。我们引入了FLAME（FLAMingo架构的多模态实体代理），一种针对城市VLN任务设计的新型多模态LLM基代理及架构，能高效处理多重观察。我们的方法采用了一种三阶段调优技术，以便有效适应导航任务，这包括单感知调优以进行街景描述、多感知调优以实现轨迹总结，以及在VLN数据集上的端到端训练。增强的数据集通过自动化方式合成。实验结果表明，FLAME相比现有方法具有优越性，在Touchdown数据集上任务完成率提高了7.3%，超越了最先进方法。此工作彰显了多模态大型语言模型（MLLMs）在复杂导航任务中的潜力，标志着向实用化MLLMs在具身AI领域应用的迈进。项目页面：https://flame-sjtu.github.io**|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|由于突发的性能提升，大型语言模型（LLMs）已被用作基于语言的智能体，以执行各种任务并展现出越来越高的自主决策能力。这些自主智能体能够理解高级指令，与环境互动，并利用一系列可用工具执行复杂任务。随着智能体能力的扩展，确保其安全性和可信度变得尤为重要。本研究中，我们引入了Athena框架，该框架利用了言语对比学习的概念，即利用过去安全和不安全的行为轨迹作为上下文（对比）示例，指导智能体在完成指定任务的同时趋向安全操作。此外，框架还融入了一个评判机制，以便在每一步操作中指导智能体避免风险行为。鉴于目前缺乏针对基于LLM智能体安全推理能力的评估基准，我们汇编了一套包含8个类别、180个场景的80个工具包集，作为安全评估的基准数据集。我们的实验评估，涵盖了封闭源和开源的LLMs，表明言语对比学习及交互层面的评判机制能显著提高安全执行率。|
|**2024-08-19**|**IDEA: Enhancing the rule learning ability of language agent through Induction, DEuction, and Abduction**|Kaiyu He et.al.|[2408.10455](http://arxiv.org/abs/2408.10455)|null|尽管大型语言模型（LLMs）在演绎和归纳推理方面的评估已经相当全面，但它们在互动环境中进行溯因推理与整体规则学习的能力探索尚不充分。本研究引入了RULEARN，一个专为评估LLMs在交互式场景下规则学习能力的新基准。在RULEARN中，代理通过与环境互动收集观察并洞察规律，利用这些见解解决问题。为了进一步提升LLM代理在该基准中的规则学习能力，我们提出了IDEA代理，它整合了归纳、演绎及溯因过程。IDEA代理通过采用结构化的推理序列来优化这一方法：通过溯因生成假设，借助演绎进行测试，并根据归纳反馈进行精炼。这一序列使代理能够动态建立并应用规则，模拟人类的推理过程。我们对五种代表性的LLMs进行的评估显示，虽然这些模型能生成貌似合理的初始假设，但它们在环境中的策略性互动、有效整合反馈以及假设的适应性细化方面常常面临挑战。IDEA代理在RULEARN基准上展示了显著提升的性能，为开发能够在现实世界情境中进行类似人类规则学习的代理提供了宝贵启示。我们将公开代码和数据。|
|**2024-08-20**|**MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems**|Qian Wang et.al.|[2408.09955](http://arxiv.org/abs/2408.09955)|null|随着大型语言模型（LLMs）的兴起，基于LLM的多智能体系统（LLM-MA系统）被提出以应对现实任务。然而，这些系统中的智能体大多遵循预定义的标准操作程序（SOPs），在交互过程中保持不变，缺乏自主性和可扩展性。此外，当前解决方案往往忽视了智能体间有效合作的需求。为了解决上述局限性，我们提出了MegaAgent框架，一个专为大规模LLM智能体系统中自主合作设计的实用框架。MegaAgent利用智能体的自主性，根据任务需求动态生成智能体，融入了自动任务分配、系统化规划与监控智能体活动以及管理并发操作等功能。此外，MegaAgent采用层次化结构设计，并利用系统级并行性来提升性能和加强通信效率。我们通过五子棋游戏开发展示了MegaAgent的有效性，表明其性能超越了流行的LLM-MA系统；并通过国家政策模拟，证明了其高度自主性及快速扩容至590个智能体的能力，同时确保它们之间的有效协作。我们的结果表明，MegaAgent是首个无预设SOP、具备高效性和高可扩展性的自主大规模LLM-MA系统，为该领域的进一步研究铺平了道路。我们的代码位于https://anonymous.4open.science/r/MegaAgent-81F3。|
|**2024-08-19**|**GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making**|Arsham Gholamzadeh Khoee et.al.|[2408.09785](http://arxiv.org/abs/2408.09785)|null|在汽车行业中，传统的软件部署决策方法通常依赖于手动分析软件测试的表格数据。这些方法因其劳动密集型的特点，往往导致成本增加和软件发布周期的延迟。大型语言模型（LLMs）为解决这些挑战提供了有前景的方案。然而，它们的应用通常需要多轮人为驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠且高效结果的工业终端用户而言。在本文中，我们提出了GoNoGo，一个旨在简化汽车软件部署流程的同时满足功能需求和实际工业约束的LLM代理系统。与以往系统不同，GoNoGo特别针对领域特定和风险敏感系统进行了定制。我们使用来自工业实践的零样本和少量样本，跨不同任务难度对GoNoGo的性能进行了评估。结果显示，GoNoGo在使用3个样本的情况下，对于难度达到第2级别的任务实现了100%的成功率，并且即使面对更复杂的任务，也保持了高水准的表现。我们发现，GoNoGo能有效自动化简单任务的决策过程，大幅减少了人工干预的需求。总之，GoNoGo代表了一种高效且用户友好的基于LLM的解决方案，目前已被我们的工业合作伙伴公司采用，以辅助进行软件发布决策，支持对风险敏感的车辆系统发布过程中的更加明智且及时的决策。|
|**2024-08-18**|**HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model**|Mengkang Hu et.al.|[2408.09559](http://arxiv.org/abs/2408.09559)|**[link](https://github.com/hiagent2024/hiagent)**|**基于大型语言模型（LLM）的智能体在众多领域展现出巨大潜力，它们作为交互系统运作，处理环境观察以生成针对目标任务的可执行动作。这些智能体的效能极大程度上取决于其记忆机制，该机制将历史经验记录为动作-观察对的序列。记忆可分为两类：跨试次记忆，横跨多次尝试累积；以及试次内记忆（工作记忆），在单次尝试中累积。尽管大量研究已通过优化跨试次记忆来提升性能，但通过改善工作记忆利用以增强智能体性能的研究仍较少探索。现有方法常常涉及将整个历史动作-观察对直接输入到LLMs中，这在长 horizon 任务中导致了冗余。受人类问题解决策略启发，本论文介绍了一种名为HiAgent的框架，它利用子目标作为记忆块来对LLM智能体的工作记忆进行层次化管理。具体而言，HiAgent促使LLMs在生成可执行动作前先制定子目标，并使LLMs能够主动决定用总结过的观察结果替换先前的子目标，仅保留与当前子目标相关的动作-观察对。跨五个长 horizon 任务的实验结果显示，HiAgent使得成功率提高了两倍，并将所需的平均步数减少了3.8步。此外，我们的分析表明，HiAgent在不同步骤上持续提升性能，彰显了其稳定性和泛化能力。项目页面：https://github.com/HiAgent2024/HiAgent 。**|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应的传感器数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、眼动以及XR环境中的上下文记忆中隐式提取情境。这最大限度地减少了对人为设计的明确提示的依赖，促进了根植于现实且直观的交互，从而为聊天机器人捕捉用户的意图。用户研究表明，我们的方法即将实现，对简化XR中与聊天机器人的用户交互具有变革性潜力，并为未来XR融合型LLM代理的设计提供了洞见。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担不仅使设计过程复杂化，还阻碍了建筑设计行业采用BIM及基于模型的设计方法。为更直观地表达设计意图，我们提出了一种名为Text2BIM的框架，该框架基于大型语言模型（LLM），能够根据自然语言指令生成三维建筑模型。此框架协调多个LLM代理进行协作和推理，将用户文本输入转化为调用BIM创作工具API的指令性代码，直接在软件中生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，我们还在代理工作流程中融入了基于规则的模型检查器，利用预定义的领域知识指导LLM代理识别并解决生成模型中的问题，从而迭代提升模型质量。通过大量实验，我们对比分析了三种不同LLM在所提框架下的性能。评估结果显示，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入的抽象概念保持一致。最后，我们开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的可能性。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个重大挑战。传统的静态数据监督预训练无法赋予代理在网页导航等动态场景中进行复杂决策所需的自主能力。以往通过在专家演示的监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为了克服这些挑战，我们提出了一种框架，该框架结合了引导式的蒙特卡洛树搜索（MCTS）与自我批评机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和强化微调基线，并在具备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升到81.7%（相对增长340%），仅经过一天的数据收集后，进一步提升至95.4%配合在线搜索。我们认为，这标志着自主代理能力的重大飞跃，为现实世界环境中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架在不同任务上的能力各异，有的任务表现优异，而在其他任务上则表现不佳。为了充分利用这些代理的独特专长，我们提出了DEI（多样性赋能智能）这一框架，它能利用它们各自的专业知识。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上最大个体解决率为27.3%，而通过DEI可以达到34.3%的解决率，实现了25%的提升，并超过了大多数闭源解决方案。我们表现最好的群体以55%的解决率脱颖而出，在SWE-Bench Lite上占据榜首位置。我们的研究发现为协作AI系统解决复杂软件工程挑战的潜力提供了重要贡献。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-20**|**Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks**|Nathaniel Pinckney et.al.|[2408.11053](http://arxiv.org/abs/2408.11053)|null|大型语言模型（LLMs）在数字硬件代码生成领域的应用是一个新兴的领域。大多数LLMs主要接受自然语言和软件代码的训练，而硬件代码（如Verilog）在训练数据中所占比例很小，且鲜有硬件基准测试存在。为了填补这一空白，开源的VerilogEval基准于2023年发布，它为评估LLMs在代码补全任务中的表现提供了一个统一的框架，并在当时对最先进的模型包括GPT-4进行了测试。然而，VerilogEval及其他Verilog代码生成基准缺乏故障分析能力，且目前形式不利于探索提示技术。此外，自VerilogEval发布以来，不论是商业还是开源模型都持续进行了发展。    本工作中，我们利用一个改进后的VerilogEval基准套件，对新型商业及开源模型（涵盖不同规模）进行了评估。我们通过自动分类失败案例来增强VerilogEval的基础设施和数据集，引入了新的提示以支持上下文学习（ICL）实例，并将支持的任务扩展到了规格至RTL（寄存器传输级）转换。我们发现，最前沿的商业模型有显著提升，其中GPT-4 Turbo在规格至RTL任务上达到了59%的通过率。同时，我们也研究了新近发布的开源及领域特定模型的表现，证明模型能从ICL中显著获益。我们发现，最新发布的Llama 3.1 405B模型在该任务上的通过率为58%，几乎与GPT-4 Turbo持平，而小得多的领域特定模型RTL-Coder 6.7B也取得了令人印象深刻的37%的通过率。然而，良好的通过率高度依赖于提示工程，且这一需求随着模型和任务的不同而大相径庭。一个支持提示工程和故障分析的基准测试基础设施对于模型的持续开发和部署至关重要。|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|**大型语言模型（LLMs）在视觉与语言导航（VLN）任务中展现出潜力，但当前应用面临挑战。尽管LLMs在一般对话场景中表现出色，它们在专门的导航任务上表现挣扎，相比专门的VLN模型，其性能次优。我们引入了FLAME（FLAMingo架构的多模态实体代理），一种针对城市VLN任务设计的新型多模态LLM基代理及架构，能高效处理多重观察结果。我们的方法采用了一种三阶段微调技术以有效适应导航任务，包括单感知微调用于街景描述、多感知微调用于轨迹概括，以及在VLN数据集上的端到端训练。增强的数据集通过自动方式合成。实验结果表明，FLAME相较于现有方法的优越性，在Touchdown数据集上的任务完成率提高了7.3%，超越了最先进方法。此工作彰显了多模态大型语言模型（MLLMs）在复杂导航任务中的潜力，标志着向实用化MLLMs在具身AI领域应用的进步。项目页面：https://flame-sjtu.github.io**|
|**2024-08-21**|**MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**|Jian Chen et.al.|[2408.11049](http://arxiv.org/abs/2408.11049)|null|大型语言模型（LLMs）在长上下文应用中日益普及，如交互式聊天机器人、文档分析和代理工作流程，但以低延迟和高吞吐量服务于长上下文请求仍具挑战性。推测性解码（SD）是一种广泛用于降低延迟而不牺牲性能的技术，但传统观点认为其有效性仅限于小批次大小。在MagicDec中，我们出人意料地展示，即使在中等到长序列上，SD也能在高吞吐量推理场景下实现加速。更有趣的是，基于我们严谨的分析，一种智能的草稿策略能够随着批次大小的增加而实现更好的加速效果。MagicDec首先识别随着批次大小和序列长度增加时的瓶颈转移，并利用这些洞察更有效地为高吞吐量推理部署推测性解码。接着，它利用具有稀疏KV缓存的草稿模型来解决随序列长度和批次大小扩展的KV瓶颈问题。这一发现强调了推测性解码在长上下文服务中的广泛应用潜力，因为它可以在不牺牲准确性的前提下提高吞吐量并减少延迟。对于中等到长序列，我们在8块NVIDIA A100 GPU上服务从32到256的批次大小时，展示了对LLaMA-2-7B-32K高达2倍的加速和对LLaMA-3.1-8B高达1.84倍的加速。相关代码可于https://github.com/Infini-AI-Lab/MagicDec/获取。|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|定性数据的收集与分析方法，如访谈和焦点小组，能深入揭示顾客的态度、情感及行为，但手动分析此类数据需耗费大量时间和精力以识别相关主题及意涵。本研究提出一种创新方法，旨在利用基于检索增强生成（RAG）的大型语言模型（LLMs）来分析访谈记录，以应对上述挑战。该研究新颖之处在于，将研究设计构想为一个由LLM辅助的过程，该模型扮演初级定性研究助理的角色。研究探索了LLMs的心智模型，以期其能服务于人才管理领域研究员，作为初级定性研究助手。通过扩展RAG架构下的LLM应用，本研究实现了对半结构化访谈数据的主题建模，展示了这些模型在信息检索与搜索之外的广泛应用潜力。研究发现，LLM增强的RAG方法能有效提取关注主题，并与人工从相同数据集中提炼的主题有显著的覆盖度比较，从而证明了采用LLM作为初级定性研究助理的可行性。此外，本研究建议采用这类模型的研究者应严格遵循传统定性研究中的质量标准，以确保方法的严谨性和可信度。最后，论文为行业实践者提供了关键建议，旨在调和LLMs的使用与既定的定性研究范式，为这些强大而新颖的AI工具在人才管理领域的定性数据分析中有效整合，绘制出实施路径图。|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|由于突现的能力，大型语言模型（LLMs）已被用作基于语言的智能体，以执行各种任务并展现出越来越高的自主决策能力。这些自治智能体能够理解高级指令，与环境互动，并利用可选工具执行复杂任务。随着智能体能力的扩展，确保其安全性和可信度变得愈发关键。本研究中，我们引入了Athena框架，该框架利用了言语对比学习的概念，即利用过去安全和不安全的行为轨迹作为上下文（对比）示例，引导智能体在完成指定任务的同时趋向安全。此外，框架还融入了一个评判机制，以便在每一步操作中指导智能体避免风险行为。鉴于目前缺乏对基于LLM智能体安全推理能力的评估基准，我们编纂了一套包含8个类别、180个场景的80个工具包集合，作为安全评估的基准。我们的实验评估，涵盖封闭源码和开源LLMs，表明言语对比学习及交互层面的评判显著提升了安全率。|
|**2024-08-20**|**While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?**|Wen Cheng et.al.|[2408.11006](http://arxiv.org/abs/2408.11006)|**[link](https://github.com/sensente/security-attacks-on-lccts)**|**大型语言模型（LLMs）的迅速发展极大地推动了代码补全功能的进步，催生了新一代基于LLM的代码补全工具（LCCTs）。与通用型LLMs不同，这些工具具有独特的处理流程，整合多种信息来源作为输入，并优先考虑代码建议而非自然语言交互，这引入了特殊的安保挑战。此外，LCCTs常依赖专有的代码数据集进行训练，引发了对敏感数据可能泄露的担忧。本文针对LCCTs的这些独特特征，开发了针对两大关键安全风险——越狱攻击和训练数据提取攻击的定向攻击方法。实验结果显示，LCCTs存在显著漏洞，包括在GitHub Copilot上实施越狱攻击的成功率达到99.4%，以及在Amazon Q上的成功率达到了46.3%。此外，我们成功地从GitHub Copilot中提取到敏感用户数据，涉及54个真实的电子邮件地址和与GitHub用户名关联的314个物理地址。本研究还证明，这些基于代码的攻击手段同样能有效作用于GPT系列等通用型LLMs，揭示了现代LLMs处理代码时存在的广泛安保失衡问题。这些发现突显了与LCCTs相关的重大安保挑战，并指出了加强其安保框架的紧迫方向。我们的研究代码及攻击样本已提供在https://github.com/Sensente/Security-Attacks-on-LCCTs。**|
|**2024-08-20**|**CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models**|Michael Reinisch et.al.|[2408.10995](http://arxiv.org/abs/2408.10995)|null|新药研发过程中需经历多个临床试验阶段，而即便投入大量人力与财力，仍仅有不到20%的药物能从一期试验推进至最终批准。近期文献指出，试验方案的设计对试验成效有重大影响。我们针对临床试验结果预测（CTOP）进行研究，旨在利用试验设计文件自动预测各阶段过渡。我们提出CTP-LLM模型，首个基于大型语言模型的CTOP解决方案，并引入PhaseTransition（PT）数据集，该数据集依据试验在监管流程中的进展进行标注，成为CTOP评估的基准。我们的模型基于GPT-3.5进行了微调（CTP-LLM），能够通过分析试验原始协议文本预测临床试验阶段转换，无需人工选取特征。CTP-LLM在预测所有阶段试验过渡时达到67%的准确率，尤其在预测从三期到最终批准的过渡上，准确率高达75%。实验结果彰显了基于LLM的应用在预测临床试验结果及评估试验设计潜力方面的广阔前景。|
|**2024-08-20**|**Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models**|Yuyan Chen et.al.|[2408.10947](http://arxiv.org/abs/2408.10947)|null|教师在传授知识和引导学习者方面至关重要，而大型语言模型（LLMs）作为潜在教育者的角色正成为一个重要研究领域。认识到LLMs生成教育内容的能力可促进自动化和个性化学习的发展。尽管LLMs在理解与问题解决能力方面已经过测试，但其教学能力仍未得到充分探索。在教学过程中，提问是一项关键技能，能够引导学生分析、评估和综合核心概念及原理。因此，我们的研究引入了一项基准，旨在通过评估LLMs生成的教育问题，利用Anderson和Krathwohl的分类法跨学科、单学科和交叉学科领域来评价LLMs作为教师的提问能力。我们从LLMs作为学习者转向将其视为教育者，通过指导其生成问题来评估其教学能力。我们应用了四个指标，包括相关性、覆盖范围、代表性与一致性，来评估LLMs输出的教育质量。结果显示，GPT-4在教授通用知识、人文和社会科学课程方面显示出巨大潜力；而Claude2则更适合作为跨学科教育者。此外，自动评分与人类观点一致。|
|**2024-08-20**|**HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments**|Kazi Hasan Ibn Arif et.al.|[2408.10945](http://arxiv.org/abs/2408.10945)|**[link](https://github.com/hasanar1f/hired)**|**高分辨率视觉-语言模型（VLM）被广泛应用于多模态任务中，通过保留图像的详细信息来提高准确性。然而，这些模型往往会因对输入图像的多个分区进行编码而生成过多的视觉令牌，处理这些过多的视觉令牌在计算上极具挑战性，特别是在配备有商品级GPU的资源受限环境下。为了在满足资源约束的同时支持高分辨率图像，我们提出了高分辨率早期丢弃（HiRED）策略，这是一种在大型语言模型（LLM）阶段前、遵循固定令牌预算的令牌丢弃方案。HiRED能够以即插即用的方式与现有的高分辨率VLMs集成，无需额外训练，同时仍能保持优越的准确性。我们策略性地利用视觉编码器在初始层的注意力来评估每个图像分区的视觉内容，并据此分配令牌预算。然后，利用最终层的注意力，我们在每个分区的分配预算内选择最重要的视觉令牌，丢弃其余部分。实验结果显示，在NVIDIA TESLA P40 GPU上将HiRED应用于LLaVA-Next-7B时，使用20%的令牌预算，令牌生成吞吐量提高了4.7倍，首个令牌生成的延迟减少了15秒，并且为单次推理节省了2.3 GB的GPU内存。**|
|**2024-08-20**|**SysBench: Can Large Language Models Follow System Messages?**|Yanzhao Qin et.al.|[2408.10943](http://arxiv.org/abs/2408.10943)|**[link](https://github.com/pku-baichuan-mlsystemlab/sysbench)**|**大型语言模型（LLMs）在众多应用中已成为不可或缺的工具，针对特定场景对这些模型进行定制日益关键。系统消息作为LLMs的基本构成部分，包含了精心设计的指导指令，旨在引导模型行为以达成既定目标。尽管认识到系统消息在优化AI驱动解决方案中的潜在价值，目前尚缺乏一个全面的基准来评估不同LLMs遵循这些系统消息的能力。为了填补这一空白，我们引入了SysBench，一个用于系统性分析LLMs遵循系统消息能力的基准，尤其针对三个具有挑战性的方面：约束复杂度、指令偏离及多轮对话稳定性。SysBench通过构建涵盖多种交互关系的多轮用户对话，基于实际应用场景中系统消息里常见的六种约束类型，来实现有效评估。我们的数据集包含来自各领域的500条系统消息，每条均配以5轮手动设计并核验的用户对话，确保了高质量标准。SysBench广泛评估了各种LLMs在遵循给定系统消息中指定约束的能力，其结果既展现了现有模型的优点也揭示了不足，为未来研究提供了关键洞察和方向。SysBench开源库可于https://github.com/PKU-Baichuan-MLSystemLab/SysBench访问。**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-20**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Ling He et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-19**|**Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models**|Jiao Chen et.al.|[2408.09972](http://arxiv.org/abs/2408.09972)|null|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-04-02**|**LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**|Zhiyuan He et.al.|[2404.01617](http://arxiv.org/abs/2404.01617)|null|我们介绍了LLM-ABR系统，这是首个利用大型语言模型（LLMs）的生成能力来自行设计适应性比特率（ABR）算法的系统，旨在满足多样的网络特性需求。LLM-ABR在强化学习框架内运作，使LLMs能够设计出如状态和神经网络架构等关键组件。我们在包括宽带、卫星、4G及5G在内的多种网络环境下对LLM-ABR进行了评估。结果显示，LLM-ABR持续超越默认的ABR算法表现。|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800](http://arxiv.org/abs/2408.11800)|null|在自然语言处理（NLP）与文本生成领域日新月异的发展背景下，检索增强生成（RAG）的出现为通过利用用户指定数据库中检索到的信息来提升生成文本的质量与可靠性提供了一条富有前景的道路。为了评估和比较不同RAG配置在检索器与生成器方面的性能，基准测试至关重要，它能提供关于其有效性、可扩展性以及针对特定领域及应用的适用性的深刻见解。本文提出了一套综合框架，用于生成领域相关的RAG基准。该框架基于自动问答生成，并采用人类（领域专家）与大型语言模型（LLM）协作的方式。作为案例研究，我们通过引入PermitQA展示了这一框架，它是首个针对风力选址与许可领域的基准，涵盖了与风能项目环境影响相关的多份科学文献/报告。我们的框架系统地运用多样化的指标与不同复杂度的问题类型来评估RAG的表现。同时，我们也展示了不同模型在该基准上的性能表现。|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793](http://arxiv.org/abs/2408.11793)|null|分子性质预测与通过深度学习模型进行的生成设计已成为研究热点，因其有望加速新型高性能材料的开发。近期，大型语言模型（LLMs）及由LLM驱动的代理系统的发展显著增强了这些工作流程，使得预训练模型能够在更复杂的科研任务中进行预测。尽管成效显著，但在面向材料设计任务的信息检索方面，代理系统仍有较大改进空间。此外，利用预测性深度学习模型的潜在表示以促进跨模态检索增强生成，并在代理系统中实现针对特定任务的材料设计，这一领域尚待探索。  本文展示了大型预训练化学基础模型可作为支持小分子、复杂聚合物材料及反应的语义化学信息检索的基础。同时，我们还展示了化学基础模型与图像模型（如OpenCLIP）的结合使用，能实现对多种表征数据域前所未有的查询与信息检索能力。最后，我们展示了这些系统在多代理系统中的集成，以促进基于结构和拓扑的自然语言查询及复杂研究任务中的信息检索。|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775](http://arxiv.org/abs/2408.11775)|null|最近的研究表明，大型语言模型（LLMs）在处理电信技术标准方面存在困难。我们提出了一种基于Phi-2小型语言模型（SLM）的微调检索增强生成（RAG）系统，用作通信网络的智囊。所开发的系统利用前瞻性的语义分块来自适应地根据嵌入相似性确定解析断点，从而有效地处理多样的文档格式。针对技术标准中多个相似上下文的挑战，我们采用了一种重新排序算法，以优先考虑最相关的检索到的片段。认识到Phi-2小模型有限的上下文窗口限制，我们实施了一项名为SelfExtend的最新技术，在推理时扩大上下文窗口，这不仅提高了性能，还能适应更广泛的用户查询和从普通客户到专业技术人员的设计需求。在微调过程中，我们使用了低秩适应（LoRA）技术来提高训练期间的计算效率，并允许在小数据集上进行有效微调。我们的综合实验显示，在电信领域对现有问答方法有显著改进，达到了超越更大语言模型（如GPT-4，其大小约为Phi-2的880倍）的性能水平。本工作为利用SLM处理通信网络提供了一个新颖的方法，实现了效率与性能的平衡。这一研究可作为迈向网络代理语言模型基础的重要一步。|
|**2024-08-21**|**Xinyu: An Efficient LLM-based System for Commentary Generation**|Yiquan Wu et.al.|[2408.11609](http://arxiv.org/abs/2408.11609)|null|评论为读者提供了深入理解事件的途径，通过呈现多样的观点和证据。然而，撰写评论是一项耗时的任务，即便是对熟练的评论员来说。大型语言模型（LLMs）简化了自然语言生成的过程，但它们在评论生成中的直接应用仍面临挑战，这主要是由于任务的独特要求。这些要求可以分为两个层面：1）基本要求，包括构建结构良好、逻辑连贯的叙述；2）高级要求，涉及产生高质量的论点并提供有说服力的证据。在本文中，我们介绍了Xinyu，一个高效的基于LLM的系统，旨在辅助创建中文评论。为了满足基本要求，我们将生成过程分解为顺序步骤，针对每个步骤提出有针对性的策略并采用监督式微调（SFT）。为了解决高级要求，我们提出了一个论点排序模型来优化论点，并建立了包含最新事件和经典文献的综合证据数据库，利用检索增强生成（RAG）技术加强证据的支撑力度。为了更公正地评估生成的评论，我们对应两级要求引入了一个全面的评估指标，该指标从五个不同角度审视评论生成。实验结果证实了我们提出的系统有效性。同时，在真实场景中，我们观察到评论员的工作效率显著提升，平均创作评论的时间从4小时缩短至20分钟。重要的是，这种效率的提高并未牺牲评论的质量。|
|**2024-08-21**|**A Quick, trustworthy spectral detection Q&A system based on the SDAAP Dataset and large language model**|Jiheng Liang et.al.|[2408.11557](http://arxiv.org/abs/2408.11557)|null|大型语言模型（LLM）在广泛的自然语言处理（NLP）任务中展示了显著的成功，并已在自然科学等众多领域引入了创新方法。研究者旨在利用LLM实施自动化、并发的知识驱动过程，以替代传统的手动、重复及劳动密集型工作。在光谱分析与检测领域，研究人员迫切需要自主获取关于不同研究对象的关联知识，这包括实验与分析中采用的光谱学技术和化学计量学方法。然而，尽管光谱检测被公认为一种有效的分析手段，其基础知识的检索过程仍然既耗时又重复。  针对这一挑战，我们首先引入了“光谱检测与分析文献数据集”（SDAAP），这是首个面向光谱分析与检测领域的开源文本知识数据集，包含了标注过的文献资料及相应的知识指导信息。随后，我们设计了一种基于SDAAP数据集的自动问答框架，该框架能够通过提取输入中的实体作为检索参数，检索相关信息并生成高质量的回答。值得注意的是，在此框架内，LLM仅作为一种工具提供泛化能力，而RAG技术则用于精确捕捉知识来源。这一方法不仅提升了生成回答的专业性，还确保了知识的可追溯性。实验结果表明，相比于基线，我们的框架生成了更具专业可信度的回答。|
|**2024-08-21**|**RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**|Xuanwang Zhang et.al.|[2408.11381](http://arxiv.org/abs/2408.11381)|null|大型语言模型（LLMs）在对话、推理和知识保留方面展示出人类级别的能力。然而，即使是最先进的LLMs也面临着诸如幻觉和实时知识更新的挑战。当前的研究通过为LLMs配备外部知识来解决这一瓶颈，这种技术被称为检索增强生成（RAG）。但是，RAG的发展受到两个关键问题的制约。首先，对于新颖的RAG算法之间缺乏全面和公平的比较正在逐渐增加。其次，像LlamaIndex和LangChain这样的开源工具采用了高层抽象，这导致了透明度的缺失，并限制了开发新算法和评估指标的能力。为了填补这一空白，我们引入了RAGLAB，一个模块化且面向研究的开源库。RAGLAB重现了6种现有算法，并为研究RAG算法提供了一个综合生态系统。利用RAGLAB，我们在10个基准上对6种RAG算法进行了公平的比较。通过RAGLAB，研究人员可以高效地比较各种算法的性能并开发新的算法。|
|**2024-08-20**|**Reading with Intent**|Benjamin Reichman et.al.|[2408.11189](http://arxiv.org/abs/2408.11189)|null|检索增强生成（Retrieval Augmented Generation，简称RAG）系统通过整合外部信息来源，如维基百科、内部文档、科学论文或开放互联网，来增强知识语言模型的能力。依赖开放互联网作为知识来源的RAG系统必须应对人为生成内容的复杂性。人类交流远不止于文字层面的传达，意图、语气和含义都能改变所传达信息的意义。近期RAG系统在实际部署中显示出理解人类交流这些细微差别的某些困难。这些系统面临的一大挑战在于处理讽刺语。虽然构成RAG系统骨干的大型语言模型（Large Language Models, LLMs）能够识别讽刺，但它们目前并不总是利用这些识别结果来进行后续的文本处理。  为了解决这些问题，本文从自然问题的维基百科检索语料库中合成生成讽刺性段落。然后，我们测试这些段落对RAG管道中检索器和阅读器部分性能的影响。我们引入了一种提示系统，旨在增强模型在存在讽刺情况下的解释和生成响应能力，从而提升系统的整体性能。最后，我们进行消融研究以验证我们方法的有效性，展示在处理讽刺内容方面RAG系统的改进。|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|定性数据的收集与分析方法，如访谈和焦点小组，能深入揭示顾客的态度、情感及行为特征。然而，手动分析这类定性数据需投入大量时间和精力以识别相关主题及意涵。本研究提出一种创新方法，旨在利用基于检索增强生成（RAG）的大型语言模型（LLMs）来分析访谈记录，以应对上述挑战。该研究新颖之处在于，将研究设计构想为一个由LLM辅助的过程，其中LLM扮演初级定性研究助手的角色。研究探索了LLMs的心理模型，以期其能在人才管理领域作为初级定性研究助理辅助研究人员。通过扩展RAG架构的LLM应用，本研究实现了对半结构化访谈数据的主题建模，展示了这些模型在信息检索和搜索之外的广泛应用潜力。研究发现，基于LLM的RAG方法能有效提取关注主题，且覆盖范围与人工从相同数据集中提炼的主题相当，从而证明了采用LLM作为初级定性研究助理的可行性。此外，研究建议采用此类模型的研究者应严格遵循传统定性研究中的质量标准，以确保方法的严谨性和可信度。最后，本文为希望将LLMs与既定的定性研究范式相结合的行业实践者提供了关键建议，勾勒出了一条有效整合这些强大但尚处初级阶段的人工智能工具，以分析人才管理领域内定性数据集的路径。|
|**2024-08-19**|**Enhanced document retrieval with topic embeddings**|Kavsar Huseynova et.al.|[2408.10435](http://arxiv.org/abs/2408.10435)|null|文档检索系统随着检索增强生成（RAG）的出现而重新引起了广泛关注。RAG架构相比于仅使用大型语言模型（LLM）的应用，提供了更低的幻觉率。然而，检索机制的准确性被认为是影响这些应用效率的瓶颈。特别是在语料库中包含来自多个不同但相关主题的多份文档时，检索性能不佳的问题尤为突出。我们设计了一种新的向量化方法，该方法考虑了文档的主题信息。本文介绍了一种针对文本向量化的创新方法，并在RAG的背景下对其进行了评估。此外，我们还讨论了评估RAG系统所面临的挑战，这一挑战也适用于当前情况。|
|**2024-08-19**|**LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain**|Nicholas Pipitone et.al.|[2408.10343](http://arxiv.org/abs/2408.10343)|**[link](https://github.com/zeroentropy-cc/legalbenchrag)**|**检索增强生成（Retrieval-Augmented Generation，简称RAG）系统展现出巨大的潜力，并在AI驱动的法律应用领域日益重要。目前存在的基准测试，如LegalBench，评估了大型语言模型（Large Language Models, LLMs）在法律领域的生成能力，但在评估RAG系统中的检索组件方面存在明显缺口。为解决这一问题，我们引入了LegalBench-RAG，这是首个专门针对法律领域RAG管道中检索步骤的基准测试。LegalBench-RAG侧重于精确检索，专注于从法律文件中提取最少量、高度相关的文本片段。相比检索文档ID或大量不精确的文本块，这些高度相关的摘录更为可取，因为前者可能导致超出上下文窗口限制。长上下文窗口不仅处理成本更高，还会增加延迟，并使LLMs出现信息遗忘或虚构的情况。此外，精确的结果使得LLMs能够为最终用户生成引用。LegalBench-RAG基准通过追溯LegalBench查询情境至其在法律语料库中的原始位置构建而成，形成了一个包含6,858对查询-答案、覆盖超过7,900万字符的数据库，且全部由法律专家人工标注。我们还推出了LegalBench-RAG-mini，这是一个轻量级版本，便于快速迭代和实验。通过提供专门针对法律检索的基准，LegalBench-RAG成为了致力于提升法律领域RAG系统准确性和性能的公司与研究者的不可或缺工具。LegalBench-RAG数据集已公开发布在https://github.com/zeroentropy-cc/legalbenchrag。**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-20**|**Carbon Footprint Accounting Driven by Large Language Models and Retrieval-augmented Generation**|Haijin Wang et.al.|[2408.09713](http://arxiv.org/abs/2408.09713)|null|碳足迹核算对于量化温室气体排放及实现碳中和至关重要。由于过程的动态性、核算规则、碳相关政策以及能源供应结构的变化，实时更新碳足迹核算（CFA）变得尤为重要。传统生命周期评估方法严重依赖人力专业知识，使得接近实时的更新面临挑战。本文提出了一种创新方法，该方法融合了大型语言模型（LLMs）与检索增强生成技术，旨在提升碳足迹信息检索与分析的实时性、专业性和经济性。通过利用LLMs的逻辑与语言理解能力，结合RAG的高效检索功能，所提出的LLMs-RAG-CFA方法能更有效地检索到有助于LLMs的专业信息，增强了模型的生成能力。此方法提供了广泛的专业覆盖范围，实现了碳足迹信息的高效实时获取与核算，并以无需频繁更新LLMs参数的经济型自动化方式达成目标。跨五个行业（原铝、锂电池、光伏、新能源汽车及变压器）的实验结果表明，LLMs-RAG-CFA方法优于传统方法及其他LLMs，达到了更高的信息检索率，且显著降低了信息偏差与碳足迹核算偏差。该经济可行的设计利用RAG技术平衡了实时更新与成本效益，为实时碳排放管理提供了一个高效、可靠且节省成本的解决方案，从而提升了环境可持续实践。|
|**2024-08-17**|**Developing a Llama-Based Chatbot for CI/CD Question Answering: A Case Study at Ericsson**|Daksh Chaudhary et.al.|[2408.09277](http://arxiv.org/abs/2408.09277)|null|本文介绍了我们在爱立信开发基于Llama的聊天机器人的经验，该机器人旨在回答关于持续集成和持续交付（CI/CD）的问题。爱立信是一家跨国电信公司。我们的聊天机器人专门针对爱立信CI/CD文档的特性进行了设计，采用检索增强生成（RAG）模型来提高回答的准确性和相关性。通过在工业界CI/CD相关问题上的实证评估，我们发现结合了BM25和嵌入式检索器的集成检索器能够带来最佳性能。在针对爱立信的72个CI/CD问题与答案组成的地面真实数据集上进行评估时，我们最精确的聊天机器人配置能完全正确回答61.11%的问题，部分正确回答26.39%，并对12.50%的问题给出错误答案。通过对部分正确和错误答案的错误分析，我们讨论了不准确性的根本原因并提供了进一步改进的见解。同时，我们也反思了所学到的教训，并为未来进一步提升聊天机器人准确性指明了方向。|
|**2024-08-17**|**TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems**|Xinke Jiang et.al.|[2408.09199](http://arxiv.org/abs/2408.09199)|null|在提升针对特定领域的大型语言模型（LLMs）性能的过程中，检索增强生成（RAG）作为一种有前景的解决方案，旨在缓解诸如虚构信息、知识陈旧及处理高度专业查询时专业知识有限等问题。然而，现存的RAG方法忽略了系统状态变量，这些变量对于实现自适应控制、检索终止及系统收敛至关重要。本文通过严谨的证明，引入了TC-RAG这一创新框架，通过整合图灵完备系统来管理状态变量，有效应对上述挑战。该框架借助具备自适应检索、推理及规划能力的内存堆栈系统，不仅实现了检索过程的受控停止，还通过推入（Push）和弹出（Pop）操作减轻了错误知识的累积。在医疗领域的案例研究中，我们在真实世界的医疗数据集上进行了大量实验，结果显示TC-RAG相比于现有方法，在准确性上提高了超过7.20%。我们的数据集和代码已开源，可访问https://github.com/Artessay/SAMA.git获取。|
|**2024-08-16**|**A Primer on Generative AI for Telecom: From Theory to Practice**|Xingqin Lin et.al.|[2408.09031](http://arxiv.org/abs/2408.09031)|null|生成式人工智能（GenAI）的兴起正在深刻改变电信行业。其中，大型语言模型（LLMs）作为GenAI的重要组成部分，已经崭露头角，成为推动创新、提升效率及优化客户服务的强大工具。本文从理论到实践，全面概述了GenAI在电信领域的应用。我们回顾了GenAI模型，并探讨了其在电信行业的实际应用场景。同时，文中阐述了有效将GenAI应用于电信领域的关键技术促进因素与最佳实践。特别强调了检索增强生成（RAG）技术在连接LLMs与电信领域特定数据源方面的重要性，以此提升LLMs回应的准确性。文章通过一个基于RAG的聊天机器人实例，展示了其能有效解答开放式无线接入网络（O-RAN）相关问题的能力。该聊天机器人在O-RAN联盟中的演示引发了业界的极大兴趣。为进一步推动技术共享，我们已将O-RAN RAG聊天机器人的源代码公开至GitHub平台。|
|**2024-08-16**|**Meta Knowledge for Retrieval Augmented Large Language Models**|Laurent Mombaerts et.al.|[2408.09017](http://arxiv.org/abs/2408.09017)|null|检索增强生成（Retrieval Augmented Generation，简称RAG）是一种技术，用于在不改变底层模型参数的前提下，通过增加情境相关、时效性关键或领域特定信息来增强大型语言模型（Large Language Models，LLMs）。然而，构建能够从庞大且多样的文档集中有效综合信息的RAG系统仍是一个重大挑战。我们引入了一种针对LLMs的新型数据驱动型RAG工作流程，将传统的“先检索后阅读”系统转变为更先进的“先准备-再改写-再检索-后阅读”框架，以实现对知识库的更高层次的领域专家级理解。我们的方法依赖于为每份文档生成元数据和合成的问题与答案（QA），以及引入基于元数据的文档集群的新型概念——元知识摘要（Meta Knowledge Summary，MK摘要）。所提出的创新使用户查询个性化及深入信息检索横跨整个知识库成为可能。本研究做出了两大重要贡献：利用LLMs作为评估工具并采用新的比较性能指标，我们证明了(1) 使用带有合成问题匹配的增强查询在性能上显著优于依赖文档切块的传统RAG管道（p < 0.01），并且(2) 基于元知识的增强查询进一步显著提高了检索的准确性和召回率，以及最终答案的广度、深度、相关性和特异性。我们的方法成本效益高，使用Claude 3 Haiku处理2000篇研究论文的成本低于20美元，并且可以通过对语言模型或嵌入模型进行任何微调来进一步提升端到端RAG管道的性能。|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-16**|**Extracting polygonal footprints in off-nadir images with Segment Anything Model**|Kai Li et.al.|[2408.08645](http://arxiv.org/abs/2408.08645)|null|建筑物足迹提取（BFE）在非垂直航空图像中通常依赖于屋顶分割和屋顶到足迹的偏移量预测，随后通过该偏移量将屋顶转换为足迹。然而，这种多阶段推断的结果在数据生产中并不适用，因为预测给出的掩码质量较低。为了解决这个问题，本文提出了OBMv2，它支持端到端和可提示的多边形足迹预测。与OBM不同，OBMv2采用了一种新提出的自偏移注意力（SOFA）机制，以弥合平房和摩天大楼之间性能差距，实现了无需后处理的真实端到端足迹多边形预测。%，如非极大值抑制（NMS）和距离NMS（DNMS）。%为了充分利用屋顶掩码、建筑物掩码和偏移量中所含的信息，我们为足迹预测设计了一个多层次信息系统（MISS），使得OBMv2即使在预测不足的情况下也能预测足迹。此外，为了从同一模型中榨取更多信息，我们受到自然语言处理领域中的检索增强生成（RAG）启发，提出了“BFE中的RAG”问题。为了验证所提方法的有效性，我们在开放数据集BONAI和OmniCity-view3上进行了实验，并在惠州测试集上进行了泛化能力测试。代码将在\url{https://github.com/likaiucas/OBM}上公布。|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535](http://arxiv.org/abs/2408.08535)|null|尽管大型语言模型（LLMs）和检索增强生成（RAG）系统取得了进展，但它们在事实核查中的有效性常受到限制，主要原因在于未与实体关系和社群结构充分融合，导致难以提供内容丰富且准确的信息检索。我们引入了CommunityKG-RAG（社群知识图谱-检索增强生成）这一创新的零样本框架，它将知识图谱（KG）中的社群结构与RAG系统整合，以提升事实核查的过程。CommunityKG-RAG能够适应新领域和查询，无需额外训练，通过利用KG中社群结构的多跳特性，显著提高了信息检索的准确性和相关性。实验结果表明，CommunityKG-RAG超越了传统方法，在事实核查领域代表着一项重大进步，提供了一个强大、可扩展且高效的解决方案。|
|**2024-08-16**|**MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering**|Zhengyuan Zhu et.al.|[2408.08521](http://arxiv.org/abs/2408.08521)|null|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444](http://arxiv.org/abs/2408.08444)|**[link](https://github.com/jmnian/weak_label_for_rag)**|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422](http://arxiv.org/abs/2408.08422)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|**[link](https://github.com/hkustdial/nl2sql_handbook)**|**翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对LLM驱动的NL2SQL技术的全面回顾，从以下四个方面覆盖其整个生命周期：（1）模型：解决NL的歧义和欠指定问题的NL2SQL翻译技术，以及恰当映射NL与数据库模式和实例；（2）数据：从训练数据的收集、因训练数据稀缺而进行的数据合成，到NL2SQL基准测试；（3）评估：使用不同指标和粒度从多角度评估NL2SQL方法；以及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进化。此外，我们为开发NL2SQL解决方案提供了一套经验法则。最后，我们讨论了LLM时代NL2SQL的研究挑战和开放问题。**|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现完全自动化——包括数据查询、分析、可视化及报告制作——仍是一个复杂挑战。本研究介绍了一款名为SageCopilot的先进工业级系统，该系统通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用了一个双阶段设计：在线阶段利用上下文学习（ICL）细化用户输入为可执行脚本并运行这些脚本以报告结果及生成可视化，而离线阶段则根据在线阶段ICL的需求准备演示。该系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格的测试和与基于提示的解决方案的比较分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面能实现端到端的卓越性能，其验证基于真实世界数据集。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证实能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器动态检索示例，但外部检索器与LLMs之间在表征能力上存在固有的差异。此外，优化示例选择并非易事，因为缺乏直接方法在不进行成对推理的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们设计了一种代理评分，根据输出查询之间的相似性来估算示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经准备好在生产环境中部署NL2SQL模型？为解答这一问题，我们提出了一种多角度NL2SQL评估框架NL2SQL360，旨在为研究人员设计和测试新的NL2SQL方法提供便利。借助NL2SQL360，我们在不同的应用情境下，如不同数据领域和SQL特性，对领先的NL2SQL方法进行了详尽的比较，为针对特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别出针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下识别出了一种有效的NL2SQL方法，即SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现出竞争优势。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术让不熟悉数据库的非专业用户有机会使用SQL进行数据分析。将自然语言转换为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项名为ChatBI的综合高效技术，旨在解决NL2BI任务。首先，我们分析了交互模式这一重要模块，这是NL2SQL与NL2BI在应用中的不同之处，并设计了一个更小、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而无法进行。BI场景中更高比例的列存在歧义性也使得模式链接变得困难。ChatBI结合了数据库社区现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中选择单个视图。该单视图的列作为所需列输入到LLM进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，使ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其融入多条产品线中，进行了大规模生产任务的评估。所获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，在我们的实际BI场景数据表和查询下，与当前主流的NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进翻译，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而未能生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含来自不同数据库的已知NL2SQL翻译。LLMs能够从输入的示例中学习如何为给定任务组织运算符组合。在本文中，我们提出了PURPLE（用于逻辑增强的预训练模型检索提示），该方法通过检索包含所需逻辑运算符组合的示例以提高NL2SQL任务的准确性，从而指导LLMs生成更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的完全集合匹配准确率和87.8%的执行匹配准确率的新状态-of-the-art性能。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确度，展现出稳健性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取实例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性是一项重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为此，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。全面的评估表明，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到证明。尤其值得注意的是，我们的模型超越了来自OpenAI和Cohere的强大竞争性嵌入模型。此外，与这些竞争模型相比，我们提出的编码器在1-shot情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进步着重于利用大型语言模型（LLM）的上下文学习能力，取得了显著成果。然而，这些方法在处理冗长的数据库信息和复杂用户意图时仍面临挑战。本文提出了一种两阶段框架，旨在提升当前基于LLM的自然语言至SQL系统性能。首先，我们引入一种新颖的提示表示方式，称为参考增强表示，它融入了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，利用链接后的模式，我们简化提示中的模式信息，并指示LLM产出最终SQL。最后，作为后处理优化模块，我们建议采用跨LM的一致性而非单一LM内部的自一致性。我们的方法在Spider基准测试上达到了新的最佳状态，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们借助ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，该方法能从查询的自然语言中抽取相关模式作为输入上下文，以此引导LLMs生成精确的GQL语句。我们在两个构建于金融和医疗领域的图数据库——FinGQL和MediGQL上对该方法进行了评估。实验结果显示，相较于一系列基线方法，我们的方法显著提高了性能，分别在精准匹配（EM）指标上提升了5.90和6.36绝对百分点，在 existence 匹配（EX）指标上提升了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资源。访问控制跨越两个领域：策略（组织级原则，定义谁应拥有访问权限）和流程（数据库级原语，实际实施策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种名为“面向数据库的意图型访问控制”（Intent-Based Access Control for Databases, 简称IBAC-DB）的新访问控制范式。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix, NLACM）得以更精确地表达。数据库访问控制原语随后自动生成自这些NLACM。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（我们称之为LLM4AC），以及初步的基准测试，用以评估此类系统的准确性和覆盖范围。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC极大地超越了其他基线，在我们的初始Dr. Spider基准测试中达到了高准确率和F1分数。在所有系统上，我们发现在扩展的基准测试中整体性能优异，这些测试包括需要外部知识的最先进的NL2SQL数据，以及来自Amazon Access数据集的真实世界角色层次结构。|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-21**|**RFID based Health Adherence Medicine Case Using Fair Federated Learning**|Ali Kamrani khodaei et.al.|[2408.11782](http://arxiv.org/abs/2408.11782)|null|药物依从性的缺失显著降低了治疗效果，然而在患者中这一问题仍然普遍存在。非依从性与不良后果相关联，包括增加死亡风险和住院风险。尽管存在多种方法帮助患者跟踪服药时间表，如智能给药系统（IDAS）和智能泡罩包装，这些工具在推广时往往遇到阻碍其商业可行性的挑战。基于物联网中剂量测量与信息通讯的原理，我们引入了智能药盒——一种智能健康依从性工具，它利用RFID进行数据记录及NFC进行数据提取。该系统集成了负载传感器以实现精确剂量测量，并配备有安卓应用程序以监控药物摄入、提供建议及发出警告。  为了提升智能药盒的有效性和个性化程度，我们提议将其与联邦学习相结合。联邦学习使智能药盒能够从多个用户的药物依从性模式中学习，同时不侵犯个人隐私。通过在收集自不同智能药盒的去中心化数据上训练机器学习模型，该系统能持续改进其推荐和警告机制，适应用户的多样需求和行为习惯。这一方法不仅增强了工具支持药物依从性的能力，还确保了敏感用户数据的安全与私密。|
|**2024-08-21**|**FedGS: Federated Gradient Scaling for Heterogeneous Medical Image Segmentation**|Philip Schutte et.al.|[2408.11701](http://arxiv.org/abs/2408.11701)|null|联邦学习（FL）在深度学习（DL）自动化医学图像分割中的应用有助于通过协同模型训练保护隐私，无需共享患者数据。然而，FL面临着机构间数据异质性的挑战，这导致了次优的全局模型。将离散表示学习（DRL）融入FL可以提高鲁棒性，通过将数据分离为不同的表示。现有的DRL方法假设异质性仅存在于风格特征中，忽视了基于内容的变异性，如病灶大小和形状。我们提出了FedGS，一种新颖的FL聚合方法，旨在提升对小型、代表性不足目标的分割性能，同时保持整体效能。FedGS在PolypGen和LiTS数据集上展现了相对于FedAvg的优越性能，特别是在小病灶方面。代码和预训练检查点可于以下链接获取：https://github.com/Trustworthy-AI-UU-NKI/Federated-Learning-Disentanglement|
|**2024-08-21**|**Technical Report: Coopetition in Heterogeneous Cross-Silo Federated Learning**|Chao Huang et.al.|[2408.11355](http://arxiv.org/abs/2408.11355)|null|在跨机构联邦学习（FL）中，各公司协同训练一个共享的全局模型，而不分享异构数据。先前的相关研究主要集中在应对数据异质性的算法开发上。然而，合作与竞争并存的双重问题，即FL合作与市场竞赛，尚未得到充分探索。本文利用一个动态双期博弈模型来研究FL中的合作竞争关系。在第一期，一家现有公司训练本地模型，并以选定的价格向用户提供基于模型的服务。第二期，一家新进公司加入，两家公司随后决定是否进行FL合作，并以不同的价格向用户出售基于模型的服务以进行市场竞争。  分析这一双期博弈面临挑战，原因在于数据异质性，以及现有公司在第一期的定价对第二期合作竞争产生的时序影响，导致问题非凹。为解决这一难题，我们将问题分解为多个凹子问题，并开发出一种能达到全局最优解的算法。在三个公共数据集上的数值结果显示两个有趣见解：首先，FL训练带来模型性能提升的同时也伴随着市场竞争损失，只有当性能提升超过损失时才会发生合作。其次，数据异质性可能激励现有公司在第一期限制市场渗透，并在第二期促进价格竞争。|
|**2024-08-21**|**FedMoE: Personalized Federated Learning via Heterogeneous Mixture of Experts**|Hanzi Mei et.al.|[2408.11304](http://arxiv.org/abs/2408.11304)|null|随着大型语言模型（LLMs）不断拓展人工智能的能力边界，它们对数据的需求日益增长。这些数据中很大一部分是私有的，并分布在边缘设备上，使得联邦学习（FL）成为微调（例如，FedLLM）的默认替代方案。然而，由于客户端间存在的固有异质性，包括数据分布的不同和任务类型的多样性，联邦学习面临着重大挑战。为了构建一个适应性强的FedLLM，我们用稀疏激活的混合专家（MoE）架构替换了传统的密集模型，其并行的前馈网络提供了更大的灵活性。为了让它在资源受限的环境中更加实用，我们提出了FedMoE，这是一个高效个性化联邦学习框架，旨在解决数据异质性问题，通过为每个客户端构建最优子MoE并将其知识反馈给全局MoE来实现。  FedMoE包含两个细调阶段。在第一阶段，FedMoE通过基于观察到的激活模式进行启发式搜索简化问题，为每个客户端确定一个次优子模型。在第二阶段，这些子模型被分发给客户端进行进一步训练，并通过一种新颖的模块化聚合策略返回服务器进行聚合。同时，FedMoE通过全局专家推荐逐步调整子模型至最优状态。  实验结果证明，我们的方法相比以往的个性化联邦学习方法具有优越性。|
|**2024-08-21**|**The Key of Parameter Skew in Federated Learning**|Sifan Wang et.al.|[2408.11278](http://arxiv.org/abs/2408.11278)|null|联邦学习（FL）作为一种在不同数据持有者之间进行深度学习而无需交换原始数据的优秀解决方案已崭露头角。然而，联邦学习中的统计异质性带来了关键挑战，导致局部模型参数分布的偏斜现象，这一现象至今为止研究者们关注不足。在此工作中，我们提出了参数偏斜的概念来描述这一现象，该现象能够显著影响全局模型参数估计的准确性。此外，我们引入了FedSA，一种聚合策略，旨在应对参数偏斜所带来的影响，以获得高质量的全局模型。具体而言，我们根据变异系数将参数分为高离散度和低离散度两类。对于高离散度参数，微类（MIC）和宏类（MAC）分别代表微观和宏观层面的离散情况，构成了FedSA的基础。为了评估FedSA的有效性，我们在三个计算机视觉数据集上采用不同的联邦学习算法进行了广泛实验。结果表明，FedSA相比八个前沿基线方法平均提高了约4.7%的测试准确率。|
|**2024-08-20**|**NeuLite: Memory-Efficient Federated Learning via Elastic Progressive Training**|Yebo Wu et.al.|[2408.10826](http://arxiv.org/abs/2408.10826)|null|联邦学习（FL）作为一种新兴的学习范式，使得多个设备能够协同训练一个共享模型，同时保持数据隐私。然而，在实际案例中，资源受限设备上部署FL时，训练过程中的巨大内存占用成为了严峻的瓶颈。为此，我们提出了NeuLite这一框架，它通过弹性渐进式训练打破了内存限制的障碍。与传统FL在整个训练过程中更新完整模型不同，NeuLite将模型划分为多个块，并以逐步的方式进行训练。除了渐进式训练范式外，NeuLite还包含两个关键组件来指导训练过程：1）课程导师和2）训练协调器。具体来说，课程导师为每个块设计了基于课程的训练损失，帮助它们学习预期的特征表示并减轻有价值信息的丢失。此外，训练协调器则开发了一种参数共适应训练模式，从正向和反向传播两方面打破块间的信息隔离。同时，它为每个块构建输出模块以增强模型参数的共适应性。我们通过详尽的实验，在模拟和硬件测试平台 上评估了NeuLite的有效性。结果显示，NeuLite最多能将峰值内存使用量减少50.4%，同时将模型性能提升最多84.2%，并将训练速度加快至多1.9倍。|
|**2024-08-20**|**Security Assessment of Hierarchical Federated Deep Learning**|D Alqattan et.al.|[2408.10752](http://arxiv.org/abs/2408.10752)|null|分层联邦学习（Hierarchical Federated Learning, HFL）作为一种有前景的分布式深度学习模型训练范式，面临着由对抗性攻击引起的重大安全挑战。本研究通过一种新颖的方法论，针对推理时间和训练时间的对抗性攻击，对HFL的安全性进行了深入的调查与评估。借助于跨多个数据集和攻击场景的广泛实验，我们发现HFL因其实现结构的层次性，对于无目标的训练时间攻击展现出较强的韧性。然而，特定目标攻击，尤其是后门攻击，利用了这一架构特点，尤其是在恶意客户端位于边缘服务器重叠覆盖区域时，该问题更为突出。因此，HFL在抵御攻击方面表现出双重特性，得益于其层次化的聚合机制，增强了对对抗性训练的适应性，从而强化了对推理时间攻击的抵抗能力。这些发现突显出在HFL系统中采取平衡安全策略的必要性，既要利用其内在优势，又要有效缓解脆弱性。|
|**2024-08-20**|**Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions**|Mirko Nardi et.al.|[2408.10664](http://arxiv.org/abs/2408.10664)|null|联邦学习（FL）是分布式机器学习中的一个关键方法，特别是在数据隐私至关重要且直接数据共享不可行的情况下。尽管FL通常与监督学习相关联，但其在无监督场景下的潜力尚未得到充分探索。本文介绍了一种新颖的无监督联邦学习方法论，旨在识别多个客户端中不带标签、非统一数据分布下的全部类别集合（全局K），这一过程称为联邦聚类。我们的方法，名为联邦群智细化（FedCRef），涉及客户端协作对具有相似数据分布的群组进行模型训练。最初，具有多样本地数据分布（本地K）的客户端在其群组上训练模型以生成压缩数据表示。这些局部模型随后在网络中共享，使客户端能够通过重建误差分析进行比较，从而形成联邦小组。在这些小组中，客户端协作训练代表每个数据分布的共享模型，并持续细化其本地群组以提高数据关联准确性。这一迭代过程使得我们的系统能够识别网络中所有潜在的数据分布，并为每个分布开发出强大的表示模型。为了验证我们的方法，我们将其与传统的集中式方法进行对比，建立了性能基线并展示了我们分布式解决方案的优势。我们还在EMNIST和KMNIST数据集上进行了实验，证明了FedCRef细化并调整群组模型以匹配实际数据分布的能力，显著提高了无监督联邦环境下的数据表示精度。|
|**2024-08-19**|**Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement**|Jeremiah Birrell et.al.|[2408.10456](http://arxiv.org/abs/2408.10456)|null|差分隐私随机梯度下降（Differentially Private Stochastic Gradient Descent, DP-SGD）通过提供一个控制和记录训练过程中隐私损失的框架，对于私密训练深度学习模型至关重要。该计算的核心涉及一种子采样方法，该方法利用隐私放大引理来增强由添加噪声提供的隐私保障。固定大小子采样因其恒定的内存使用而具有吸引力，这与Poisson子采样中的可变大小小批量不同。它在处理类别不平衡和联邦学习问题时也很重要。然而，目前对固定大小子采样的可计算性保证并不紧密，且未同时考虑增加/移除和替换一元的邻接关系。我们提出了一种新的、全面的Rényi差分隐私（RDP）会计师，用于无放回（Fixed-Size without Replacement, FSwoR）和有放回（Fixed-Size with Replacement, FSwR）的DP-SGD固定大小子采样。对于FSwoR，我们考虑了增加/移除和替换一元的邻接关系。我们的FSwoR结果相比当前最佳的可计算界限提高了4倍。我们还首次表明，广泛使用的Poisson子采样与考虑替换一元邻接关系的FSwoR在抽样概率的主导阶上具有相同的隐私性。因此，我们的工作表明，由于其恒定的内存使用，FSwoR通常比Poisson子采样更可取。我们的FSwR会计师包括了明确的非渐近上界和下界，并且据作者所知，这是首次对DP-SGD中固定大小有放回RDP的此类分析。我们在理论和经验上比较了固定大小和Poisson子采样，并显示在固定大小子采样制度下，DP-SGD的梯度在实践中表现出更低的方差，除了内存使用的益处。|
|**2024-08-19**|**Federated Learning of Large ASR Models in the Real World**|Yonghui Xiao et.al.|[2408.10443](http://arxiv.org/abs/2408.10443)|null|联邦学习（FL）在以隐私保护的方式训练机器学习模型方面已展现出巨大潜力。然而，对于拥有超过亿万个参数的大型模型而言，训练资源需求成为联邦学习的障碍，因为普通设备往往不具备足够的内存和计算能力来完成联邦学习任务。尽管已提出了一些高效的训练方法，但使用联邦学习训练像基于Conformer的自动语音识别（ASR）这样的大型模型仍是一项挑战。本文提出了一种系统性解决方案，用以在联邦学习框架下训练参数量达1.3亿的完整规模ASR模型。据我们所知，这是首次将Conformer模型应用于现实世界中的联邦学习案例，同时也是迄今为止使用联邦学习训练的最大规模模型。同时，本研究首次展示了通过一系列提升客户端数据及标签质量的方法，联邦学习能改善ASR模型的质量。我们在实际实验中验证了该方案在训练效率和模型质量提升两方面的效果。|
|**2024-08-19**|**Federated Frank-Wolfe Algorithm**|Ali Dadras et.al.|[2408.10090](http://arxiv.org/abs/2408.10090)|null|近年来，联邦学习（FL）因能构建隐私保护的协同学习系统而备受关注。然而，针对约束机器学习问题的FL算法仍然有限，特别是在投影步骤成本高昂时。为此，我们提出了一种联邦Frank-Wolfe算法（FedFW）。FedFW具有数据隐私保护、每迭代步成本低以及通信信号稀疏等特点。在确定性设置下，FedFW对于光滑且凸的目标函数，在 $O(\varepsilon^{-2})$次迭代内达到$\varepsilon$-次优解，而对于光滑但非凸的目标函数，则需$O(\varepsilon^{-3})$次迭代。此外，我们还提出了一种FedFW的随机变体，并证明在凸设置下，该变体能在$O(\varepsilon^{-3})$ 次迭代内找到解。我们通过多个机器学习任务展示了FedFW的实验性能。|
|**2024-08-19**|**Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing**|Vinit Hegiste et.al.|[2408.10024](http://arxiv.org/abs/2408.10024)|null|在联邦学习（FL）领域，特别是在制造业中，服务器聚合时选择客户端权重的策略对于模型性能至关重要。本研究对比分析了两种权重选择策略：最终轮次权重选择（FEWS）和最优轮次权重选择（OEWS）在实际应用中的效果。针对制造业合作场景通常涉及有限合作伙伴（两到四个客户端）的特点，我们的研究聚焦于联邦图像分类任务，并采用包括EfficientNet、ResNet和VGG在内的多种神经网络架构，以评估这些权重选择策略对模型收敛性和鲁棒性的影响。研究旨在通过通信轮次（CRs），确定FEWS或OEWS哪一种能更有效地提升全局FL模型的表现。借助实证分析和严谨实验，我们力求为优化制造业中的FL实施提供宝贵见解，确保在这种关键行业中，协作努力能够产生最有效且可靠的模型。本研究的发现预期将显著改进制造业中的FL实践，从而增强协作机器学习工作的效率与性能。|
|**2024-08-19**|**Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets**|Xingrun Yan et.al.|[2408.09762](http://arxiv.org/abs/2408.09762)|null|在实际的联邦学习（FL）系统中，客户端与参数服务器（PS）间传递模型参数的通信开销常常成为瓶颈。层次化联邦学习（HFL）通过在客户端与PS之间设置多级边缘服务器（ESs）部分缓解了这一问题，但仍然需要从多个ES汇总模型参数至PS。为了进一步减少通信开销，我们首次将序列联邦学习（SFL）引入HFL中，该方法取消了中心PS，使得模型训练仅需通过每轮迭代时在两个相邻ES间传递全局模型即可完成，并提出了一种适应此组合框架的新型算法，称为Fed-CHS。在不同的数据异质性设定下，针对强凸和非凸损失函数，我们推导了收敛性结果，表明其收敛性能与仅采用HFL或SFL的算法相当。实验结果进一步证实了我们提出的Fed-CHS在节省通信开销和提高测试准确性方面相对于基线方法的优势。|
|**2024-08-18**|**Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment**|Tatjana Legler et.al.|[2408.09556](http://arxiv.org/abs/2408.09556)|null|联邦学习（FL）作为一种在保护数据隐私的同时跨分散数据源训练机器学习模型的有前景方法，尤其在制造业和共享生产环境中的应用日益凸显。然而，不同客户端和生产场所间存在的数据异质性——包括数据分布、质量和数量的变化——对FL的有效性和效率构成了重大挑战。本文全面概述了制造业背景下FL中的异质性问题，详细阐述了异质性的类型及来源，如非独立同分布（non-IID）数据、不平衡数据、可变的数据质量和统计异质性。我们讨论了这些类型的异质性对模型训练的影响，并回顾了当前缓解其不良影响的方法论，包括个性化与定制化模型、鲁棒聚合技术以及客户端选择技术。通过综合现有研究并提出新的策略，本文旨在为有效管理FL中的数据异质性提供见解，增强模型的鲁棒性，并确保在多样化的环境下实现公平且高效的训练。此外，本文还明确了未来研究方向，强调了为在工业4.0背景下进一步改进FL范式，需要研发适应性强和可扩展的解决方案。|
|**2024-08-20**|**Seamless Integration: Sampling Strategies in Federated Learning Systems**|Tatjana Legler et.al.|[2408.09545](http://arxiv.org/abs/2408.09545)|null|联邦学习（Federated Learning, FL）在机器学习领域标志着一种范式转变，它提供了一种分散训练模型的方法，能够在保护本地数据隐私的同时，横跨众多设备进行操作。然而，FL系统所固有的动态特性，特别是不断有新客户端加入，这些新客户端可能拥有差异巨大的数据分布和计算能力，给这些分布式学习网络的稳定性和效率带来了重大挑战。无缝融入新客户端对于维持和提升FL系统的性能及鲁棒性至关重要。本文深入探讨了将新客户端整合进现有FL系统所面临的复杂性，以及数据异质性和它们之间不同数据分布（非独立同分布）如何影响模型训练、系统效率、可扩展性和稳定性。尽管存在这些挑战，新客户端的整合也为FL系统提供了增强数据多样性、提升学习性能及利用分布式计算能力的契机。与最初应用于诸如Gboard中的单词预测分布式优化等场景不同，生产环境中的客户端数量通常较少，这使得每个新客户端的信息变得更加宝贵。本文概述了有效的客户端选择策略及确保系统可扩展性和稳定性的解决方案，并以光学质量检测图像为例，提供了实际操作方法的见解。总之，本文提出，应对新客户端整合带来的挑战对于分布式学习网络的进步和效率至关重要，从而为FL在生产环境中的采纳铺平道路。|
|**2024-08-18**|**Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets**|Shiyuan Zuo et.al.|[2408.09539](http://arxiv.org/abs/2408.09539)|null|
|**2024-08-18**|**Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover**|Dong-Jun Han et.al.|[2408.09522](http://arxiv.org/abs/2408.09522)|null|
|**2024-08-18**|**Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training**|Huitong Jin et.al.|[2408.09478](http://arxiv.org/abs/2408.09478)|null|
|**2024-08-18**|**Federated Graph Learning with Structure Proxy Alignment**|Xingbo Fu et.al.|[2408.09393](http://arxiv.org/abs/2408.09393)|**[link](https://github.com/xbfu/fedspray)**|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227](http://arxiv.org/abs/2408.09227)|null|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240822>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

