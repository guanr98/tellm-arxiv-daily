[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.20
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLM）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应的传感器数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、眼动以及XR环境中的上下文记忆中隐式提取情境。这最大限度地减少了对人为设计的明确提示的依赖，促进了基于现实情境且直观的交互，为聊天机器人提供用户的深入洞察。用户研究证明了我们方法的可行性及其在简化XR中用户与聊天机器人交互方面的变革性潜力，同时为未来XR实体化LLM代理的设计提供了启示。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使设计过程复杂化，阻碍了AEC（建筑、工程和施工）行业中BIM及基于模型设计的应用推广。为更直观地表达设计意图，我们提出了Text2BIM框架，这是一个基于LLM（大型语言模型）的多智能体系统，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作与推理，将用户的文本输入转化为可执行代码，进而调用BIM创作工具的API，直接在软件内部生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，框架内嵌入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体识别并解决生成模型中的问题，通过迭代优化提升模型质量。我们进行了大量实验，对比分析了在本框架下三种不同LLM的表现。评估结果表明，该方法能有效生成高质量、结构合理的建筑模型，与用户输入的抽象概念保持一致。最后，开发了一款交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，通过“对话式建模”展示了其应用潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练在使能动态场景（如网络导航）中所需的复杂决策制定自治代理能力方面存在不足。以往通过在精心设计的专家演示上进行监督微调来弥合这一差距的尝试，常因累积错误和有限探索数据的问题，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式的蒙特卡洛树搜索（MCTS）与自我批判机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能够从成功和不成功的轨迹中有效学习，从而提高其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其中它持续超越了行为克隆和强化微调基线，并在配备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升到单日数据收集后的81.7%成功率（相对增长340%），进一步利用在线搜索提升至95.4%。我们相信，这代表了自主代理能力的实质性飞跃，为现实世界设置中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架展现出不同的优势，在某些任务上表现出色，而在其他任务上则表现不佳。为了充分利用这些代理的独特专长，我们提出了DEI（多样性赋能智能）这一框架，它能利用代理们的专业知识。DEI作为一个元模块置于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果显示，由DEI引导的代理委员会能够大幅超越单个最佳代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上的最高个人解决问题率为27.3%，而通过DEI可以达到34.3%的解决问题率，实现了25%的提升，并且超过了大多数闭源解决方案。我们表现最好的群体以55%的解决问题率脱颖而出，在SWE-Bench Lite上占据了榜首位置。我们的发现为协作AI系统研究领域做出了贡献，进一步证明了它们在解决复杂软件工程挑战中的潜力。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受到分层强化学习（HRL）的启发，我们提出了一种新颖的框架——分层上下文强化学习（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即在运行时通过高层策略将复杂任务分解为子任务。这些子任务由目标定义，并分配给低层策略去完成。一旦LLM代理判断目标达成，将提出新的目标。为了提升代理在多回合执行中的表现，我们提出了“事后模块化反思”（HMR）方法，其中，代理不是对完整轨迹进行反思，而是将任务目标替换为中间目标，让代理针对更短的轨迹进行反思，从而提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果显示，在5轮执行中，与强大的上下文学习基线相比，HCRL能分别实现9%、42%和10%的性能提升。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工通用智能（AGI）。然而，在这些模型基于的代理在实际世界中的行为表现、潜在失败原因及改进方法，特别是在高要求的真实规划任务中的研究还较为匮乏。为了填补这一空白，我们通过一个现实的基准测试——TravelPlanner，来展开研究。在此基准测试中，代理必须满足多重约束以生成准确的计划。我们利用这一基准测试来探讨四个关键研究问题：(1) LLM代理在面对冗长和嘈杂的上下文环境时，其推理和规划能力是否足够稳健？(2) 少样本提示在涉及长上下文的场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化策略来改进计划，以及(4) 通过结合正面和负面反馈对LLM进行微调能否带来进一步的性能提升？  我们的综合实验显示，首先，尽管LLMs能够处理大量参考信息和少样本示例，但它们往往未能关注长上下文中的关键部分；其次，它们在分析长篇计划时仍面临挑战，无法为细化提供精确的反馈；第三，我们提出了一种反馈感知微调方法（FAFT），该方法利用正负反馈相结合，相比监督式微调（SFT）展现出显著的性能提升。我们的发现为关于真实世界规划应用的多个方面提供了深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大的表达方式，它通过结合叙述技巧与可视化和文本，传达深刻见解。这类故事融合了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释这些见解的文本注释。然而，创作此类故事需要对数据有深入的理解及精心的叙事规划，往往需要人工介入，这既耗时又耗费心力。尽管大型语言模型（LLMs）在多种自然语言处理任务上表现出色，但它们生成连贯、全面的数据故事的能力尚未得到充分探索。本研究中，我们提出了一项新颖的数据故事生成任务，并建立了一个包含1,449个来自不同来源的故事的基准数据集。为了应对构建连贯数据故事的挑战，我们设计了一个多智能体框架，采用两个LLM智能体来模拟人类讲故事的过程：一个负责理解并描述数据（反思），生成提纲和叙述，另一个则在每个中间步骤进行验证。尽管我们的智能体框架在基于模型和人工评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成中的一些独特挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收到关于目标位置相对于知名地标语言描述的信息；仅依据对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间不提供具体指令。这一问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，而地标在该环境中常常不可见。在缺乏导航指引的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs根据每次观察“反应”并相应地做出决策。然而，该基线性能较差，代理往往会重复访问同一位置，并做出短视、不连贯的决策。为解决这些问题，本文提出了一种新颖的代理工作流程，其特点是具有感知、反思和规划的能力。具体而言，我们发现LLaVA-7B模型可以通过微调，以足够精度感知地标的方向和距离，满足城市导航需求。此外，通过记忆机制实现反思，将过往经验存储起来，并能与当前感知结合，以便有效支持决策论证。规划则利用反思结果来制定长期计划，从而避免在长距离导航中做出短视决策。研究结果显示，设计的这一工作流程显著提升了基于LLM的代理的导航能力，相比现有最先进基线有明显优势。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，各有显著缺点。基于相似性的检索在复杂任务中往往召回率低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的泛用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口集成。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索和代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个实际的编程应用场景。凭借统一的图数据库模式，CodexGraph在学术和现实世界环境中均展现出竞争力和潜力，彰显其在软件工程中的多样性和有效性。我们的应用演示位于：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法不仅劳动强度大，而且需要在通信、网络和优化领域拥有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程领域，网络优化将迎来革新性途径。这一途径通过精心设计的提示策略，将人类经验和知识融入这些复杂的LLMs中，并部署自主智能体作为通信桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合预示着人工智能即服务（AIaaS）的未来模式及AI使复杂任务更简易化的趋势。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体策略（LaBa），以及协同多LLM基自主BSS智能体策略（CLaBa）。通过真实世界数据的评估，实验表明，辅助提示的LLMs与基于LLM的智能体能生成更高效、成本效益更高且更可靠的网络部署，显著提升了BSS优化的效率并减少了人工参与的繁琐程度。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）的文本生成中展示了显著的性能提升。然而，这些技术依赖于精确的答案提取过程来聚合多个输出，并且由于需要生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以使用LLMs可靠地聚合以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLMs输出的多样性。这些已证实的技术可以轻松扩展到自我集成方法中，以在文本生成中实现更优结果。在本文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），一种混合自我集成方法，它结合了多样化示例提示和基于LLM聚合的优点，以提高整体性能。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|实现人类水平的智能需要细化系统1与系统2思维之间的认知差异。尽管当前的人工智能，特别是在大型语言模型的推动下，展示出了类似人类的特征，但它仍未达到真正意义上的认知水平。从结构化的基准测试过渡到现实世界的场景为视觉代理提出了挑战，往往导致不准确且过度自信的反应。为了解决这一挑战，我们引入了FaST，它将快速与慢速思考机制融入视觉代理中。FaST利用一个切换适配器动态地在系统1/2模式间进行选择，根据任务复杂度调整问题解决方法。它通过调整模型置信度并整合新的上下文数据来应对不确定和未见过的对象。凭借这一新颖设计，我们倡导了一个灵活的系统、层次化的推理能力和透明的决策制定流程，所有这些都有助于其在视觉智能中模拟人类类似的认知过程。实证结果表明，FaST超越了多种知名基线，在视觉问答VQA^{v2}上达到了80.8%的准确率，在ReasonSeg推理分割任务上达到了48.7%的GIoU分数，彰显了FaST的优越性能。广泛的测试验证了FaST核心组件的有效性和鲁棒性，展示了其在推进人工智能系统中认知视觉代理发展的潜力。|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|多模态大型语言模型（Multimodal Large Language Models, MLLMs）在医疗辅助领域的成功展现出巨大潜力，使患者能够利用生理信号数据进行对话。然而，通用MLLMs在心脏病诊断方面表现欠佳，特别是在心电图（ECG）数据分析与长文本医学报告生成的融合上，主要由于ECG数据分析的复杂性及文本与ECG信号模态间存在差距。此外，模型在长文本生成中常表现出严重的稳定性不足，原因在于缺乏与用户查询紧密相关的精确知识。针对这些问题，我们提出了ECG-Chat，首个专注于ECG医学报告生成的多任务MLLMs，提供了基于心脏病学知识的多模态对话能力。我们提出了一种对比学习方法，该方法将ECG波形数据与文本报告整合，以细粒度方式对齐ECG特征与报告。此方法还促成了一种在零样本报告检索任务中表现出色的ECG编码器。此外，通过扩展现有数据集，我们构建了1.9万个ECG诊断数据集和2.5万个多轮对话数据集，用于训练和微调ECG-Chat，使其具备专业的诊断和对话能力。而且，ECG-Chat能通过自动化LaTeX生成管道产出全面的ECG分析报告。我们为ECG报告生成任务建立了基准，并在多个基线上测试了我们的模型。ECG-Chat在分类、检索、多模态对话及医学报告生成任务中均取得了最佳性能。我们的报告模板设计也得到了医学从业者的广泛认可。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发和评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语及英语心理学术语处理方面的能力。PsychoLex的核心贡献包括PsychoLexQA数据集，用于教学内容的指导，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理场景中的表现。此外，我们还展示了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并在性能上超越了一般的通用模型。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步完善的领域。此项研究为将LLMs融入特定的心理学领域奠定了基础性工作，对AI驱动的心理学实践未来发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|**表格推理任务旨在根据给定的表格回答问题。目前，利用大型语言模型（LLMs）是解决表格推理问题的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，鉴于每个实例需要不同的能力和模型具有不同的能力，不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析，证明了上述观点，其中不同的实例和模型在使用各种表格格式时表现出不同的性能。基于这一讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对支撑SDM的关键认知过程——搜索、呈现及整合——的影响。我们的分析指出，AI有潜力提升战略分析的速度、质量和规模，并促成新的方法，如虚拟战略模拟。然而，其对企业绩效的最终影响将取决于随着AI能力发展而形成竞争动态。我们提出一个框架，将AI在SDM中的应用与企业成果相联系，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏考虑。在本文中，我们通过引入一种新颖的数据管道来解决这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含14个类别下的1573个样本，展现了在十大顶级模型间的高可分离性（84%），并与Chatbot Arena的符合度达到84%，斯皮尔曼相关系数为0.915。这些符合度值比Arena Hard高出9%，比AlpacaEval 2.0 LC高出20%，而斯皮尔曼系数比下一个最佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别上的性能进行细粒度分析，为实践者提供了宝贵的见解。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|**设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的进展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。为应对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一种新颖的对话策略预测器EmoDynamiX，它利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一个灵活的混合情感模块以捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。**|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，LLMs可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务中，涉及三个LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式比专注于特定描述内容更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|**文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行修正，而先前研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果发现并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和框架解析来进行SQL纠错。DAC首先生成与问题对应的实体和框架，然后比较初始SQL与生成的实体和框架之间的差异，作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，证明了DAC的有效性。**|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）的文本生成中展示了显著的性能提升。然而，这些技术依赖于精确的答案提取过程来聚合多个输出，并且由于需要生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以使用LLMs可靠地聚合以产生最终输出。此外，近期LLM推理方面的进展显示，提示中使用多样化的示例能够促使LLMs输出更加多样化。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性的提示，通过LLMs聚合），一种混合自我集成方法，它结合了多样示例基于提示的优势和LLM基于的聚合，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发和评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在心理学任务上的专业能力，涵盖了波斯语和英语两种语言环境。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强学习，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理场景中的表现。此外，我们推出了PsychoLexLLaMA模型，该模型经过专门优化以适应心理学应用，展示出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与实践方面的潜力，同时也指出了未来精进方向。此研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|**表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们认为，每个实例需要不同的能力，而模型也具备不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析，证明了上述观点，在不同格式下，不同的实例和模型表现各异。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以灵活的表格格式提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式下的推理结果。在WikiTableQuestions和TabFact数据集上的实验显示出了显著的改进，与使用固定表格格式及贪婪解码、自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时启用如虚拟战略模拟等新方法。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一种新颖的数据管道来解决这些局限性，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含1573个样本，横跨14个类别，展现了在十大顶级模型间高达84\%的高可分离性，并与Chatbot Arena的共识度达到84\%，斯皮尔曼相关系数为0.915。这些共识值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比下一个最佳基准高出0.7，彰显了基准实用性的显著提升。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|**设计具有情感智能的对话系统，以向处于困境中的人提供安慰和建议，是研究领域中的一个引人注目方向。过往的研究重点在于开发模块化对话系统，这些系统将社会情感策略预测作为辅助任务，并利用定制的解码器生成策略条件化的回应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。为了解决这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，它利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一个灵活的混合情感模块来捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大规模语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）被广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量判断时（例如文本的连贯性），预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLMs作为裁判的评估仅仅基于提示中的指令，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLMs裁判的提示在多大程度上影响了AI评判与人类评判的一致性，我们分析了针对几个LLMs裁判的、关于评价目标质量的指示逐步增加的提示。此外，我们还将使用模型困惑度作为质量度量的无提示方法进行了对比。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs进行的最先进评估中，并提供了作为裁判模型的严格基准。总的来说，我们的研究表明，LLMs作为裁判从高度详细的提示指令中获益甚微，而在某些情况下，特别是对于文本质量的评判，困惑度与人类评判的一致性甚至可能优于提示方法。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，LLMs可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务等多个领域，并采用三个LLMs进行实验，结果喜人，再次证明设计恰当的提示格式远比在特定描述上花费精力更为有效和高效。一旦论文发表，我们的代码将公开可用。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|**文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误进一步提升性能。现有的纠错方法需要LLMs直接对生成的SQL进行修正，而先前研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果发现并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和框架解析来进行SQL纠错。DAC首先生成与问题对应的实体和框架，然后比较初始SQL与生成的实体和框架之间的差异，作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA数据集上的平均性能提升了3.7%，证明了DAC的有效性。**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不协调的内容，这种现象经验性地称为“幻觉”。为解决这一问题，近期研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码方法，已展现出可喜成果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在特定情况下可能导致错误。本文引入了一种新颖的对比解码框架，名为LOL（较低层重要）。我们的方法是连接原始模型与业余模型在最终层与更低层的对比解码结果，从而实现多层融合，以助于缓解幻觉现象。此外，我们融入了一个侧重真实性的模块，该模块利用上下文引导增强事实编码，进一步在对比解码过程中捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉现象，并在多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）的文本生成中展示了显著的性能提升，通过采用多种推理路径。然而，这类技术依赖于精确的答案抽取过程来聚合多个输出，并且由于需要生成相对较多的输出令牌，其推断成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够促使LLMs输出更加多样化。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本论文中，我们引入了PEDAL（基于示例多样性的提示，通过LLMs聚合），一种混合自我集成方法，它结合了多样示例基于提示的优势与LLM基于的聚合，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推断成本下达到更高的准确率，相比基于自我一致性方法亦是如此。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语及英语环境中处理心理学任务的能力。PsychoLex的核心贡献包括：PsychoLexQA数据集，用于教学内容的指导；以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情景中的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相较于通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此研究作为将LLMs融入特定心理学领域的奠基性工作，对促进AI驱动的心理学实践未来发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|**表格推理任务旨在根据给定的表格回答问题。目前，利用大型语言模型（LLMs）是解决表格推理问题的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，鉴于每个实例需要不同的能力和模型具有不同的能力，不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明这一观点，结果显示在使用不同表格格式时，不同的实例和模型会取得不同的表现。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM来预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码、自我一致性解码达到的最佳性能相比，平均提升了2.3%和4.8%，从而验证了我们方法的有效性。**|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|环境回波通信（Ambient backscatter communications，简称AmBC）是一种有前景的技术，旨在通过反射或吸收周围无线电频率（RF）信号来解决无线通信中的能耗挑战。然而，该技术需应对环境RF信号的复杂性和往返路径损耗问题。对于传统检测器而言，引入导频序列会导致频谱效率降低。此外，传统的基于能量的检测器固有地存在显著的错误地板问题，这是由同信道直接链路干扰（DLI）引起的。因此，本文提出了一种盲符号检测器，无需事先知晓信道状态信息、信号方差和噪声方差。通过利用符号内差分幅移键控（Intra-Symbol Differential Amplitude Shift Keying，IDASK）方案，该检测器能有效引导大部分DLI能量朝向接收样本协方差矩阵的最大特征值，同时利用次大特征值进行高效的符号检测。此外，本文还对所提检测器的理论性能进行了分析，包括误警概率、漏检概率以及比特误码率（BER）的下界。仿真结果表明，与传统检测器相比，所提出的盲检测器在符号检测性能上实现了显著提升。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征和汇总的影响。我们的分析指出，AI有潜力提升战略分析的速度、质量和规模，并促进诸如虚拟战略模拟等新方法的发展。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，将AI在SDM中的应用与企业成果相联系，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的研究勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏考虑。在本文中，我们通过引入一种新颖的数据管道来应对这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、特定领域的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。所得到的评估集包含了14个类别下的1573个样本，展示了在十大顶级模型间的高可分离性（84%），并与Chatbot Arena的评价一致度达到84%，斯皮尔曼相关系数为0.915。这些一致度值比Arena Hard高出9%，比AlpacaEval 2.0 LC高出20%，而斯皮尔曼系数比下一个最佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|本文介绍了一种名为Xpikeformer的混合模拟-数字硬件架构，旨在加速基于尖峰神经网络（SNN）的变压器模型。通过结合SNN的能量效率和时间动态特性与变压器的强大序列建模能力，Xpikeformer利用混合模拟-数字计算技术来增强性能和能源效率。该架构集成了模拟内存中计算（AIMC）以处理前馈和全连接层，以及一个随机尖峰注意力（SSA）引擎以实现高效的注意力机制。我们详细说明了Xpikeformer的设计、实施与评估过程，展示了在能源消耗和计算效率方面的显著改进。通过图像分类任务和无线通信符号检测任务，我们证明Xpikeformer能达到与软件相当的推理准确性。能源评估显示，与最先进的数字ANN变压器相比，Xpikeformer能实现高达17.8至19.2倍的能源消耗减少，与全数字SNN变压器相比，则可达到5.9至6.8倍的能源消耗减少。此外，Xpikeformer相较于GPU实现的尖峰变压器还实现了12.0倍的加速。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|**设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是研究领域的重大课题。过往的研究侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制的解码器生成策略条件化的回复。近年来，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，近期研究表明，LLMs对某些社会情感策略的内在偏好偏见阻碍了高质量情感支持的传递。为应对这一挑战，我们提议将策略预测与语言生成解耦，并引入一种新颖的对话策略预测器EmoDynamiX，它利用异质图来模拟用户情绪与系统策略之间的语篇动态。此外，我们借助于对话中的情感识别（ERC）任务，设计了一个灵活的混合情感模块以捕捉用户的精细化情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大规模语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）的广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量判断时，如文本的连贯性，预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLM作为裁判的评估仅仅基于提示中的指示进行评价，还是反映了其对类似于其微调数据高质量样本的偏好。为了探究对LLM裁判的提示引导在其评判与人类评判的一致性上有多大影响，我们分析了针对几个LLM裁判的不同级别指示提示，这些提示详细说明了评价目标的质量标准。此外，我们还对比了一种无提示方法，即使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs进行的最先进评估中，并以此作为模型作为裁判的严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的指示提示中获益甚微，且在某些情况下，特别是对于文本质量的评判，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述性说明的具体内容；性能的提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架也能带来改进。我们进一步将这一新型集成提示应用于包括常识、数学、逻辑推理和幻觉任务在内的广泛任务上，测试了三个LLMs，并取得了有希望的结果，再次表明设计合适的提示格式远比在特定描述上投入精力更为有效和高效。一旦论文发表，我们的代码将会公开可用。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）的文本生成中展示了显著的性能提升。然而，这些技术依赖于精确答案提取过程来聚合多个输出，并且由于需要生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，近期在LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可以轻松扩展到自我集成方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性的提示，通过LLMs聚合），一种混合自我集成方法，它结合了多样示例基于提示的优势和LLM基于聚合的力量，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大规模语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相较于通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|**表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们认为，每个实例需要不同的能力和模型具有不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明这一观点，结果显示在使用不同表格格式时，不同的实例和模型表现各异。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式下的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示出了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、呈现与整合的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和规模，并促成新的方法，如虚拟战略模拟。然而，其对企业绩效的最终影响将取决于AI能力进步下的竞争动态。我们提出了一种框架，连接了AI在SDM中的应用与企业成果，并讨论了AI如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的格局，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏考虑。在本文中，我们通过引入一种新颖的数据管道来解决这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含1573个样本，横跨14个类别，展现了在十大顶级模型间高达84\%的高可分离性，并与Chatbot Arena的评价一致度达到84\%，斯皮尔曼相关系数为0.915。这些一致度数值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比次佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵见解。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|**设计具有情感智能的对话系统，以向处于困境中的人提供安慰和建议，是研究中的一个引人注目领域。以往的研究侧重于开发模块化对话系统，将社会情感策略预测作为辅助任务，并利用定制的解码器生成策略条件化的回应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一种新颖的对话策略预测器EmoDynamiX，它利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一个灵活的混合情感模块来捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX以显著优势超越了先前的最先进方法。**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大规模语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）的广泛应用，像GPT4和Llama3这样的最先进LLMs在被提示进行质量评判时（例如文本的连贯性），预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLM作为裁判的评估仅仅基于提示中的指令，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示在多大程度上影响AI评判与人类评判的一致性，我们分析了针对几个LLM裁判的不同级别指令提示，这些提示详细说明了评价目标的质量要求。此外，我们还对比了一种无提示方法，即使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs的最先进评估中，并以此作为模型作为裁判的严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的指令提示中获益甚微，且在某些情况下，特别是对于文本质量的评判，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的功能尚未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务等多个领域，并采用三个LLMs进行实验，取得了令人鼓舞的结果，再次表明设计合适的提示格式远比在特定描述上投入精力更为有效和高效。一旦论文发表，我们的代码将公开可用。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|**文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行纠错，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修正错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL纠错。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，以此作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不协调的内容，这种现象经验上称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜的效果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在某些情况下可能导致错误。在本文中，我们介绍了一种新颖的对比解码框架，名为LOL（较低层重要）。我们的方法将原始模型与业余模型在最终层和较低层的对比解码进行拼接，从而实现多层融合，以助于缓解幻觉。此外，我们融入了一个侧重真实性的模块，利用上下文引导加强事实编码，在对比解码过程中进一步捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉问题，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|深度学习（DL）领域中基于变换器架构的模型已经彻底改变了诸多DL应用，例如大型语言模型（LLMs）、视觉变换器、音频生成及时间序列预测。这些进步很大程度上得益于分布式训练，然而分布式通信仍然是训练进度的一个重大瓶颈。该论文考察了变换器模型的通信行为，即在变换器架构背景下，多节点/多GPU深度学习训练中所采用的不同并行化方案如何传输数据。我们以基于GPT的语言模型作为变换器架构的案例研究，因为它们的普遍性。我们利用从通信日志中获得的经验结果，并通过分析模型进行验证。总体而言，我们的分析揭示了进一步优化小消息点对点通信的需求、序列长度、每GPU吞吐量、模型大小及所使用优化措施之间的关联，以及在框架和高性能计算中间件设计与优化中潜在的进一步优化方向。|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|序列推荐系统通过分析用户的过往交互来预测其下一个感兴趣项目，从而使得推荐内容与个人偏好相契合。近期方法利用大语言模型（LLMs）在知识理解和推理上的优势，通过语言生成范式将LLMs应用于序列推荐中。这些方法将用户行为序列转化为提示以供LLM微调，并采用低秩适应（LoRA）模块来优化推荐。然而，对不同用户行为统一应用LoRA有时无法捕捉个体差异性，导致次优性能及在迥异序列间的负面迁移。为应对这些挑战，我们提出了实例级LoRA（iLoRA），它将LoRA与专家混合（MoE）框架相结合。iLoRA创建了多样化的专家集合，每个专家捕获用户偏好的特定方面，并引入了由历史交互序列处理产生的丰富表示引导的门控函数。该门控函数指导门网络输出定制化的专家参与权重，这一量身定制的方法减轻了负面迁移并能动态适应多样的行为模式。在三个基准数据集上的广泛实验验证了iLoRA的有效性，特别是在捕捉用户特定偏好和提升推荐准确性方面，相比现有方法展现出更优越的性能。|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|尽管近期的大型语言模型（LLMs）在以多种语言响应查询方面展现出非凡的能力，但它们处理长篇多语言上下文的能力尚未得到探索。因此，系统性地评估LLMs在多语言环境下的长上下文能力，特别是在信息检索的背景下，变得至关重要。为了填补这一空白，我们引入了MultiLingual Needle-in-a-Haystack（MLNeedle）测试，旨在评估模型从多语言干扰文本集合（干草堆）中检索相关信息（针）的能力。该测试是对多语言问答任务的扩展，涵盖了单语种和跨语言检索。我们在MLNeedle上对四种最先进的LLMs进行了评估。研究发现，模型性能会随着语言和针位置的不同而显著变化。具体而言，我们观察到当针（相关信息）处于英语语系之外的语言中且位于输入上下文中间时，模型表现最差。此外，尽管某些模型声称其上下文大小为8,000个令牌或更大，但随着上下文长度的增加，没有模型展现出令人满意的跨语言检索性能。我们的分析为理解LLMs在多语言设置中的长上下文行为提供了关键见解，以指导未来的评估协议。据我们所知，这是首次研究探索LLMs在多语言环境下的长上下文行为。|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|本研究展示了一种通过预训练大型语言模型（LLMs）的指令微调方法，以自动化生成AI研究排行榜，从文章中抽取（任务，数据集，指标，得分）四元组。该研究旨在通过从传统的手动社区整理或受分类约束的自然语言推理（NLI）模型，转向自动化的、生成式的LLM基线方法，来简化AI研究成果的传播。利用FLAN-T5模型，此研究增强了LLMs在信息提取方面的适应性和可靠性，提供了一种结构化知识表示的新方法。|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|null|分子性质预测是药物发现的重要基础。近年来，预训练深度学习模型已被广泛应用于这一任务。一些方法通过将先验生物学领域知识融入预训练框架，取得了显著成果。然而，这些方法严重依赖于生物化学专家，并且收集和归纳大量领域知识文献既耗时又昂贵。大型语言模型（LLMs）在理解和高效提供通用知识方面展示了卓越的性能。尽管如此，它们有时会出现幻觉，并且在生成领域特定知识时缺乏精确性。相比之下，领域特定小型模型（DSMs）拥有丰富的领域知识，能够准确计算分子领域相关指标。但由于其模型尺寸有限且功能单一，它们缺乏进行综合表示学习所需的广泛知识。为了在分子性质预测中结合两种方法的优势，我们提出了一种新颖的分子图表示学习框架，该框架整合了大型语言模型与领域特定小型模型（MolGraph-LarDo）。技术上，我们设计了一个两阶段提示策略，其中DSMs被引入以校准LLMs提供的知识，增强了领域特定信息的准确性，从而使LLMs能够为分子样本生成更精确的文本描述。随后，我们采用多模态对齐方法来协调不同模态，包括分子图及其对应的描述文本，以指导分子表示的预训练。广泛的实验验证了所提方法的有效性。|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|在多模态语言模型（MLMs）中，为了微调和对齐而手动标注高质量的图像-文本配对数据的成本极高。尽管现有的多模态数据增强框架提出了增强图像-文本配对的方法，但它们要么遭受文本与图像之间的语义不一致性，要么生成不真实的图像，从而导致与现实世界示例之间的知识差距。为了解决这些问题，我们提出了基于属性的多模态数据增强方法（ARMADA），这是一种新颖的多模态数据增强方法，通过在知识引导下操作提及实体的视觉属性来实现。具体而言，我们从原始文本数据中提取实体及其视觉属性，然后在知识库（KBs）和大型语言模型（LLMs）的指导下搜索这些视觉属性的替代值。随后，我们使用图像编辑模型根据提取的属性来编辑图像。ARMADA作为一种新颖的多模态数据生成框架，其特点包括：(i) 从符号KB中抽取知识支撑的属性以实现语义上一致且具有差异性的图像-文本配对生成，(ii) 利用KB层次结构中的相邻实体生成不同类别但视觉相似的图像，以及(iii) 利用LLMs的常识知识调节如背景等辅助视觉属性，以实现原始实体的更稳健表示。我们在四个下游任务上的实证结果展示了我们的框架能够生成高质量数据并提升模型性能，这同时也强调了为了增强可解释性和现实世界的贴合度，需要利用外部知识代理的重要性。|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|隐私研究近年来备受关注，因为人们担忧在与智能设备、社交平台及AI应用互动时个人数据可能轻易泄露。计算机科学领域的研究者通常通过针对特定领域的隐私攻击与防护来探究隐私问题。隐私研究跨越多个子领域，涵盖计算机视觉（CV）、自然语言处理（NLP）及计算机网络等。在每个领域中，隐私问题都有其独特的表述方式。尽管先驱性工作揭示了敏感的隐私问题，但它们往往局限于特定情境，未能全面覆盖人们实际的隐私担忧。因此，关于通用性和以人为本的隐私研究仍处于相对未开发的状态。  本文将隐私问题构建为一个推理问题，而非简单的模式匹配。我们基于情境完整性（Contextual Integrity, CI）理论，该理论认为人们对隐私的认知与具体社会情境紧密相关。基于这一假设，我们制定了首个综合检查清单，涵盖了社会身份、私人属性以及现有的隐私法规。与先前仅涉及有限专家标注规范或模拟不完整社会情境的CI研究不同，我们提出的隐私检查清单以1996年《健康保险流通与责任法案》（HIPAA）为例，展示如何利用大型语言模型（LLMs）全面覆盖HIPAA的条例。此外，我们的检查清单还汇总了跨多个本体的专家注释，以确定包括但不限于个人可识别信息（PII）在内的私人信息。  我们借助对HIPAA的初步研究成果，为未来以情境为中心的隐私研究指明方向，旨在涵盖更多隐私法规、社会规范和标准。|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|临床诊断在医学实践中至关重要，通常需要一个连续且不断发展的过程，涵盖初步诊断、鉴别诊断和最终诊断等环节。然而，目前大多数临床诊断任务都是单一步骤的过程，这与现实中复杂多步骤的临床诊断程序不相符。本文针对这一问题，提出了一项多步骤诊断任务，并标注了一个临床诊断数据集（MSDiagnosis）。该数据集包含了初步诊断、鉴别诊断和最终诊断等问题。此外，我们提出了一种新颖而有效的方法框架。该框架结合了前向推理、后向推理、反思与修正，使得语言模型能够自我评估并调整其诊断结果。为了验证所提方法的有效性，我们设计并实施了广泛的实验。实验结果显示，所提出的方案具有显著的有效性。同时，我们也提供了全面的实验分析，并为该领域的未来研究方向提出了建议。|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|GPU内存容量的增长速度未能跟上大型语言模型（LLMs）规模扩增的步伐，这对模型训练过程构成了阻碍。尤其是激活值——前向传播期间产生的中间张量，并在反向传播中被重用——在GPU内存使用中占主导地位。为了解决这一挑战，我们提出了TBA方法，高效地将激活值卸载到高容量的NVMe SSD上。该方法通过自适应地将数据传输与计算重叠，减少了GPU内存占用，同时不影响性能。TBA与PyTorch、Megatron和DeepSpeed等流行的深度学习框架兼容，并采用了张量去重、前传以及自适应卸载等技术以进一步提高效率。我们在GPT、BERT和T5上进行了广泛的实验。结果表明，TBA有效减少了47%的激活值峰值内存使用。同时，TBA完美地将I/O操作与计算重叠，带来的性能开销可忽略不计。我们引入了重新计算-卸载-保留（ROK）曲线，以比较TBA卸载策略与其他两种张量放置策略（保持激活值在内存中及逐层全量重新计算）的效果。我们发现，TBA在实现比逐层全量重新计算更优的内存节省的同时，还保持了将激活值保留在内存中的性能水平。|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|本研究深入探索了大型语言模型（LLMs）ChatGLM在自动生成国家教师资格考试（NTCE）结构化试题方面的应用潜力。通过精心设计的提示工程，我们指导ChatGLM生成了一系列模拟试题，并与过往考生回忆的试题进行了全面对比。为确保评估的客观性和专业性，我们邀请了教育领域的专家对这些试题及其评分标准进行评价。研究结果显示，ChatGLM生成的试题在大多数评价标准下展现了与真实考试试题相当的合理性、科学性和实用性，彰显了该模型在试题生成上的准确性和可靠性。然而，研究也揭示了模型在生成试题时对各类评价指标考虑的局限性，表明还需进一步优化和调整。此项研究不仅验证了ChatGLM在教育测评领域的应用潜力，也为未来开发更高效、智能化的教育自动化生成系统提供了重要的实证支持。|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，最近在LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），一种混合自我集成方法，它结合了多样化示例提示和基于LLM聚合的优势，以提高整体性能。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情景中的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们认为，每个实例需要不同的能力，而模型也具备不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析，证明了上述观点，在不同格式下，不同的实例和模型表现各异。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式下的结果。在WikiTableQuestions和TabFact数据集上的实验显示出了显著的改进，与使用固定表格格式及贪婪解码、自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时促进如虚拟战略模拟等新方法的发展。然而，其对企业绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一种新颖的数据管道来应对这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。所得到的评估集涵盖了14个类别的1573个样本，展示了在十大顶级模型间的高可分离性（84\%），并与Chatbot Arena的符合度达到84\%，Spearman相关系数为0.915。这些符合度值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而Spearman系数比下一个最佳基准高出0.7，彰显了基准实用性方面的显著提升。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。本工作对增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究显示，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，该预测器利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块以捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）的广泛应用，像GPT4和Llama3这样的最新语言模型在被提示进行质量判断时（例如文本的连贯性），预期会与人类偏好有很强的一致性。尽管这看似有利，但目前尚不清楚LLM作为裁判的评估仅仅是基于提示中的指令进行的评估，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示在多大程度上影响了AI评判与人类评判的一致性，我们分析了针对几个LLM裁判的、关于评价目标质量的指示逐渐增加的提示。此外，我们还对比了一种无提示方法，该方法使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类，这些标准广泛应用于采用LLMs的最先进评估中，并提供了作为裁判的模型严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的提示指令中获益甚微，且在某些情况下，尤其是对于文本质量的评判，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。出乎意料的是，语言模型可能并不在乎描述性说明的具体内容；性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务，涉及三种LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式比专注于特定描述内容，在效率和效果上更为有效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行修正，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL修正。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，作为纠错的反馈。实验结果表明，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生事实不准确或与期望输出不一致的内容，这种现象经验上称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜的效果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在某些情况下可能导致错误。在本文中，我们介绍了一种新颖的对比解码框架，名为LOL（较低层重要）。我们的方法包括连接原始模型与业余模型在最终层和较低层的对比解码，以此实现多层融合，以助于缓解幻觉。此外，我们融入了一个侧重真实性的模块，该模块利用上下文引导来增强事实编码，进一步在对比解码过程中捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉问题，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|深度学习（DL）模型，尤其是基于变压器架构的模型，已经彻底改变了众多DL应用领域，如大型语言模型（LLMs）、视觉变换器、音频生成及时间序列预测。这些进步很大程度上得益于分布式训练，然而，分布式通信仍然是训练进展中的一个重大瓶颈。本文考察了变压器模型的通信行为，即在多节点/多GPU深度学习训练中，针对变压器架构采用的不同并行方案如何进行数据通信。我们以基于GPT的语言模型作为变压器架构的案例研究，因其普遍性。我们利用通信日志记录的实证结果，并通过分析模型进行验证。总体而言，我们的分析揭示了进一步优化小消息点对点通信的需求、序列长度、每GPU吞吐量、模型大小及所使用优化方法之间的关联，以及在框架和高性能计算（HPC）中间件设计与优化中潜在的进一步优化方向。|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|序列推荐系统通过分析用户的过往交互来预测其下一个感兴趣项目，从而使推荐内容与个人偏好相吻合。近期方法利用大语言模型（LLMs）在知识理解和推理上的优势，通过语言生成范式将LLMs应用于序列推荐中。这些方法将用户行为序列转化为提示，以供LLM微调，并采用低秩自适应（LoRA）模块来优化推荐。然而，对不同用户行为统一应用LoRA有时无法捕捉个体差异性，导致次优性能及在迥异序列间的负迁移。针对这些挑战，我们提出了实例级LoRA（iLoRA），它将LoRA与专家混合（MoE）框架相结合。iLoRA创建了多样化的专家集合，每个专家捕获用户偏好的特定方面，并引入了由序列表示引导的门函数。该门函数处理历史交互序列以生成丰富表示，指导门网络输出定制化的专家参与权重。这一量身定制的方法缓解了负迁移问题，并能动态适应多样的行为模式。在三个基准数据集上的广泛实验验证了iLoRA的有效性，尤其在捕捉用户特定偏好和提升推荐准确性方面，相比现有方法展现出更优越的性能。|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|null|尽管近期的大型语言模型（LLMs）在以多种语言响应查询方面展现出非凡的能力，但它们处理长篇多语言上下文的能力尚未得到探索。因此，系统性地评估LLMs在多语言环境下的长上下文处理能力，特别是在信息检索的背景下，变得尤为重要。为填补这一空白，我们引入了MultiLingual Needle-in-a-Haystack（MLNeedle）测试，旨在评估模型从一系列多语言干扰文本（干草堆）中检索相关信息（针）的能力。该测试是对多语言问答任务的扩展，涵盖了单语和跨语言检索。我们在MLNeedle上对四种最先进的LLMs进行了评估。研究发现，模型性能会随着语言和针位置的不同而显著变化。具体而言，我们观察到当针（相关信息）处于英语语系之外的语言中且位于输入上下文的中间位置时，模型的表现最低。此外，尽管某些模型声称其上下文大小为8,000个令牌或更多，但随着上下文长度的增加，没有模型展现出令人满意的跨语言检索性能。我们的分析为理解LLMs在多语言设置下的长上下文行为提供了关键洞察，旨在指导未来的评估标准。据我们所知，这是首次研究探讨LLMs在多语言环境中的长上下文行为。|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|本研究展示了一种通过预训练大型语言模型（LLMs）的指令微调方法，以自动化生成AI研究排行榜，从文章中抽取（任务，数据集，指标，得分）四元组。该研究旨在通过从传统的手动社区整理或受分类约束的自然语言推理（NLI）模型，转向自动化的、生成式的LLM为基础的方法，来简化AI研究成果的传播。利用FLAN-T5模型，此研究增强了LLMs在信息提取方面的适应性和可靠性，提供了一种结构化知识表示的新方法。|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|null|分子性质预测是药物发现的重要基础。近年来，预训练深度学习模型已被广泛应用于这一任务。一些方法通过将先验生物学领域知识融入预训练框架，取得了显著成果。然而，这些方法严重依赖于生物化学专家，并且收集和归纳大量领域知识文献既耗时又昂贵。大型语言模型（LLMs）在理解和高效提供通用知识方面展示了卓越的性能。尽管如此，它们有时会出现幻觉，并且在生成领域特定知识时缺乏精确性。相比之下，领域特定小型模型（DSMs）拥有丰富的领域知识，能够准确计算分子领域相关指标。但由于其模型尺寸有限且功能单一，它们缺乏进行综合表示学习所需的广泛知识。为了在分子性质预测中结合两种方法的优势，我们提出了一种新颖的分子图表示学习框架，该框架整合了大型语言模型与领域特定小型模型（MolGraph-LarDo）。技术上，我们设计了一个两阶段提示策略，其中DSMs被引入来校准LLMs提供的知识，提高了领域特定信息的准确性，从而使LLMs能够为分子样本生成更精确的文本描述。随后，我们采用多模态对齐方法来协调不同模态，包括分子图及其对应的描述文本，以指导分子表示的预训练。广泛的实验验证了所提方法的有效性。|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|在多模态语言模型（MLMs）中，为了微调和对齐而手动标注高质量的图像-文本配对数据的成本极高。尽管现有的多模态数据增强框架提出了增强图像-文本配对的方法，但它们要么遭受文本与图像之间的语义不一致性，要么生成不真实的图像，从而导致与现实世界示例之间的知识差距。为了解决这些问题，我们提出了基于属性的多模态数据增强方法（ARMADA），这是一种新颖的多模态数据增强方法，通过在知识引导下操作提及实体的视觉属性来实现。具体来说，我们从原始文本数据中提取实体及其视觉属性，然后在知识库（KBs）和大型语言模型（LLMs）的指导下搜索这些视觉属性的替代值。接着，我们利用图像编辑模型根据提取的属性来编辑图像。ARMADA作为一种新颖的多模态数据生成框架，其特点包括：(i) 从符号KB中抽取知识支撑的属性以实现语义上一致且具有区分度的图像-文本对生成，(ii) 利用KB层次结构中的相邻实体生成不同类别但视觉相似的图像，以及(iii) 利用LLMs的常识知识调节如背景等辅助视觉属性，以实现原始实体更鲁棒的表示。我们在四个下游任务上的实证结果证明了我们的框架能够生成高质量的数据并提升模型性能，这同时也强调了为增强可解释性和现实世界的贴合度而利用外部知识代理的必要性。|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|隐私研究因个人担忧在与智能设备、社交平台及AI应用交互时私人数据易遭泄露而广受关注。计算机科学领域中的研究者则通常通过针对特定领域的隐私攻击与防护来探究隐私问题。隐私研究覆盖了多个子领域，涵盖计算机视觉（CV）、自然语言处理（NLP）及计算机网络等。在每个领域内，隐私问题各有其表述方式。尽管先驱性工作揭示了敏感的隐私问题，但它们往往局限于狭隘视角，未能全面涵盖人们实际的隐私忧虑。因此，关于通用性和以人为本的隐私研究仍处于相对未开发的状态。  本文将隐私问题构架为一个推理问题，而非简单的模式匹配。我们基于情境完整性（Contextual Integrity, CI）理论，该理论认为人们对隐私的认知与其所处的社会情境高度相关。在此假设基础上，我们制定了首个综合检查清单，涵盖了社会身份、私人属性及现行隐私法规。不同于以往仅涉及有限专家标注规范或模型化不完整社会情境的CI研究，我们提出的隐私检查清单以1996年《健康保险流通与责任法案》（HIPAA）为例，展示如何利用大型语言模型（LLMs）全面覆盖HIPAA的各项规定。此外，我们的检查清单还汇集了跨多个本体的专家注释，用以确定包括但不限于个人可识别信息（PII）在内的私人信息。  我们借助对HIPAA的初步研究成果，为未来以情境为中心的隐私研究指明方向，旨在涵盖更多隐私法规、社会规范及标准。|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|临床诊断在医疗实践中至关重要，通常需要一个连续且不断发展的过程，涵盖初步诊断、鉴别诊断和最终诊断等环节。然而，目前大多数临床诊断任务都是单一步骤的过程，这与现实中复杂多步骤的临床诊断程序不相符。本文针对这一问题，提出了一项多步骤诊断任务，并标注了一个临床诊断数据集（MSDiagnosis）。该数据集包含了初步诊断、鉴别诊断和最终诊断等问题。此外，我们设计了一个新颖而有效的方法框架。此框架结合了前向推理、后向推理、反思与精炼，使得语言模型能够自我评估并调整其诊断结果。为了验证所提方法的有效性，我们设计并实施了广泛的实验。实验结果显示，所提出的这种方法具有显著的有效性。同时，我们也提供了全面的实验分析，并对未来研究方向提出了建议。|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|GPU内存容量的增长速度未能跟上大型语言模型（LLMs）规模扩增的步伐，这对模型训练过程构成了阻碍。尤其是激活值——前向传播期间产生的中间张量，并在反向传播中重用——在GPU内存占用中占主导地位。为了解决这一挑战，我们提出了TBA方法，高效地将激活值卸载到高容量的NVMe SSD上。该方法通过自适应地将数据传输与计算重叠，减少了GPU内存使用，同时不影响性能。TBA与PyTorch、Megatron和DeepSpeed等主流深度学习框架兼容，并采用张量重复数据删除、前传以及自适应卸载等技术进一步提高效率。我们在GPT、BERT和T5上进行了广泛实验。结果表明，TBA有效减少了47%的激活值峰值内存占用。同时，TBA完美地将I/O操作与计算重叠，几乎不产生性能开销。我们引入了重计算-卸载-保留（ROK）曲线，以比较TBA卸载策略与其他两种张量放置策略（内存中保持激活值和逐层全重计算）的效果。我们发现，TBA在实现比逐层全重计算更好的内存节省的同时，还能保持与内存中保持激活值相近的性能表现。|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|本研究深入探索了大型语言模型（LLMs）ChatGLM在自动生成国家教师资格考试（NTCE）结构化试题方面的应用潜力。通过精心设计的提示工程，我们引导ChatGLM生成了一系列模拟试题，并与过往考生回忆的试题进行了全面比较。为了确保评估的客观性和专业性，我们邀请了教育领域的专家对这些试题及其评分标准进行评价。研究结果显示，ChatGLM生成的试题在大多数评价标准下展现了与真实考试试题相当的合理性、科学性和实用性，彰显了该模型在试题生成上的准确性和可靠性。然而，研究也揭示了模型在生成试题时对各类评价指标考虑的局限性，表明还需进一步优化和调整。此项研究不仅验证了ChatGLM在教育测评领域的应用潜力，也为未来开发更高效、智能化的教育自动化生成系统提供了重要的实证支持。|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以使用LLMs可靠地聚合以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可以轻松扩展到自我集成方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性的提示，通过LLMs聚合），一种混合自我集成方法，它结合了多样示例基于提示的优势和LLM基于聚合的能力，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们展示了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相较于通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性步伐，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，每个实例需要不同的能力和模型具有不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明上述观点，其中不同的实例和模型在使用各种表格格式时表现出不同的性能。在此讨论的基础上，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时启用如虚拟战略模拟等新方法。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在现实应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一个新颖的数据管道来解决这些局限性，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含14个类别下的1573个样本，展现了在十大排名靠前的模型间高达84\%的高可分离性，并与Chatbot Arena的评价一致性达到84\%，斯皮尔曼相关系数为0.915。这些一致性数值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比下一个最佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。此项工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究显示，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，该预测器利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块以捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）被广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量判断时（例如文本的连贯性），预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLM作为裁判的评估仅仅基于提示中的指示进行评价，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示引导在其评判与人类评判的一致性上有多大影响，我们分析了针对几个LLM裁判的不同级别指示提示，这些提示旨在明确目标评价质量。此外，我们还对比了一种无提示方法，该方法使用模型困惑度作为质量度量标准。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs进行的先进评估中，并以此作为模型作为裁判的严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的指示提示中获益甚微，且在某些情况下，特别是对于文本质量的评价，困惑度比提示方法能更好地与人类判断保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务中，涉及三个不同的LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式远比专注于具体描述内容更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行纠正，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修正错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL纠错。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，以此作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不一致的内容，这种现象经验上被称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜的成果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在特定情况下可能导致错误。在本文中，我们引入了一个新颖的对比解码框架，称为LOL（较低层重要）。我们的方法将原始模型与业余模型在最终层和较低层的对比解码进行拼接，从而实现多层融合，以助于缓解幻觉现象。此外，我们融入了一个注重真实性的重聚焦模块，利用上下文引导增强事实编码，在对比解码过程中进一步捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉现象，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|**[link](https://github.com/hkustdial/nl2sql_handbook)**|**自然语言查询到SQL查询的转换（即NL2SQL）能够显著降低访问关系型数据库的门槛，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对LLM驱动的NL2SQL技术的全面回顾，从四个方面覆盖了其整个生命周期：（1）模型：解决不仅包括自然语言的歧义和欠指定问题，还恰当映射自然语言与数据库模式及实例的NL2SQL翻译技术；（2）数据：从训练数据的收集，由于训练数据稀缺而进行的数据合成，到NL2SQL基准测试集的建立；（3）评估：利用不同指标和粒度从多个角度评估NL2SQL方法；以及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进一步发展。此外，我们为开发NL2SQL解决方案提供了一套实用指南。最后，我们讨论了LLMs时代NL2SQL所面临的科研挑战和开放性问题。**|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现全自动化——包括数据查询、分析、可视化及报告生成——仍是一个复杂挑战。本研究介绍了一款名为SageCopilot的先进工业级系统，该系统通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用两阶段设计：在线阶段利用即时学习（ICL）细化用户输入为可执行脚本并运行这些脚本以生成结果报告与可视化；离线阶段则根据在线阶段ICL的需求准备演示。为了增强性能，SageCopilot采用了诸如Chain-of-Thought和提示调整等前沿策略。通过严格的测试和与基于提示的解决方案的比较分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面，凭借真实世界数据集实现了端到端性能的优越性。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性的个别贡献。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证明能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器动态检索示例，但外部检索器与LLMs之间在表征能力上存在固有的差异。此外，优化示例选择并非易事，因为缺乏直接方法在不进行成对推理的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们设计了一种代理评分，根据输出查询之间的相似性来估计示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为了探讨这一问题，我们提出了一种多角度的NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情境下，如不同数据领域和SQL特性，对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360识别出了一种在Spider数据集上使用执行准确率指标表现优异的有效NL2SQL方法——SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现出竞争优势。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术使不熟悉数据库的非专业用户能够使用SQL进行数据分析。将自然语言转换为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项名为ChatBI的综合且高效的技术来解决NL2BI任务。首先，我们分析了交互模式这一重要模块，这是NL2SQL与NL2BI在应用中的不同之处，并设计了一个更小、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而无法进行。BI场景中更高比例的列义模糊性也使得模式链接变得困难。ChatBI结合了数据库社区现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中选择单个视图。该单视图的列随后作为所需列传递给LLM进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，这使得ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其融入多条产品线中，进行了大规模生产任务评估。所获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，与我们真实BI场景数据表和查询下的当前主流NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进转换过程，重点在于增强对用户意图的理解。然而，由于在组织复杂逻辑运算符组合方面的知识欠缺，LLMs有时无法生成合适的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含了来自不同数据库的已知NL2SQL转换。LLMs能够从输入的示例中学习如何为当前任务组织逻辑运算符组合。在本文中，我们提出了PURPLE（用于逻辑增强的预训练模型检索提示），该方法通过检索包含所需逻辑运算符组合的示例以改善NL2SQL任务的准确性，从而指导LLMs生成更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的精确集合匹配准确率和87.8%的执行匹配准确率，树立了新的状态-of-the-art性能标准。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确度，展现出其鲁棒性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取实例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性是一项重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为了实现这一目标，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。我们的全面评估表明，所提出的模型能有效捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到证明。尤其值得一提的是，我们的模型超越了来自OpenAI和Cohere的强大竞争性嵌入模型。此外，与这些竞争模型相比，我们的提议编码器在1-shot情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进步着重于利用大型语言模型（LLM）的上下文学习能力，取得了显著成果。然而，这些方法在处理冗长的数据库信息和复杂用户意图时仍面临挑战。本文提出了一种两阶段框架，旨在提升基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示形式，称为参考增强表示，该表示融合了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，利用链接后的模式，我们简化提示中的模式信息，并指示LLM产出最终SQL。最后，作为后处理优化模块，我们建议采用跨LLM的一致性而非单一LLM内的自一致性作为评估标准。我们的方法在Spider基准测试上达到了新的最佳水平，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺少领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们使用ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，从查询的自然语言中抽取相关图模式作为输入上下文，以此引导LLMs更准确地生成GQL。我们在两个构建于金融领域和医疗领域的图数据库上评估了我们的方法，即FinGQL和MediGQL数据集。实验结果表明，相较于一组基线方法，我们的方法显著提高了性能，分别在精确匹配（EM）上提升了5.90和6.36绝对百分点，在执行精度（EX）上提高了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资产。访问控制跨越两个领域：策略（组织级原则，定义谁应具有访问权限）和流程（数据库级原语，实际实现该策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式——面向数据库的意图型访问控制（Intent-Based Access Control for Databases, IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（NLACM）得以更精确地表达。数据库访问控制原语会根据这些NLACM自动生成。这些原语可用于生成新的数据库配置和/或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（我们称之为LLM4AC），以及初步的基准测试，用以评估此类系统的准确性和覆盖范围。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC远远超越了其他基线，在我们的初始Dr. Spider基准测试中达到了高准确率和F1分数。在所有系统上，我们发现在扩大的基准测试中整体表现优异，这些测试包括需要外部知识的最新NL2SQL数据，以及来自Amazon Access数据集的真实世界角色层次结构。|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|在AIOps（面向IT运营的人工智能）时代，准确预测系统状态至关重要。在微服务系统中，这一任务面临着动态和复杂的空间-时间关系挑战，这主要归因于动态部署、多样的调用路径以及实例间的级联效应。当前的时间序列预测方法主要关注内在模式，在空间关系至关重要的环境中显得不足。同样，空间-时间图方法往往忽视了时间趋势的特性，更多地集中在节点间的消息传递上。此外，微服务领域的现有研究经常低估了网络指标和拓扑结构在捕获系统动态变化中的重要性。本文介绍了一种针对微服务环境中的系统状态预测而设计的模型STMformer，该模型能够处理多节点和多变量时间序列。我们的方法利用动态网络连接数据和拓扑信息来帮助建模系统内部复杂的时空关系。此外，我们集成了PatchCrossAttention模块以全局计算级联效应的影响。我们基于一个微服务系统构建了一个数据集，并对STMformer进行了全面的实验，与领先方法进行对比。在短期和长期预测任务中，我们的模型持续实现了8.6%的MAE（平均绝对误差）降低和2.2%的MSE（均方误差）减少。源代码可于https://github.com/xuyifeiiie/STMformer获取。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|**AIOps算法在微服务系统的维护中发挥着关键作用。许多先前基准测试的性能排行榜为选择合适算法提供了宝贵的指导。然而，现有的AIOps基准主要利用离线数据集来评估算法，无法持续使用实时数据集评估算法性能，并且评估的操作场景是静态的，这对于有效选择算法是不够的。为了解决这些问题，我们提出了一种评估一致性与场景导向的评估框架，名为MicroServo。其核心思想是构建一个实时微服务基准，以生成实时数据集，并在其上持续模拟特定操作场景。MicroServo根据操作场景选择特定算法和数据集来支持不同的排行榜。同时，它还支持多种类型算法的部署，实现了算法的热插拔。最后，我们通过三个典型的微服务操作场景测试了MicroServo，以展示其效率和易用性。**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|大型语言模型（LLMs）和AI代理在软件开发与部署中的迅速应用正在革新信息技术领域。尽管代码生成受到广泛关注，但AI代理在云服务运营韧性方面的应用具有更高的影响力，目前这类服务需要大量的人力投入及专业知识。AIOps（AI for IT Operations）作为新兴热点，旨在通过自动化复杂运维任务，如故障定位和根本原因分析，来减少人工介入并减轻对客户的影响。然而，实现自治和自愈合云的AIOps愿景受到缺乏构建、评估及改进AIOps代理标准化框架的阻碍。该展望论文首先明确需求，随后讨论满足这些需求的设计决策，为这样的框架奠定基础。我们还提出了AIOpsLab原型实现，它利用代理-云接口来编排应用程序，采用混沌工程实时注入故障，并与代理交互以进行故障定位和解决。我们报告了有前景的结果，并为构建、评估及提升自治云代理的模块化、健壮性框架奠定了基础。|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|**日志分析对于确保信息系统有序、稳定运行至关重要，尤其在人工智能运维（AIOps）领域。大型语言模型（LLMs）在自然语言处理任务中展现出巨大潜力。在AIOps领域，它们在异常检测、故障根本原因分析、运维脚本生成及告警信息总结等任务上表现出色。然而，当前LLMs在日志分析任务中的性能验证尚不充分。为解决这一缺口，我们引入了LogEval——首个全面的基准测试套件，旨在首次评估LLMs在各类日志分析任务中的能力。该基准覆盖了日志解析、日志异常检测、日志故障诊断和日志总结等任务。LogEval利用4000条公开的日志数据条目对每个任务进行评估，并为每个任务采用15种不同的提示以确保全面且公平的评估。通过严格评估领先LLMs，我们展示了不同LLM技术对日志分析性能的影响，特别聚焦于自一致性与少量样本上下文学习等方面。同时，我们也讨论了模型量化、中英文问答评估及提示工程的相关发现。这些发现揭示了LLMs在多语言环境下性能的强弱点以及不同提示策略的有效性。针对不同任务采用了多种评估方法，以准确衡量LLMs在日志分析中的表现，确保了全面的评估。LogEval的评估洞察揭示了LLMs在日志分析任务中的优势与局限，为研究人员和实践者提供了宝贵的指导。**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|随着软件系统的复杂性日益增加，为了确保大规模分布式软件系统的高可用性和可靠性，人工智能运维（AIOps）方法在软件系统故障管理中的应用已十分广泛。然而，这些方法仍面临一些挑战，比如跨平台通用性不足和跨任务灵活性欠缺。幸运的是，大型语言模型（LLMs）的最新进展能有效应对这些挑战，众多研究已着手探索这一领域。但目前尚缺乏一份全面的综述来讨论基于LLM的AIOps与传统AIOps方法之间的差异。因此，本文提供了面向LLM时代的AIOps技术在故障管理领域的综合调查。内容涵盖AIOps故障管理任务的详尽定义、AIOps所需的数据来源，以及应用于AIOps的LLM基础方法。此外，本综述还深入探讨了AIOps的子任务、适用于不同AIOps子任务的具体LLM方法，以及该领域面临的挑战与未来发展方向，旨在促进其进一步的发展与应用。|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|**动态图中的异常边检测旨在识别与正常模式显著偏离的边，应用于网络安全、金融交易和AIOps等多个领域。随着时间的推移，异常边的类型不断涌现，而针对每种类型的标注异常样本却十分有限。现有方法要么旨在检测随机插入的边，要么需要大量标注数据进行模型训练，这限制了它们在实际应用中的适用性。本文针对这一问题，通过利用大型语言模型（LLMs）中蕴含的丰富知识，提出了一种名为AnomalyLLM的方法。为了使动态图与LLMs协调工作，AnomalyLLM预先训练了一个动态感知编码器，用于生成边的表示，并利用词嵌入原型重编程边。与编码器相配套，我们设计了一种基于上下文的学习框架，该框架整合了少量标注样本的信息，以实现少样本异常检测。在四个数据集上的实验表明，AnomalyLLM不仅能显著提升少样本异常检测的性能，还能在无需更新模型参数的情况下，对新出现的异常类型达到优越的检测效果。**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|我们推出了一款基于机器学习的异常检测产品——AI检测与响应（AIDR），它能够实时监控沃尔玛的业务和系统健康状况。在为期3个月的验证期间，该产品从超过3000个模型中为25个以上的应用程序、平台和运维团队提供了预测，覆盖了63%的重大事件，并将平均检测时间（MTTD）缩短了超过7分钟。与以往的异常检测方法不同，我们的解决方案结合使用了统计学、机器学习及深度学习模型，同时继续融入基于规则的静态阈值，以整合领域特定知识。为了实现可扩展性和高可用性，不论是单变量还是多变量的机器学习模型，都通过分布式服务进行部署和维护。AIDR具备反馈机制，利用漂移检测算法和客户反馈来评估模型质量，并且提供了自我接入能力和可定制化功能。AIDR已成功应用于多个内部团队，实现了较短的检测时间和更少的误报，相比之前的方案有所提升。展望未来，我们旨在扩大事件覆盖范围和预防能力，减少噪声，并进一步与根本原因推荐（RCR）集成，以实现端到端的AIDR体验。|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|在云原生技术中，微服务架构日益增长的复杂性给维持系统稳定性和效率带来了重大挑战。为了对告警事件进行根本原因分析（RCA）和解决，我们提出了一种开创性的框架——面向微服务架构的根本原因分析多智能体区块链启发式协作（mABC），旨在革新人工智能运维（AIOps）领域。该框架下，多个基于强大大型语言模型（LLMs）的智能体通过区块链启发式的投票达成最终共识，并遵循智能体工作流程设定的标准过程来处理任务和查询。具体而言，依据智能体工作流程，七个专业化的智能体各自根据其专长和内在软件知识，协同工作于一个去中心化链条中，为根本原因分析提供宝贵见解。  为应对LLMs潜在的稳定性问题，并充分利用去中心化结构中固有的透明和平等优势，mABC采纳了受区块链治理原则启发的决策过程，同时考虑每个智能体的贡献指数和专业指数。在公开基准AIOps挑战数据集和我们创建的火车票数据集上的实验结果显示，相较于以往的强基线方法，mABC在准确识别根本原因和制定有效解决方案方面表现出更优性能。进一步的消融研究强调了mABC中各组成部分的重要性，其中智能体工作流程、多智能体协作及区块链启发式投票机制对于达到最佳性能至关重要。  mABC为微服务架构提供了一个全面的自动化根本原因分析与解决框架，在AIOps领域相对于现有基线实现了显著提升。|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|**大型语言模型（LLMs）在众多领域驱动着新一轮的交互式AI应用浪潮。然而，由于生成模型的自回归特性，有效服务于LLM推理请求极具挑战性，这主要源于其不可预测的执行时间。现有的LLM服务系统采用先来先服务（FCFS）调度策略，难以避免队头阻塞问题。为了应对LLM的非确定性本质并实现高效的交互式LLM服务，我们提出了一种推测式最短作业优先（SSJF）调度器，该调度器利用一个轻量级代理模型来预测LLM输出序列的长度。我们的开源SSJF实现无需对内存管理或批处理策略进行修改。在实际数据集和生产工作负载轨迹上的评估表明，与FCFS调度器相比，SSJF在无批处理、动态批处理和连续批处理设置下，分别将平均作业完成时间缩短了30.5%-39.6%，并将吞吐量提高了2.2-3.6倍。**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|现代IT系统的管理带来了独特的挑战，要求在处理大量数据流时具备可扩展性、可靠性和效率。传统的依赖手动任务和基于规则方法在应对IT系统产生的大量数据和警报时显得效率低下。为此，人工智能操作系统（AIOps）应运而生，它利用机器学习和大数据等高级分析手段来加强事件管理。AIOps能够检测和预测事件、识别根本原因，并自动执行修复操作，从而提升服务质量并降低运营成本。然而，尽管潜力巨大，AIOps领域仍处于初级阶段，分散于多个行业且缺乏统一的标准规范。研究与产业贡献分布广泛，缺乏关于数据管理、目标问题、实施细节、需求及能力方面的一致框架。本研究提出了一套AIOps的术语和分类法，确立了结构化的事件管理流程，并为构建AIOps框架提供了指南。研究还根据事件管理任务、应用领域、数据来源和技术方法等标准对贡献进行了分类。旨在通过全面回顾AIOps在事件管理中的技术与研究层面，整理知识体系、识别研究空白，并为该领域的未来发展奠定基础。|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Federated Frank-Wolfe Algorithm**|Ali Dadras et.al.|[2408.10090](http://arxiv.org/abs/2408.10090)|null|近年来，联邦学习（FL）因能构建隐私保护的协同学习系统而备受关注。然而，针对受约束的机器学习问题的FL算法仍有限，特别是在投影步骤成本较高时。为此，我们提出了一种联邦Frank-Wolfe算法（FedFW）。FedFW具有数据隐私保护、每迭代步成本低以及通信信号稀疏等特点。在确定性设置下，FedFW对于光滑且凸的目标函数，能在 $O(\varepsilon^{-2})$次迭代内达到$\varepsilon$-次优解；而对于光滑但非凸的目标函数，则需$O(\varepsilon^{-3})$次迭代。此外，我们还提出了一种随机版本的FedFW，并证明在凸设置下，它能在$O(\varepsilon^{-3})$ 次迭代内找到解。我们通过多个机器学习任务展示了FedFW的实验性能。|
|**2024-08-19**|**Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing**|Vinit Hegiste et.al.|[2408.10024](http://arxiv.org/abs/2408.10024)|null|在联邦学习（FL）领域，特别是在制造业中，为服务器聚合选择客户端权重的策略对于模型性能至关重要。本研究对比分析了两种权重选择策略：最终轮次权重选择（FEWS）和最优轮次权重选择（OEWS）的有效性。针对制造业合作场景通常涉及有限合作伙伴（两到四个客户端）的特点，我们的研究聚焦于联邦图像分类任务。采用EfficientNet、ResNet和VGG等多种神经网络架构，评估这些权重选择策略对模型收敛性和鲁棒性的影响。研究旨在确定在通信轮次（CR）中，是FEWS还是OEWS能更有效地提升全局FL模型的表现。通过实证分析和严谨实验，我们力求为优化制造业中的FL实施提供宝贵见解，确保协作努力能够产生最有效和可靠的模型，并且参与客户端数量有限。本研究的发现预计将显著细化制造业中的FL实践，从而增强这一关键领域中协作机器学习努力的效率和性能。|
|**2024-08-19**|**Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets**|Xingrun Yan et.al.|[2408.09762](http://arxiv.org/abs/2408.09762)|null|在实际的联邦学习（FL）系统中，客户端与参数服务器（PS）间传递模型参数的通信开销常常成为瓶颈。层次化联邦学习（HFL）通过在客户端与PS之间设置多级边缘服务器（ESs）部分缓解了这一问题，但仍然需要从多个ES汇总模型参数至PS。为了进一步减少通信开销，我们首次将顺序联邦学习（SFL）引入HFL中，该方法取消了中心PS，使得模型训练仅需通过每轮迭代时在两个相邻ES间传递全局模型即可完成，并提出了一种适应此组合框架的新型算法，称为Fed-CHS。在不同的数据异质性设定下，针对强凸和非凸损失函数，我们推导了收敛性结果，表明其收敛性能可与仅采用HFL或SFL的算法相媲美。实验结果进一步证实了我们提出的Fed-CHS在节省通信开销和提高测试准确性方面相对于基线方法的优势。|
|**2024-08-18**|**Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment**|Tatjana Legler et.al.|[2408.09556](http://arxiv.org/abs/2408.09556)|null|联邦学习（FL）作为一种在保护数据隐私的同时跨分散数据源训练机器学习模型的有前景方法，尤其在制造业和共享生产环境中的应用日益凸显。然而，不同客户端和生产场所间存在的数据异质性——包括数据分布、质量和数量的变化——对FL的有效性和效率构成了重大挑战。本文全面概述了制造业背景下FL中的异质性问题，详细说明了异质性的类型及来源，如非独立同分布（non-IID）数据、不平衡数据、变化的数据质量和统计异质性。我们讨论了这些类型的异质性对模型训练的影响，并回顾了当前缓解其不利影响的方法学，包括个性化和定制化模型、健壮的聚合技术以及客户端选择技术。通过综合现有研究并提出新的策略，本文旨在为有效管理FL中的数据异质性提供见解，增强模型的鲁棒性，并确保在多样化的环境下实现公平且高效的训练。此外，本文还明确了未来研究方向，强调了为在工业4.0背景下进一步改进FL范式，需要研发适应性强和可扩展的解决方案。|
|**2024-08-18**|**Seamless Integration: Sampling Strategies in Federated Learning Systems**|Tatjana Legler et.al.|[2408.09545](http://arxiv.org/abs/2408.09545)|null|联邦学习（Federated Learning, FL）作为一种机器学习的范式转变，提供了一种在保持本地数据隐私的同时，跨多设备进行模型分布式训练的方法。然而，FL系统的特点在于其动态性质，即持续纳入具有可能不同数据分布和计算能力的新客户端，这对这些分布式学习网络的稳定性和效率构成了重大挑战。无缝融入新客户端对于维持并提升FL系统的性能及鲁棒性至关重要。本文深入探讨了将新客户端整合进现有FL系统所面临的复杂性，以及数据异质性和它们之间不同的数据分布（非独立同分布）如何影响模型训练、系统效率、可扩展性和稳定性。尽管存在这些挑战，新客户端的整合为FL系统带来了增加数据多样性、提升学习性能及利用分布式计算能力的机遇。与诸如Gboard上的单词预测分布式优化等应用领域不同，生产环境中的客户端通常数量较少，因此每个新客户端提供的信息就显得尤为宝贵。本文概述了有效的客户端选择策略及确保系统可扩展性和稳定性的解决方案，并以光学质量检验中的图像为例，提供了实践方法的见解。总之，本文提出，应对新客户端整合带来的挑战对于推动分布式学习网络的进步和效率至关重要，从而为FL在生产环境中的采纳铺平道路。|
|**2024-08-18**|**Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets**|Shiyuan Zuo et.al.|[2408.09539](http://arxiv.org/abs/2408.09539)|null|在实际的联邦学习（FL）系统中，恶意拜占庭攻击和数据异构性的存在常常给学习过程引入偏见。然而，现有的拜占庭鲁棒方法通常只在适应不同损失函数类型（包括强凸和非凸）与对抗数据异构性之间取得折衷，但存在非零最优性差距。此外，这种折衷往往以聚合时高计算复杂性为代价，极大地减慢了训练速度。针对这一挑战，我们提出了一种名为联邦规范化梯度算法（Fed-NGA）的联邦学习方法。Fed-NGA简单地将上传的局部梯度归一化为单位向量后再进行聚合，实现了时间复杂度 $\mathcal{O}(pM)$，其中$p$表示模型参数的维度，$M$是参与客户端的数量。这一复杂度级别在所有现有的拜占庭鲁棒方法中达到最优。此外，通过严格的证明，我们展示Fed-NGA超越了现有文献中关于适应损失函数类型与数据异构性之间的折衷以及非零最优性差距的限制。具体而言，Fed-NGA能同时适应非凸损失函数和非独立同分布（non-IID）数据集，并以$\mathcal{O} (1/T^{\frac{1}{2} - \delta})$的速率实现零最优性差距，其中$T$是迭代次数，$\delta \in (0,\frac{1}{2})$ 。当损失函数为强凸时，实现零最优性差距的速率可提升至线性。实验结果进一步证实了我们提出的Fed-NGA在时间复杂度和收敛性能上相对于基线方法的优越性。|
|**2024-08-18**|**Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover**|Dong-Jun Han et.al.|[2408.09522](http://arxiv.org/abs/2408.09522)|null|偏远地区的设备通常缺乏来自完善地面通信基础设施的覆盖，这不仅限制了它们享受高质量通信服务的能力，还阻碍了在偏远地区部署机器学习服务。针对这一问题，本文提出了一种面向空天地一体化网络（SAGIN）的新型联邦学习（FL）方法。我们的方法巧妙利用空间与空中层的节点作为（i）边缘计算单元和（ii）联邦学习过程中的模型聚合器，从而应对地面设备计算能力有限以及目标区域缺少地面基站的挑战。本方法的核心思想是采用适应性数据卸载和切换流程，该流程融入了SAGIN中的多种网络动态特性，包括移动性、异构计算能力以及过顶卫星不稳定的覆盖时间。我们分析了方案的延迟，并开发了一个自适应数据卸载优化器，同时对所提算法的理论收敛界限进行了刻画。实验结果验证了我们的SAGIN辅助联邦学习方法在训练时间和测试精度方面相对于多种基线的优势。|
|**2024-08-18**|**Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training**|Huitong Jin et.al.|[2408.09478](http://arxiv.org/abs/2408.09478)|null|预训练利用公开数据集对先进机器学习模型进行预先训练，以便该模型能更容易地调整以适应各种下游任务。预训练已被广泛探索，以缓解计算和通信资源的消耗。受这些优势启发，我们首次探讨了模型预训练如何减轻差分隐私联邦学习（DPFL）中的噪声损害。DPFL是从联邦学习（FL）升级而来，FL是在多个拥有私有数据的客户端之间训练模型时保护隐私的实际标准。DPFL通过引入差分隐私（DP）噪声来混淆FL中暴露的模型梯度，但这可能会显著损害模型准确性。在我们的工作中，通过全面的实证研究，比较了基于预训练的头部微调（HT）和全模型微调（FT）在DPFL中与从零开始训练（ST）的表现。实验使用在ImageNet-1K上预训练获得的模型，进一步利用CIFAR-10、CHMNIST和Fashion-MNIST（FMNIST）数据集进行微调。结果表明，HT和FT能通过减少梯度暴露次数，显著减轻噪声影响。特别是当隐私预算紧张或模型尺寸较大时，HT表现优于FT。可视化和解释性研究进一步证实了我们的发现。我们的开创性研究为增强DPFL并扩展其实际应用提供了新视角。|
|**2024-08-18**|**Federated Graph Learning with Structure Proxy Alignment**|Xingbo Fu et.al.|[2408.09393](http://arxiv.org/abs/2408.09393)|null|联邦图学习（FGL）旨在对分布于多个数据持有者中的图数据学习图学习模型，已被应用于社交推荐和金融欺诈检测等多种场景。FGL继承了通用联邦学习（FL）的特性，同样面临数据异质性问题，即分布式图数据在不同客户端上的标签分布可能有显著差异。例如，某个客户端的节点可能大多属于某一类别，而另一个客户端中来自相同类别的节点却很少。这一问题导致了分歧的局部目标函数，并妨碍了FGL在节点级任务上，尤其是节点分类任务的收敛性。此外，FGL还面临着一个独特的挑战：在客户端中属于少数类别的节点更可能具有偏差性的邻域信息，这阻碍了FGL利用图神经网络（GNNs）学习到表达性强的节点嵌入。为应对这一挑战，我们提出了FedSpray，一种新颖的FGL框架，它在潜在空间中学习局部类别结构代理，并将其对齐以获得全局结构代理。我们的目标是获取对齐的结构代理，用作节点分类中可靠、无偏倚的邻域信息。为了实现这一目标，FedSpray训练了一个全局特征-结构编码器，并生成了利用结构代理的无偏软目标，以个性化的方式规范各客户端GNN模型的本地训练。我们在四个数据集上进行了广泛实验，实验结果验证了FedSpray相比其他基线方法的优越性。代码可于https://github.com/xbfu/FedSpray获取。|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227](http://arxiv.org/abs/2408.09227)|null|本研究提出了一项名为“联邦医学知识注入”（FEDMEKI）的平台新基准，旨在应对在隐私限制下将医学知识整合到基础模型的独特挑战。通过利用跨机构的联邦学习方法，FEDMEKI绕过了集中式数据收集的问题，这类收集方式常因健康法规（如美国的《健康保险流通与责任法案》即HIPAA）而受到禁止。该平台精心设计以处理多站点、多模态和多任务的医学数据，涵盖了7种医学模态，包括图像、信号、文本、实验室检测结果、生命体征、输入变量和输出变量。用于验证FEDMEKI的精选数据集涵盖了8项医学任务，包括6个分类任务（肺部不透明度检测、COVID-19检测、心电图（ECG）异常检测、死亡预测、败血症预测和心包纵隔增大的检测）和2个生成任务（医学视觉问答（MedVQA）和ECG噪声澄清）。这一综合数据集被划分至多个客户端，以便在16种基准方法下促进分散式训练过程。FEDMEKI不仅保护了数据隐私，还通过允许基础模型从更广泛的医学知识中学习而不直接暴露数据，增强了其在医疗领域的功能，从而在医疗领域应用基础模型方面设定了新的基准。|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|针对移动键盘应用中设备端语言模型训练的最新技术，结合了联邦学习（FL）与差分隐私（DP），通过使用DP-Follow-the-Regularized-Leader（DP-FTRL）算法。实践中采用的DP-FTRL有两种变体，即树聚合和矩阵分解。然而，树聚合在隐私与效用的权衡上表现不佳，而矩阵机制需要通过难以预先准确估计的常数进行昂贵的优化，并且运行时内存成本高。本文将最近引入的缓冲线性Toeplitz（BLT）机制扩展至多参与场景。我们的BLT-DP-FTRL保持了树聚合的易用性优势，同时几乎在实用性和隐私保护方面达到了矩阵分解的水平。我们在StackOverflow数据集上进行了评估，作为可复现的模拟基准，并在生产FL系统的四个设备端语言模型任务中进行了测试。实证结果突显了BLT机制的优势，提升了DP在现实世界场景中的实用性和有效性。|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|工业物联网（IIoT）对数据隐私和网络安全威胁高度敏感。联邦学习（FL）作为解决方案应运而生，旨在保护隐私，使得本地IIoT客户端的数据得以保留在本地，同时协同训练模型以检测网络异常。然而，无论是同步还是异步的FL架构，在处理因数据异质性和资源限制导致的客户端速度不均问题时，都存在局限性。同步架构会受到拖尾效应的影响，而异步方法则遇到通信瓶颈的问题。此外，FL模型还容易受到旨在披露私人训练数据的对抗性推理攻击。为了解决这些挑战，我们提出了一种针对异构IIoT环境中的异常检测、融合了同态加密的缓冲联邦学习（BFL）框架。BFL采用了一种新颖的加权平均时间方法，以缓解拖尾效应和通信瓶颈，通过与基于缓冲区的服务器协作，确保了处理速度各异的客户端之间的公平性。基于两组数据集的性能结果显示，BFL相比于先进的FL方法具有优越性，展现出在提高准确性和收敛速度的同时，增强了隐私保护的能力。|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|联邦学习（FL）是一种有前景的隐私保护分布式学习框架，能够在移动电话、桌面电脑及配备CPU或GPU的设备等各种装置上部署。在基于服务器的联邦学习即服务（FLaaS）场景下，FL使中央服务器能够协调多个设备上的训练过程，无需直接访问本地数据，从而增强隐私和数据安全性。低秩自适应（LoRA）是一种高效微调模型的方法，通过专注于模型参数的低维子空间来实现。与从头开始微调所有参数相比，这种方法显著降低了计算和内存成本。当LoRA与FL结合，尤其是在FLaaS环境中，通过调整局部模型的秩，允许在具有不同计算能力的多样化硬件上灵活且高效地部署。然而，在启用LoRA的FL中，不同的客户端可能会使用不同秩来训练模型，这对服务器端的模型聚合提出了挑战。当前聚合不同秩模型的方法需要对权重进行填充以达到统一形状，这可能损害全局模型的性能。为解决这一问题，我们提出了基于秩的LoRA聚合（RBLA），这是一种针对异构LoRA结构设计的新颖模型聚合方法，旨在保留不同秩模型的关键特征。本文首先分析了当前填充方法在FLaaS环境中重塑模型以进行聚合存在的问题，随后引入了RBLA，该方法能在保持低秩与高秩特征的同时进行聚合。最后，我们通过与前沿方法的对比实验，验证了RBLA的有效性。|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|联邦学习通过消除数据共享的需要，为AI应用带来了革命性的变化。然而，研究表明，在训练过程中仍可提取信息，因此需要额外的隐私保护措施，如差分隐私。为了实现现实世界的联邦学习应用，从性能的公平分配到非歧视性行为，公平性都是必须考虑的因素。特别是在高风险应用领域（如医疗健康），避免重复过去歧视性错误至关重要。近期研究表明，隐私与公平之间存在固有的紧张关系，为此，我们进行了多声部文献回顾，以考察当前在联邦学习中整合隐私与公平的方法。我们的分析揭示了隐私与公平之间的关系被忽视的问题，这对现实世界的应用构成了重大风险。我们强调了探索隐私、公平与性能之间关系的必要性，并倡导创建综合性的联邦学习框架。|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|联邦学习能够在遵守隐私要求的前提下，让多个客户端在服务器的总体规划下协同训练机器学习模型。然而，服务器无法直接监督局部训练过程，这为恶意客户端植入后门提供了可乘之机。现有研究表明，后门攻击会在受感染的模型中激活特定神经元，而这些神经元在处理干净数据时保持休眠状态。基于这一观察，我们提出了一种名为“低激活输入神经元权重更新反转”（FLAIN）的方法来防御联邦学习中的后门攻击。具体而言，在完成全局训练后，我们利用一个辅助数据集来识别低激活输入神经元，并反转与之相关的权重更新。我们逐步提高低激活输入的阈值，并迭代地进行权重更新的反转，直至在辅助数据上的性能下降变得不可接受为止。广泛实验验证了我们的方法能有效降低各种攻击场景下的后门攻击成功率，包括非独立同分布数据或高错分类率（MCR）的情况，同时对干净数据的性能影响保持在最低水平。|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|为保护数据隐私，联邦学习（FL）范式应运而生，其中客户端仅公开模型梯度而非原始数据进行模型训练。为了进一步增强联邦学习中模型梯度的保护，提出了差分隐私联邦学习（DPFL），该方法通过引入差分隐私（DP）噪声来混淆梯度，然后再将其暴露。然而，DPFL中一个基本但常被忽视的问题是客户端隐私需求的异质性，这种需求在不同客户端间可能有显著差异，极大地复杂化了DPFL中的客户端选择问题。换句话说，在选择客户端时，既要考虑数据质量，也要考虑DP噪声的影响。为解决这一问题，我们针对具有异构隐私设置的DPFL进行了收敛性分析，考虑了一般的客户端选择策略、流行的DP机制及凸损失函数。基于收敛性分析，我们将目标设定为最小化DPFL中带有异构隐私设置下损失函数的值，这是一个凸优化问题，可以高效求解。因此，我们提出了DPFL-BCS（有偏客户端选择）算法。广泛的实验结果，包括使用真实数据集及在凸与非凸损失函数下的测试，表明DPFL-BCS能显著提升模型效用，相比当前最优的基线方法有明显优势。|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|随着联网和自动驾驶车辆的普及，控制器区域网络（CAN）总线已成为车内网络通信的主要标准，这得益于其速度和效率。然而，CAN总线缺乏基本的安全措施，如认证和加密，使其极易受到网络攻击。为了确保车内安全，入侵检测系统（IDS）必须能检测已知攻击，并对新的、未见过的攻击提供强大的防御能力，同时保持轻量级以便实际部署。以往的研究要么仅依赖CAN标识符特征，要么使用了传统的机器学习（ML）方法结合手动特征提取。这些方法忽视了其他可被利用的特征，使得系统难以适应新出现的攻击变种，从而影响安全性。本文提出了一种创新的、轻量级的、车载IDS解决方案，该方案利用深度学习（DL）算法来解决这些局限性。所提议的IDS采用多阶段方法：第一阶段使用人工神经网络（ANN）来检测已知攻击，第二阶段则采用长短期记忆（LSTM）自编码器来检测新的、未见过的攻击。  为理解并分析多样的驾驶行为，实时更新模型以涵盖最新的攻击模式，并保护数据隐私，我们提出了一种理论框架，用于在层次化联邦学习（H-FL）环境中部署我们的IDS。实验结果显示，我们的IDS在已知攻击上的F1分数超过0.99，在新型攻击上的F1分数超过0.95，检测率达到99.99%。此外，误报率（FAR）极低，仅为0.016%，有效减少了误报。尽管采用了在识别复杂及零日攻击方面表现出色的深度学习算法，但该IDS仍保持轻量化，确保了其在现实世界中的可部署性。|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|联邦学习（FL）理论上在保护个体客户端数据隐私的同时能够生成高质量的机器学习模型。然而，诸如深度梯度泄露（DLG）等攻击严重质疑了FL的实际应用性。本文通过实证评估了四种防御方法针对DLG的有效性：掩码（Masking）、裁剪（Clipping）、修剪（Pruning）和噪声注入（Noising）。掩码技术，虽然之前仅作为参数传输过程中压缩信息的方法进行研究，但出人意料地展现出相比于其他三种成熟方法更为强大的防御效用。我们的实验分为两部分。首先，我们跨MNIST、CIFAR-10和lfw数据集评估每种方法的最低超参数阈值。接着，我们利用各方法及其最低阈值训练FL客户端，以研究对抗DLG防御与训练性能之间的权衡。结果显示，掩码和裁剪在几乎不影响性能的同时，能有效混淆足够信息以防御DLG攻击。|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|**联邦学习（FL）是一种增强隐私的技术，用于分布式机器学习。通过本地训练模型并聚合更新，联邦能够在不进行集中数据收集的情况下共同学习。FL在医疗、金融和个人计算领域日益受到欢迎。然而，它继承了经典机器学习中的公平性挑战，并由于数据质量差异、客户端参与度、通信限制、聚合方法及底层硬件差异引入了新的挑战。公平性仍然是FL中一个未解决的问题，社区已识别出缺乏简明定义和指标来量化公平性的现状；为应对这一问题，我们提出了联邦公平性分析方法论——一种衡量公平性的方法。我们的公平性定义包括四个概念，并配有新颖的对应指标。这些定义是针对问题症状提出的，并利用了源自可解释AI、合作博弈论和网络工程的技术。  我们在多种实验设置下进行了测试，改变了FL方法、机器学习任务和数据设置。结果表明，统计异质性和客户端参与度会影响公平性，而诸如Ditto和q-FedAvg等注重公平性的方法仅在一定程度上改善了公平性与性能之间的权衡。借助我们的技术，FL从业者能够揭示其系统公平性的前所未有的深入见解，包括不同粒度级别的见解，从而应对FL中的公平性挑战。我们的工作已在https://github.com/oscardilley/federated-fairness开源。**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|分布式太阳能发电系统的快速增长给配电系统规划和调度带来了挑战，主要原因是这类系统背后的太阳能发电难以观测。为了解决集中式机器学习方法在估算用户侧（BTM）太阳能发电量时的数据泄露问题，联邦学习（FL）方法因具备分布式学习能力而受到研究者的关注。然而，传统的联邦学习方法面临着异构性、通信故障以及恶意隐私攻击等多种挑战。针对这些挑战，本研究提出了一种针对异构社区级BTM太阳能发电量的通信鲁棒性和隐私安全性的分布式估计算法。具体而言，本研究采用多任务联邦学习作为主体框架，旨在学习所有社区间的共同特征与独特特性。同时，研究中嵌入了一种更新参数估计算法到多任务联邦学习中，能够自动识别任意两个客户端之间的相似性，并为无法通信的客户端估计更新参数，从而缓解通信故障带来的负面影响。最后，本研究在动态隐私预算分配策略下采用了差分隐私机制，以抵御恶意隐私攻击并提升模型训练效率。案例研究表明，在存在异构性和通信故障的情况下，所提出的算法相比于传统联邦学习和局部化学习方法，展现出更优的估测精度和收敛性能，同时提供了更强的隐私保护。|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240820>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

