[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.19
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中丢弃的多模态数据。我们提出了一种解决方案，该方案利用注意力机制框架，从用户行为、视线聚焦和XR环境中的情境记忆中隐式提取上下文。这最大限度地减少了对人工设计的明确提示的需求，促进了根植于现实且直观的交互，为聊天机器人提供用户洞察。我们的用户研究表明，我们的方法即将实现无缝化XR中与聊天机器人的交互，并为未来XR实体化LLM代理的设计提供了见解，展现出其变革性的潜力。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的建筑信息模型（BIM）创建过程中，设计者往往需掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使得设计过程复杂化，并阻碍了建筑、工程与施工（AEC）行业中BIM及基于模型设计的普及。为更直观地表达设计意图，我们提出了Text2BIM框架，这是一个基于大型语言模型（LLM）的多智能体系统，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作和推理，将用户的文本输入转化为调用BIM创作工具API的指令性代码，直接在软件中生成包含内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，框架引入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体识别并解决生成模型中的问题，通过迭代优化提升模型质量。我们进行了广泛实验，比较和分析了在所提框架下三种不同LLM的表现。评估结果显示，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入的抽象概念保持一致。最后，我们开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，展示了通过聊天进行建模的潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|大型语言模型（LLMs）在需要复杂推理的自然语言任务中展现了非凡的能力，但它们在交互式环境中的自主、多步推理应用仍是一个严峻挑战。传统的静态数据监督预训练无法充分赋能代理在动态场景（如网页导航）中进行复杂决策所需的自主能力。以往通过在专家演示的监督微调来弥合这一差距的尝试，常因累积错误和有限的探索数据而受限，导致次优策略结果。为克服这些挑战，我们提出了一种框架，该框架结合了引导式蒙特卡洛树搜索（MCTS）与自我批判机制，并利用离策略直接偏好优化（DPO）算法变体对代理交互进行迭代微调。我们的方法使LLM代理能从成功和不成功的轨迹中有效学习，从而提升其在复杂多步推理任务中的泛化能力。我们在WebShop环境——一个模拟的电子商务平台中验证了我们的方法，其间它持续超越了行为克隆和强化微调基线，并在具备在线搜索能力时超越人类平均表现。在实际预订场景中，我们的方法使Llama-3 70B模型的零样本性能从18.6%提升至81.7%（相对增长340%）仅经过一天的数据收集，进一步利用在线搜索可提升至95.4%。我们相信，这标志着自主代理能力的重大飞跃，为现实世界设置中更复杂、可靠的决策制定铺平了道路。|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|大型语言模型（LLM）代理在解决实际的软件工程（SWE）问题上显示出了巨大潜力。最先进的开源SWE代理能在SWE-Bench Lite上解决超过27%的真实GitHub问题。然而，这些复杂的代理框架展现出不同的优势，在某些任务上表现出色，而在其他任务上则表现不佳。为了充分利用这些代理的独特专长，我们提出了DEI（多样性赋能智能）框架，它能利用它们的专业知识。DEI作为一个元模块位于现有SWE代理框架之上，管理代理集体以增强问题解决能力。实验结果表明，由DEI引导的代理委员会能够大幅超越最佳单个代理的表现。例如，一组开源SWE代理在SWE-Bench Lite上的最高个体解决率为27.3%，而通过DEI可以达到34.3%的解决率，实现了25%的提升，并且超过了大多数闭源解决方案。我们表现最佳的小组以55%的解决率脱颖而出，在SWE-Bench Lite上占据了首位。我们的发现为协作AI系统研究领域做出了贡献，强调了其解决复杂软件工程挑战的潜力。|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|大型语言模型（LLMs）在多种语言任务中展示了非凡的能力，使它们成为机器人决策领域的有潜力候选者。受分层强化学习（HRL）启发，我们提出了一种新颖框架——Hierarchical in-Context Reinforcement Learning（HCRL），该框架利用基于LLM的高层策略对复杂任务进行分解，即动态地将复杂任务分解为由低层策略完成的子任务。一旦LLM代理判断目标达成，便会提出新的目标。为了提升代理在多回合执行中的性能，我们提出了Hindsight Modular Reflection（HMR）方法，其中，不同于反思完整轨迹，我们用中间目标替换任务目标，并让代理对较短的轨迹进行反思，以提高反思效率。我们在三个基准环境——ALFWorld、Webshop和HotpotQA中评估了HCRL的决策能力。结果表明，在5个执行回合中，HCRL相比强大的基于上下文学习的基线，性能提升了9%、42%和10%。|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|大型语言模型（LLMs）由于其出色的泛化能力和涌现特性，使得自主代理更接近于人工通用智能（AGI）。然而，在这些基于LLM的代理在实际世界中的规划任务中的行为、潜在失败原因及改进方法方面的研究还较为匮乏，尤其是面对高要求的真实规划任务。为填补这一空白，我们通过一个现实的基准测试——TravelPlanner，来展开我们的研究。在此基准中，代理必须满足多重约束以生成准确的计划。我们利用此基准来探讨四个关键研究问题：(1) LLM代理在涉及长篇幅和嘈杂背景信息的推理与规划任务中是否足够稳健？(2) 少样本提示在长上下文场景中是否会负面影响LLM代理的表现？(3) 我们能否依靠细化策略来改进计划质量，以及(4) 通过结合正面和负面反馈对LLM进行微调能否带来进一步的性能提升？  我们的综合实验显示，首先，尽管LLMs能够处理大量参考信息和少样本示例，但在处理长上下文时，它们往往未能关注到关键部分；其次，它们在分析长篇计划时仍面临挑战，无法为计划的细化提供精确的反馈；第三，我们提出了一种反馈感知微调方法（FAFT），该方法利用正负反馈相结合，相比仅监督微调（SFT）实现了显著的性能提升。我们的发现为社区提供了关于真实世界规划应用多个方面的深入见解。|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|数据驱动的故事讲述是一种强大的表达方式，它通过结合叙述技巧与可视化和文本，传达深刻见解。这类故事融合了视觉辅助元素，如图表中突出显示的柱状图和线图，以及解释这些见解的文本注释。然而，创作此类故事需要对数据有深入的理解及精心的叙事规划，往往需要人工介入，这既耗时又耗费心力。尽管大型语言模型（LLMs）在多种自然语言处理任务上表现出色，但在生成连贯且全面的数据故事方面的能力尚未得到充分探索。本研究中，我们引入了一项新颖的数据故事生成任务及一个包含1,449个来自不同来源的故事的基准数据集。为了应对构建连贯数据故事的挑战，我们提出了一种多智能体框架，该框架采用两个LLM智能体，旨在模仿人类讲故事的过程：一个负责理解并描述数据（反思），生成大纲及叙述，另一个则负责在每个中间步骤进行验证。尽管我们的智能体框架在基于模型和人工评估中普遍优于非智能体对照组，但结果也揭示了数据故事生成领域特有的挑战。|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|null|本文探讨了城市导航中的一个场景：AI代理接收到关于目标位置相对于知名地标语言描述的信息；仅依据对周围环境的观察，包括识别地标和道路网络连接，代理必须做出决策以导航至目标位置，期间并无具体指引。这一问题极具挑战性，因为它要求代理建立自我位置认知并掌握复杂城市环境的空间表示，其中地标往往不可见。在缺乏导航指示的情况下，这些能力对于代理在远距离城市导航中做出高质量决策至关重要。随着大型语言模型（LLMs）推理能力的兴起，一个诱人的基线方法是促使LLMs根据每次观察“做出反应”并相应地做出决策。然而，该基线性能较差，代理常重复访问同一位置，并做出短视、不连贯的决策。为解决这些问题，本文引入了一种新颖的代理工作流程，其特点是具备感知、反思与规划的能力。具体而言，我们发现LLaVA-7B模型可通过微调以足够精度感知地标的方向和距离，这对于城市导航而言是必要的。此外，通过记忆机制实现反思，过往经验得以存储并能与当前感知结合，以便进行有效的决策论证。规划环节利用反思结果来制定长期计划，从而避免在远距离导航中做出短视决策。研究显示，设计的这一工作流程显著提升了基于LLM的代理的导航能力，相比现有最先进基线有明显优势。|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|**大型语言模型（LLMs）在独立代码任务如HumanEval和MBPP中表现出色，但在处理整个代码仓库时面临挑战。这一难题激发了对增强LLM与代码库交互能力的研究，特别是在仓库规模上。当前的解决方案依赖于基于相似性的检索或手动工具及API，各有显著缺点。基于相似性的检索在复杂任务中往往召回率低，而手动工具和API通常是任务特定的，需要专业知识，这降低了它们在不同代码任务和真实世界应用中的泛用性。为了缓解这些限制，我们引入了CodexGraph系统，它将LLM代理与从代码仓库中提取的图数据库接口集成。通过利用图数据库的结构特性及图查询语言的灵活性，CodexGraph使LLM代理能够构建并执行查询，从而实现精确、针对代码结构感知的上下文检索和代码导航。我们使用CrossCodeEval、SWE-bench和EvoCodeBench三个基准进行评估。此外，我们还开发了五个实际的编程应用场景。凭借统一的图数据库模式，CodexGraph在学术和现实环境的双领域中展示了竞争力和潜力，彰显其在软件工程中的多样性和有效性。我们的应用演示可访问：https://github.com/modelscope/modelscope-agent/tree/master/apps/codexgraph_agent。**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|传统的基站选址（BSS）方法严重依赖于路测和用户反馈，这些方法既费时又需要在通信、网络和优化领域具有丰富的专业知识。随着大型语言模型（LLMs）及其相关技术的进步，特别是在提示工程和智能体工程方面，网络优化将迎来革新性的方法。这种方法通过精心设计的提示策略，将人类的经验和知识融入这些复杂的LLMs中，并部署自主智能体作为沟通桥梁，以自然语言无缝连接基于机器语言的LLMs与人类用户。这种整合预示着人工智能即服务的未来模式，以及利用AI实现更高效率的应用场景。作为初步探索，本研究首先开发了一个新颖的、基于LLM的BSS优化框架，并试探性地提出了四种不同的潜在实施方案：基于优化提示的LLM策略（PoL）、人机交互LLM策略（HiLL）、LLM赋能的自主BSS智能体（LaBa），以及协作式多LLM基自主BSS智能体（CLaBa）。通过对真实世界数据的评估，实验表明，辅助提示的LLMs和基于LLM的智能体能够生成更高效、成本效益更高且更可靠的网络部署，显著提高了BSS优化的效率并减少了人工参与的繁琐工作。|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）上展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，近期LLM推理的进展显示，在提示中使用多样化的示例能够促使LLM输出的多样性。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本论文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），一种混合自我集成方法，它结合了多样化示例基于提示的优势和LLM基于的聚合，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下达到更高的准确率。|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|实现人类水平的智能需要细化系统1与系统2思维之间的认知差异。尽管当前的人工智能，特别是在大型语言模型的驱动下，展示出类似人类的特征，但它仍未达到真正意义上的认知水平。从结构化的基准测试过渡到现实世界的场景为视觉代理提出了挑战，往往导致不准确且过度自信的反应。为了解决这一挑战，我们引入了FaST，它将快速与慢速思考机制融入视觉代理中。FaST利用开关适配器动态选择系统1/2模式，根据任务复杂度调整问题解决方法。它通过调整模型置信度并整合新的上下文数据来应对不确定和未见过的对象。凭借这一新颖设计，我们提倡建立一个灵活的系统、具有层次推理能力及透明决策流程，所有这些都有助于其在视觉智能中模拟人类认知过程的能力。实证结果表明，FaST超越多种知名基线，在视觉问题回答任务VQA^{v2}上达到80.8%的准确率，在ReasonSeg推理分割任务上达到48.7%的GIoU得分，彰显了FaST的卓越性能。广泛的测试验证了FaST核心组件的有效性和鲁棒性，展示了其在推进AI系统中认知视觉代理发展的潜力。|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|多模态大型语言模型（Multimodal Large Language Models, MLLMs）在医疗辅助领域的成功展现出巨大潜力，使患者能够利用生理信号数据进行对话。然而，通用MLLMs在心脏病诊断方面表现欠佳，特别是在心电图（ECG）数据分析与长文本医学报告生成的融合上，主要由于ECG数据分析的复杂性及文本与ECG信号模态间存在差距。此外，模型在长文本生成中常表现出严重的稳定性不足，原因在于缺乏与用户查询紧密相关的精确知识。针对这些问题，我们提出了ECG-Chat，首个专注于ECG医学报告生成的多任务MLLMs，提供了基于心脏病学知识的多模态对话能力。我们设计了一种对比学习方法，该方法将ECG波形数据与文本报告整合，以细粒度方式对齐ECG特征与报告。此方法还促成了一种在零样本报告检索任务中表现出色的ECG编码器。此外，通过扩展现有数据集，我们构建了1.9万个ECG诊断数据集和2.5万个多轮对话数据集，用于训练和微调ECG-Chat，使其具备专业的诊断和对话能力。ECG-Chat还能通过自动化LaTeX生成管道生成全面的ECG分析报告。我们为ECG报告生成任务建立了基准，并在多个基线上测试了我们的模型。ECG-Chat在分类、检索、多模态对话及医学报告生成任务中均取得了最佳性能。我们设计的报告模板也得到了医学从业者的广泛认可。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发和评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语及英语环境中处理心理学任务的能力。PsychoLex的核心贡献包括PsychoLexQA数据集，用于教学内容的指导，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们还展示了PsychoLexLLaMA模型，该模型针对心理学应用进行了优化，并展现出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，利用大型语言模型（LLMs）是进行表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，鉴于每个实例需要不同的能力和模型拥有不同的能力，不同的实例和模型适合不同的表格格式。我们通过对实验结果的定量分析证明了上述观点，其中不同实例和模型在使用各种表格格式时表现出不同的性能。基于这一讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote来通过采用灵活的表格格式增强表格推理性能。具体来说，(i) FLEXTAF-Single训练一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote整合不同格式的结果。在WikiTableQuestions和TabFact上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提升分别为2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征和汇总的影响。我们的分析指出，AI有潜力提升战略分析的速度、质量和规模，并促进诸如虚拟战略模拟等新方法的发展。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接AI在SDM中的应用与企业成果，并讨论AI如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的格局，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的关注以及在法律、医学和多语言环境等领域的多样性缺乏。在本文中，我们通过引入一个新颖的数据管道来应对这些局限，该管道专门针对LLM作为评价者框架定制了多样化、领域特定的评估集。我们的方法结合了人工筛选、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。所得的评估集包含14个类别下的1573个样本，展现了在十大顶级模型间高达84\%的高可分离性，并与Chatbot Arena的评价达成84\%的一致性，及0.915的斯皮尔曼相关系数。这一致性值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比下一个最佳基准高出0.7，彰显了基准实用性方面的显著提升。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别上的性能进行细粒度分析，为实践者提供了宝贵的见解。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰和建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究侧重于开发模块化对话系统，将社会情感策略预测作为辅助任务，并利用定制的解码器生成策略条件化的回应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。为了解决这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，它利用异构图来建模用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块来捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX以显著优势超越了先前的最先进方法。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务中，涉及三个不同的LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式远比在特定描述上投入精力更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行纠错，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修正错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL纠错。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，以此作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中通过采用多种推理路径，已展现出显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于生成相对较多的输出令牌，其推断成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以借助LLMs可靠地聚合，以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够促使LLMs输出更加多样化。这些已验证的技术可轻松扩展到自我集成方法中，以在文本生成中实现更优结果。在本文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），这是一种混合自我集成方法，结合了多样示例基于提示的优势与LLM基于的聚合优势，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推断成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发和评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在心理学任务上的专业能力，涵盖了波斯语和英语两种语言环境。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强学习，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学场景中的表现。此外，我们推出了PsychoLexLLaMA模型，该模型经过专门优化以适应心理学应用，展示出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与实践方面的发展潜力，同时也指出了未来精进的方向。此研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，大型语言模型（LLMs）是解决表格推理问题的主要方法。大多数现有方法使用固定的表格格式来表示表格，这可能限制了性能表现。我们提出，鉴于每个实例需要不同的能力和模型具有不同的优势，不同的实例和模型适合不同的表格格式。通过定量分析实验结果，我们证实了这一观点，即在使用不同表格格式时，不同的实例和模型会取得不同的性能表现。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM来预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式下的推理结果。在WikiTableQuestions和TabFact数据集上的实验表明，与使用固定表格格式及贪婪解码、自我一致性解码达到的最佳性能相比，我们的方法平均提高了2.3%和4.8%，从而验证了方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时促进如虚拟战略模拟等新方法的发展。然而，其对firm绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的格局，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏考虑。在本文中，我们通过引入一个新颖的数据管道来解决这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含14个类别下的1573个样本，展现了在十大顶级模型间的高可分离性（84%），并与Chatbot Arena的符合度达到84%，斯皮尔曼相关系数为0.915。这些符合度值比Arena Hard高出9%，比AlpacaEval 2.0 LC高出20%，而斯皮尔曼系数比下一个最佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别上的性能进行细粒度分析，为实践者提供了宝贵的洞察。本工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究侧重于开发模块化对话系统，将社会情感策略预测作为辅助任务，并利用定制的解码器生成策略条件化的回应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。为了解决这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，它利用异构图来建模用户情感与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块来捕捉用户的精细化情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX以显著优势超越了先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（郑等人，2024年）。鉴于强化学习从人类反馈（RLHF）的广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量判断时（例如文本的连贯性），预期会与人类偏好有强烈的对齐。尽管这看似有益，但尚不清楚LLM作为裁判的评估仅仅是基于提示中的指令进行评价，还是反映了其对类似于其微调数据的高质量数据的偏好。为了探究在LLMs作为裁判时，通过提示进行指导对其评判与人类评判的一致性有多大影响，我们分析了针对几个LLMs裁判的不同级别指令详细度的提示，这些提示关乎评价目标的质量。此外，我们还对比了一种无提示方法，即使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类，这些标准广泛应用于采用LLMs的前沿评估中，并提供了作为裁判模型的严格基准。总的来说，我们的研究表明LLMs作为裁判从高度详细的指示性提示中获益甚微，且在某些情况下，特别是对于文本质量的评估，困惑度与人类评判的一致性甚至可能优于提示方法。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于包括常识、数学、逻辑推理和幻觉任务在内的广泛任务中，并采用了三个LLMs进行实验，结果颇为乐观，再次表明设计恰当的提示格式远比在特定描述上投入精力更为有效和高效。一旦论文发表，我们的代码将会公开可用。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行修正，而先前的研究表明，LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL修正。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，作为纠错的反馈。实验结果表明，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不一致的内容，这种现象经验性地被称为“幻觉”。为解决这一问题，近期研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码方法，已展现出可喜成果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在特定情况下可能导致错误。本文引入了一种新颖的对比解码框架，名为LOL（较低层重要）。我们的方法是连接原始模型与业余模型在最终层与更低层的对比解码结果，从而实现多层融合，以助于缓解幻觉现象。此外，我们融入了一个注重真实性的反馈模块，利用上下文引导增强事实编码，进一步在对比解码过程中捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉现象，并在大多数情况下超越现有基线。相比于最佳基线，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中通过采用多种推理路径展现了显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于需要生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可轻松扩展到基于自我集成的方法中，以在文本生成中实现更优结果。在本论文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），这是一种混合自我集成方法，它结合了多样化示例基于提示的优势与LLM基于聚合的能力，以实现整体性能的提升。在公开可用的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是解决表格推理问题的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，鉴于每个实例需要不同的能力和模型具有不同的能力，不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明这一观点，结果显示在使用不同表格格式时，不同的实例和模型表现出不同的性能。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|环境回波通信（Ambient backscatter communications，简称AmBC）是一种有前景的技术，旨在通过反射或吸收周围无线电频率（RF）信号来解决无线通信中的能耗问题。然而，该技术需应对环境RF信号的复杂性及往返路径损耗带来的挑战。传统检测器在采用导频序列时，会降低频谱效率。此外，传统的基于能量的检测器固有地存在显著的错误地板问题，这是由同信道直接链路干扰（DLI）造成的。因此，本文提出了一种盲符号检测器，无需事先知晓信道状态信息、信号方差和噪声方差。通过利用符号内差分幅移键控（Intra-Symbol Differential Amplitude Shift Keying，IDASK）方案，该检测器能有效引导大部分DLI能量至接收样本协方差矩阵的最大特征值，同时利用次大特征值进行有效的符号检测。此外，本文还对所提检测器的理论性能进行了分析，包括虚警概率、漏检概率以及比特误码率（BER）的下界。仿真结果表明，与传统检测器相比，所提出的盲检测器在符号检测性能上实现了显著提升。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已能达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时促进如虚拟战略模拟等新方法的发展。然而，其对firm绩效的最终影响将取决于随着AI能力进展的竞争动态。我们提出一个框架，连接了AI在SDM中的应用到企业成果，并讨论了AI如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏考虑。在本文中，我们通过引入一种新颖的数据管道来解决这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含14个类别下的1573个样本，展现了在十大排名靠前的模型间高达84\%的高可分离性，并与Chatbot Arena的评价一致性达到84\%，斯皮尔曼相关系数为0.915。这些一致度指标比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比次佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。此工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|本文介绍了一种名为Xpikeformer的混合模拟-数字硬件架构，旨在加速基于尖峰神经网络（SNN）的变压器模型。通过结合SNN的能量效率和时间动态特性与变压器的强大序列建模能力，Xpikeformer利用混合模拟-数字计算技术来增强性能和能源效率。该架构集成了模拟内存中计算（AIMC）以处理前馈和全连接层，以及一个随机尖峰注意力（SSA）引擎以实现高效的注意力机制。我们详细介绍了Xpikeformer的设计、实施及其评估过程，展示其在能源消耗和计算效率方面的显著改进。通过图像分类任务和无线通信符号检测任务，我们证明Xpikeformer能达到与软件相当的推理准确性。能源评估显示，与最先进的数字ANN变压器相比，Xpikeformer能实现高达17.8至19.2倍的能源消耗减少，与全数字SNN变压器相比，则可达到5.9至6.8倍的能源节约。此外，Xpikeformer还实现了相较于GPU实现的尖峰变压器快12.0倍的加速。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计具有情感智能的对话系统，以向处于困境中的人提供安慰和建议，是研究领域中的一个引人注目的方向。以往的研究工作侧重于开发模块化对话系统，将社会情感策略预测作为辅助任务，并利用定制的解码器生成策略条件化的回复。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入一种新颖的对话策略预测器EmoDynamiX，它利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一个灵活的混合情感模块来捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）的广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量评判时（例如文本的连贯性），预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLM作为裁判的评估仅仅基于提示中的指令，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示在多大程度上影响AI评判与人类评判的一致性，我们分析了针对几个LLM裁判的不同级别指令提示，这些提示详细说明了评价目标的质量要求。此外，我们还对比了一种无提示方法，即使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs进行的先进评估，并提供了作为裁判的模型严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的指令提示中获益甚微，且在某些情况下，特别是对于文本质量的评判，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但令人意外的是，语言模型可能并不关心描述内容的具体表述，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架也能带来改进。我们进一步将这种新型集成提示应用于常识、数学、逻辑推理及虚构检测等广泛任务，并采用了三个LLMs进行实验，结果喜人，再次表明设计合适的提示格式比专注于具体描述内容更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）上展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，近期LLM推理的进展显示，在提示中使用多样化的示例能够促使LLMs输出的多样性。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本论文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），一种混合自我集成方法，它结合了多样化示例基于提示的优势和LLM基于的聚合，以实现整体性能的提升。在公开可用的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发和评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语及英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相较于通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此研究作为将LLMs融入特定心理学领域的奠基性工作，对促进未来AI驱动的心理学实践发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，大型语言模型（LLMs）是解决表格推理问题的主要方法。大多数现有方法使用固定的表格格式来表示表格，这可能限制了性能。我们主张，鉴于每个实例需要不同的能力和模型拥有不同的能力，不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明这一论点，结果显示在使用不同表格格式时，不同的实例和模型会取得不同的表现。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM来预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时启用如虚拟战略模拟等新方法。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的格局，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一种新颖的数据管道来应对这些局限，该管道专门针对LLM作为评判者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终的评估集包含了14个类别下的1573个样本，显示出在十大顶级模型间高达84\%的高可分离性，并与Chatbot Arena的评价一致度达到84\%，斯皮尔曼相关系数为0.915。这一致度值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比次佳基准高出0.7，彰显了评估基准实用性的显著提升。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。此项工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究表明，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入一种新颖的对话策略预测器EmoDynamiX，该预测器利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一个灵活的混合情感模块以捕捉用户的精细化情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判（LLMs-as-a-judge）是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于强化学习从人类反馈（RLHF）的广泛应用，像GPT4和Llama3这样的最新LLMs在被提示进行质量判断时（例如文本的连贯性），预计会与人类偏好有强烈的对齐。尽管这看似有益，但尚不清楚LLM作为裁判的评估仅仅是基于提示中的指令进行的评估，还是反映了其对类似于其微调数据的高质量数据的偏好。为了研究对LLM裁判的提示如何影响AI评判与人类评判的一致性，我们分析了针对几个LLM裁判的、关于评价目标质量的指示逐渐增加的提示。此外，我们还对比了一种无提示方法，该方法使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类，这些标准普遍应用于采用LLMs的最先进评估中，并提供了作为裁判的模型严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的提示指令中获益甚微，且在某些情况下，特别是对于文本质量的评估，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的功能尚未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务中，涉及三个不同的LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式远比在特定描述上投入精力更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行修正，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL修正。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，以此作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不一致的内容，这种现象经验上被称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜成果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在某些情况下可能导致错误。在本文中，我们介绍了一种新颖的对比解码框架，称为LOL（较低层重要）。我们的方法将原始模型与业余模型的最终层及较低层的对比解码进行拼接，从而实现多层融合，以助于缓解幻觉。此外，我们融入了一个侧重真实性的重聚焦模块，利用上下文引导增强事实编码，在对比解码过程中进一步捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉现象，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以可靠地使用LLMs进行聚合，以产生最终输出。此外，最近在LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可以轻松扩展到基于自我集成的方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性并使用LLMs聚合的提示），一种混合自我集成方法，它结合了多样化示例提示和基于LLM聚合的优势，以提高整体性能。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情景中的表现。此外，我们推出了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相比通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性工作，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们认为，每个实例需要不同的能力，而模型也具备不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析，证明了上述观点，在不同格式下，不同的实例和模型表现各异。基于此讨论，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，以通过采用灵活的表格格式来提升表格推理性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式下的结果。在WikiTableQuestions和TabFact数据集上的实验显示出了显著的改进，与使用固定表格格式及贪婪解码、自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时促进如虚拟战略模拟等新方法的发展。然而，其对企业绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在实际应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一种新颖的数据管道来应对这些局限，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。所得到的评估集涵盖了14个类别的1573个样本，展示了在十大顶级模型间的高可分离性（84\%），并与Chatbot Arena的符合度达到84\%，Spearman相关系数为0.915。这些符合度值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而Spearman系数比下一个最佳基准高出0.7，彰显了基准实用性方面的显著提升。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。本工作对增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究显示，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，该预测器利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块以捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）的广泛应用，像GPT4和Llama3这样的最新语言模型在被提示进行质量判断时（例如文本的连贯性），预期会与人类偏好有很强的一致性。尽管这看似有利，但目前尚不清楚LLM作为裁判的评估仅仅是基于提示中的指令进行的评估，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示在多大程度上影响了AI评判与人类评判的一致性，我们分析了针对几个LLM裁判的、关于评价目标质量的指示逐渐增加的提示。此外，我们还对比了一种无提示方法，该方法使用模型困惑度作为质量度量。我们汇总了一个质量标准的分类，这些标准广泛应用于采用LLMs的最先进评估中，并提供了作为裁判的模型严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的提示指令中获益甚微，且在某些情况下，尤其是对于文本质量的评判，困惑度比提示更能与人类评判保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。出乎意料的是，语言模型可能并不在乎描述性说明的具体内容；性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务，涉及三种LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式比专注于特定描述内容，在效率和效果上更为有效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行修正，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修复错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL修正。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，作为纠错的反馈。实验结果表明，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生事实不准确或与期望输出不一致的内容，这种现象经验上称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜的效果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在某些情况下可能导致错误。在本文中，我们介绍了一种新颖的对比解码框架，名为LOL（较低层重要）。我们的方法包括连接原始模型与业余模型在最终层和较低层的对比解码，以此实现多层融合，以助于缓解幻觉。此外，我们融入了一个侧重真实性的模块，该模块利用上下文引导来增强事实编码，进一步在对比解码过程中捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉问题，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|自我增强技术，如自我一致性方法，在大型语言模型（LLMs）中展示了显著的准确性提升。然而，这些技术依赖于精确答案提取过程的可用性来聚合多个输出，并且由于生成相对较多的输出令牌，其推理成本相较于贪婪解码更高。研究表明，自我一致性产生的自由格式文本输出可以使用LLMs可靠地聚合以产生最终输出。此外，近期LLM推理方面的进展表明，在提示中使用多样化的示例能够诱导LLM输出的多样性。这些已证实的技术可以轻松扩展到自我集成方法中，以在文本生成中实现更优的结果。在本文中，我们介绍了PEDAL（基于示例多样性的提示，通过LLMs聚合），一种混合自我集成方法，它结合了多样示例基于提示的优势和LLM基于聚合的能力，以实现整体性能的提升。在公开的SVAMP和ARC数据集上的实验表明，PEDAL能够在比基于贪婪解码的策略更低的推理成本下实现更高的准确率。|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|本论文聚焦于心理学与人工智能的交叉领域，通过开发及评估专为心理学任务设计的大型语言模型（Large Language Models, LLMs）来进行深入探讨。我们引入了PsychoLex这一资源集合，旨在提升LLMs在波斯语和英语环境中进行心理学任务的能力。PsychoLex的核心贡献包含PsychoLexQA数据集，用于指导性内容的增强，以及PsychoLexEval数据集，用以严格评估LLMs在复杂心理学情境下的表现。此外，我们展示了PsychoLexLLaMA模型，该模型针对心理学应用进行了特别优化，并展现出相较于通用型模型更优越的性能。研究结果强调了定制化LLMs在推动心理学研究与应用方面的潜力，同时也指出了需要进一步细化的领域。此项研究为将LLMs融入特定心理学领域奠定了基础性步伐，对AI驱动的心理学实践未来的发展具有深远意义。|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|null|表格推理任务旨在根据给定的表格回答问题。目前，使用大型语言模型（LLMs）是表格推理的主要方法。大多数现有方法采用固定的表格格式来表示表格，这可能限制了性能。我们主张，每个实例需要不同的能力和模型具有不同的能力，因此不同的实例和模型适合不同的表格格式。我们通过对实验结果进行定量分析来证明上述观点，其中不同的实例和模型在使用各种表格格式时表现出不同的性能。在此讨论的基础上，我们提出了FLEXTAF-Single和FLEXTAF-Vote两种方法，通过采用灵活的表格格式来提升表格推理的性能。具体来说，(i) FLEXTAF-Single训练了一个分类器，根据实例和LLM预测最合适的表格格式。(ii) FLEXTAF-Vote则整合了不同格式的结果。我们在WikiTableQuestions和TabFact数据集上的实验显示了显著的改进，与使用固定表格格式及贪婪解码和自我一致性解码达到的最佳性能相比，平均提高了2.3%和4.8%，从而验证了我们方法的有效性。|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|本论文探讨了人工智能（AI）如何影响企业中的战略决策（SDM）过程。我们展示了AI如何增强现有的SDM工具，并提供了来自一个顶尖加速器项目和初创企业竞赛的实证证据，表明当前的大规模语言模型（LLMs）在生成和评估策略方面已达到与企业家和投资者相当的水平。随后，我们分析了AI对战略决策背后关键认知过程——搜索、表征与综合——的影响。我们的分析指出，AI有潜力提高战略分析的速度、质量和范围，同时启用如虚拟战略模拟等新方法。然而，其对企业发展绩效的最终影响将取决于随着AI能力进步的竞争动态。我们提出一个框架，连接了AI在SDM中的应用与企业成果，并讨论了AI可能如何重塑竞争优势的来源。最后，我们思考了AI如何既支持又挑战基于理论的战略视角的核心原则。总的来说，我们的工作勾勒出了AI与战略交叉领域的一个新兴研究前沿。|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|大型语言模型（LLMs）已经彻底改变了机器学习的领域，但当前的评估基准往往未能充分捕捉这些模型在现实应用中的多样行为。一个基准的有效性在于其区分不同能力模型的能力（可分离性）以及与人类偏好的紧密贴合度。现有的框架，如Alpaca-Eval 2.0 LC \cite{dubois2024lengthcontrolledalpacaevalsimpleway}和Arena-Hard v0.1 \cite{li2024crowdsourced}，受限于它们对通用查询的侧重以及在法律、医学、多语言环境等领域的多样性缺乏。在本文中，我们通过引入一个新颖的数据管道来解决这些局限性，该管道专门针对LLM作为评价者的框架，策划了跨多个领域的多样化、领域特定的评估集。我们的方法结合了人工策划、半监督学习以生成聚类，以及分层抽样以确保在广泛领域和语言中的均衡代表性。最终得到的评估集包含14个类别下的1573个样本，展现了在十大排名靠前的模型间高达84\%的高可分离性，并与Chatbot Arena的评价一致性达到84\%，斯皮尔曼相关系数为0.915。这些一致性数值比Arena Hard高出9\%，比AlpacaEval 2.0 LC高出20\%，而斯皮尔曼系数比下一个最佳基准高出0.7，显著提升了基准的实用性。我们进一步提供了一个开源的评估工具，使研究人员能够对模型在用户自定义类别下的性能进行细粒度分析，为实践者提供了宝贵的洞察。此项工作为增强LLM评估方法的透明度、多样性和有效性做出了贡献。|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|null|设计能够向处于困境中的人提供安慰与建议的高情感智能对话系统是一个极具吸引力的研究领域。以往的研究工作侧重于开发模块化对话系统，其中将社会情感策略预测视为辅助任务，并利用定制化的解码器生成策略条件响应。近期，随着大型语言模型（LLMs）的发展，无需显式社会情感策略预测步骤的端到端对话代理变得日益普遍。然而，尽管这些模型在语言生成方面表现出色，最近的研究显示，LLMs对某些社会情感策略的固有偏好偏见阻碍了高质量情感支持的传递。针对这一挑战，我们提议将策略预测与语言生成解耦，并引入了一个新颖的对话策略预测器EmoDynamiX，该预测器利用异构图来模拟用户情绪与系统策略之间的语篇动态。此外，我们还利用了对话中的情感识别（ERC）任务，并设计了一种灵活的混合情感模块以捕捉用户的细粒度情感状态。在两个ESC数据集上的实验结果表明，EmoDynamiX显著优于先前的最先进方法。|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|LLMs作为裁判是一种新近流行的方法，它在任务评估中用大型语言模型（LLMs）的自动评估替代了人工评判（Zheng等人，2024年）。鉴于通过人类反馈的强化学习（RLHF）被广泛应用，像GPT4和Llama3这样的最新水平LLMs在被提示进行质量判断时（例如文本的连贯性），预计会与人类偏好有很强的一致性。尽管这看似有益，但目前尚不清楚LLM作为裁判的评估仅仅基于提示中的指示进行评价，还是反映了其对类似其微调数据高质量样本的偏好。为了探究对LLM裁判的提示引导在其评判与人类评判的一致性上有多大影响，我们分析了针对几个LLM裁判的不同级别指示提示，这些提示旨在明确目标评价质量。此外，我们还对比了一种无提示方法，该方法使用模型困惑度作为质量度量标准。我们汇总了一个质量标准的分类体系，这些标准普遍应用于采用LLMs进行的先进评估中，并以此作为模型作为裁判的严格基准。总的来说，我们的研究表明，LLM作为裁判从高度详细的指示提示中获益甚微，且在某些情况下，特别是对于文本质量的评价，困惑度比提示方法能更好地与人类判断保持一致。|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|通过在上下文学习（ICL）中的应用，大型语言模型（LLMs）已经在多种任务上取得了令人瞩目的表现。然而，ICL过程中描述性指令的作用仍未得到充分探索。本研究提出了一种集成提示框架，旨在阐述多个上下文示例选择标准，并初步在六个翻译方向上的机器翻译（MT）任务上验证了该框架能提升ICL性能。但出乎意料的是，语言模型可能并不在乎描述内容的具体含义，性能提升主要归因于集成格式本身，因为即使使用随机的描述性名词，该框架仍能带来改进。我们进一步将这一新型集成提示应用于常识、数学、逻辑推理及幻觉任务中，涉及三个不同的LLMs，并取得了鼓舞人心的结果，再次表明设计合适的提示格式远比专注于具体描述内容更为有效和高效。一旦论文发表，我们的代码将会公开提供。|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|null|文本到SQL转换是一项重要任务，它通过自动生成SQL查询帮助人们从数据库中获取信息。鉴于大型语言模型（LLMs）的出色表现，基于LLMs的方法已成为文本到SQL的主流。在这些方法中，自动纠错是一种有效方法，通过纠正生成结果中的错误来进一步提升性能。现有的纠错方法要求LLMs直接对生成的SQL进行纠正，而先前的研究表明LLMs并不擅长发现错误，导致性能不佳。因此，本文提出利用分解纠错来增强文本到SQL的性能。我们首先证明了分解纠错优于直接纠错，因为根据分解子任务的结果检测并修正错误比直接针对SQL更容易。基于此分析，我们引入了分解自动纠错（DAC）方法，该方法通过将文本到SQL任务分解为实体链接和骨架解析来进行SQL纠错。DAC首先生成与问题对应的实体和骨架，然后比较初始SQL与生成的实体和骨架之间的差异，以此作为纠错的反馈。实验结果显示，与基线方法相比，我们的方法在Spider、Bird和KaggleDBQA上的平均性能提升了3.7%，验证了DAC的有效性。|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|大型语言模型（LLMs）在多种自然语言处理任务中展示了卓越的性能，但它们有时会产生与事实不符或与期望输出不一致的内容，这种现象经验上被称为“幻觉”。为了解决这一问题，近期的研究探索了原始模型与诱导产生幻觉的业余模型之间的对比解码，已展现出可喜的成果。然而，这种方法可能因粗糙的对比和简单的减法操作而削弱原始LLM的输出分布，在特定情况下可能导致错误。在本文中，我们引入了一个新颖的对比解码框架，称为LOL（较低层重要）。我们的方法将原始模型与业余模型在最终层和较低层的对比解码进行拼接，从而实现多层融合，以助于缓解幻觉现象。此外，我们融入了一个注重真实性的重聚焦模块，利用上下文引导增强事实编码，在对比解码过程中进一步捕捉真实性。在两个公开可用数据集上进行的广泛实验表明，我们提出的LOL框架能显著减轻幻觉现象，并在大多数情况下超越现有基线。与最佳基线相比，我们在TruthfulQA的所有指标上平均提高了4.5分。源代码即将发布。|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|null|翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了对由LLMs驱动的NL2SQL技术的全面回顾，涵盖了其整个生命周期的四个方面：（1）模型：解决NL的歧义和欠规范问题的NL2SQL翻译技术，以及恰当映射NL与数据库模式和实例；（2）数据：从训练数据的收集、因训练数据稀缺而进行的数据合成，到NL2SQL基准测试；（3）评估：使用不同指标和粒度从多角度评估NL2SQL方法；及（4）错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进化。此外，我们为开发NL2SQL解决方案提供了一套经验法则。最后，我们讨论了LLMs时代NL2SQL的研究挑战和开放问题。|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但在更广泛的数据科学管道中实现完全自动化——包括数据查询、分析、可视化及报告制作——仍是一个复杂挑战。本研究介绍了一款名为SageCopilot的先进工业级系统，该系统通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs），实现了数据科学管道的自动化。具体而言，SageCopilot采用了一个双阶段设计：在线阶段利用情境学习（ICL）精炼用户输入为可执行脚本并运行这些脚本以报告结果及生成可视化内容；离线阶段则根据在线阶段ICL的需求准备演示。系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格的测试和与基于提示解决方案的比较分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面达到了端到端的优越性能，并且这些验证基于真实世界数据集。我们的深入消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）被证明能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的示范示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器来动态检索示例，但外部检索器与LLMs之间在表示能力上存在固有的差异。此外，优化示例选择并非易事，因为缺乏直接方法能在不进行成对推理的情况下评估示例的相对益处。为了解决这些不足，我们提出了DeTriever，一种新颖的示范检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练该模型，我们设计了一种代理评分，根据输出查询之间的相似性来估算示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为了解决这一问题，我们提出了一种多角度的NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情境下（如不同的数据领域和SQL特性）对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360识别出了在Spider数据集上使用执行准确率指标表现优异的有效NL2SQL方法——SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现了竞争力强的性能。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术使得不熟悉数据库的非专业用户也能利用SQL进行数据分析。其中，将自然语言转化为商业智能（NL2BI）是NL2SQL在实际生产系统中一个广泛应用的实践场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项综合且高效的技术——ChatBI，旨在解决NL2BI任务。首先，我们分析了交互模式这一重要模块，该模块在NL2SQL与NL2BI的应用中存在差异，并设计了一个更小巧、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而难以进行。BI场景中更高比例的列义模糊性也加剧了模式链接的难度。ChatBI结合了数据库领域现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列再作为所需列输入到LLM中进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，使ChatBI能更准确地生成包含复杂语义和比较关系的SQL。   我们已在百度的数据平台上部署了ChatBI，并将其整合进多条产品线中，进行了大规模生产任务的评估。所得结果彰显了其在实用性、通用性和效率上的优越性。同时，相较于当前主流NL2SQL技术，在我们的实际BI场景数据表和查询下，ChatBI也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进翻译，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而未能生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含来自不同数据库的已知NL2SQL转换。LLMs可以从输入的示例中学习如何为当前任务组织运算符组合。在本文中，我们提出了PURPLE（利用预训练模型检索提示以进行逻辑增强），通过为手头的NL2SQL任务检索包含必要逻辑运算符组合的示例，从而引导LLMs产生更佳的SQL转换，以此提升准确率。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的精确集匹配准确率和87.8%的执行匹配准确率，树立了新的state-of-the-art性能标准。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确率，展现出其鲁棒性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取示例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性是一项重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为了实现这一目标，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。我们的全面评估表明，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到了证实。尤其值得一提的是，与OpenAI和Cohere的强竞争性嵌入模型相比，我们的模型表现出色。此外，与这些竞争模型相比，我们提出的编码器在1-shot情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进展集中在利用大语言模型（LLM）的上下文学习能力上，取得了显著成效。然而，这些方法在处理冗长的数据库信息和复杂用户意图时面临挑战。本文提出了一种两阶段框架，旨在提升基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示方式——参考增强表示法，该方法整合了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，借助已链接的模式，我们简化提示中的模式信息，并指示LLM输出最终SQL。最后，作为后处理优化模块，我们建议采用跨LM一致性而非单一LM内的自一致性策略。我们的方法在Spider基准测试上达到了新的最佳水平，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们借助ChatGPT通过自我指导的方式，基于给定的图数据库生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们提出了一种方法，即从查询的自然语言中抽取相关模式作为输入上下文，以此引导LLMs更准确地生成GQL。我们在两个构建于金融和医疗领域的图数据库——FinGQL和MediGQL上评估了我们的方法。实验结果表明，相较于一组基线方法，我们的方法显著提高了性能，分别在精准匹配（EM）指标上提升了5.90和6.36绝对百分点，在 existence 匹配（EX）指标上提升了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资源。访问控制跨越两个领域：策略（组织级原则，定义谁应具有访问权限）与流程（数据库级原语，实际实施该策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种新的访问控制范式——面向数据库的意图型访问控制（Intent-Based Access Control for Databases, IBAC-DB）。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix, NLACM）得以更精确地表达。数据库访问控制原语会根据这些NLACMs自动生成。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（称为LLM4AC），以及评估此类系统准确性和范围的初始基准测试。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC极大地超越了其他基线，在我们的初步Dr. Spider基准测试中达到了高准确度和F1分数。在所有系统上，我们发现扩展基准测试的整体性能优异，这些测试包括需要外部知识的最先进NL2SQL数据，以及来自Amazon Access数据集的真实世界角色层次结构。|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|在AIOps（面向IT运营的人工智能）时代，准确预测系统状态至关重要。在微服务系统中，这一任务面临着动态和复杂的空间-时间关系挑战，这主要归因于动态部署、多样的调用路径以及实例间的级联效应。当前的时间序列预测方法主要关注内在模式，在空间关系至关重要的环境中显得不足。同样，空间-时间图方法往往忽视了时间趋势的本质，更多地集中在节点间的消息传递上。此外，微服务领域的现有研究常常低估了网络指标和拓扑结构在捕捉系统动态演化中的重要性。本文介绍了一种针对微服务环境中的系统状态预测而设计的模型STMformer，该模型能够处理多节点和多变量时间序列。我们的方法利用动态网络连接数据和拓扑信息来帮助建模系统内部复杂的时空关系。此外，我们集成了PatchCrossAttention模块以全局计算级联效应的影响。我们基于一个微服务系统构建了一个数据集，并对STMformer进行了全面的实验对比领先方法。在短期和长期预测任务中，我们的模型持续实现了8.6%的MAE（平均绝对误差）降低和2.2%的MSE（均方误差）减少。模型源代码可于https://github.com/xuyifeiiie/STMformer获取。|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|**AIOps算法在微服务系统的维护中发挥着关键作用。许多先前的基准性能排行榜为选择合适的算法提供了有价值的指导。然而，现有的AIOps基准主要利用离线数据集来评估算法，无法持续使用实时数据集评估算法性能，并且评估的操作场景是静态的，这对于有效选择算法是不够的。为了解决这些问题，我们提出了一种评估一致性和面向场景的评估框架，名为MicroServo。其核心思想是构建一个实时微服务基准，以生成实时数据集，并在其上持续模拟特定操作场景。MicroServo通过根据操作场景选择特定算法和数据集来支持不同的排行榜。它还支持多种类型算法的部署，实现了算法的热插拔功能。最后，我们通过三个典型的微服务操作场景测试了MicroServo，以展示其效率和易用性。**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|大型语言模型（LLMs）和AI代理在软件开发与部署中的迅速应用正在革新信息技术领域。尽管代码生成受到广泛关注，但AI代理在云服务运营韧性方面的应用具有更高的影响力，目前这类服务需要大量的人力投入及专业知识。AIOps（AI for IT Operations）作为新兴热点，旨在通过自动化复杂运维任务（如故障定位和根本原因分析），减少人为干预并降低对客户的影响。然而，实现通过AIOps达到自主且自愈合云服务的愿景，受到缺乏构建、评估及改进AIOps代理标准化框架的阻碍。该愿景论文首先界定了需求，随后讨论了满足这些需求的设计决策，为这一框架奠定了基础。我们还提出了AIOpsLab原型实现，它利用代理-云接口来编排应用程序，采用混沌工程实时注入故障，并与代理接口以定位和解决这些故障。我们报告了有前景的结果，并为构建、评估及提升自主云所需的模块化、健壮框架奠定了基础。|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|**日志分析对于确保信息系统有序和稳定运行至关重要，尤其在人工智能运维（AIOps）领域。大型语言模型（LLMs）在自然语言处理任务中显示出了巨大潜力。在AIOps领域，它们在异常检测、故障根本原因分析、运维脚本生成及警报信息摘要等任务上表现出色。然而，当前LLMs在日志分析任务中的性能尚缺乏充分验证。为解决这一缺口，我们引入了LogEval——首个全面的基准测试套件，旨在评估LLMs在各种日志分析任务中的能力。该基准涵盖了日志解析、日志异常检测、日志故障诊断和日志摘要等任务。LogEval利用4,000条公开的日志数据条目对每个任务进行评估，并为每个任务采用15种不同的提示，以确保评估的深入性和公正性。通过对领先LLMs的严格评估，我们展示了不同LLM技术对日志分析性能的影响，特别关注自一致性与少量样本的上下文学习能力。同时，我们也讨论了模型量化、中英文问答评估及提示工程方面的发现。这些发现揭示了LLMs在多语言环境下的优缺点以及不同提示策略的有效性。针对不同任务采用了多种评估方法，以准确衡量LLMs在日志分析中的表现，实现全面评估。LogEval评估所得的洞见展现了LLMs在日志分析任务中的强项与局限，为研究人员和实践者提供了宝贵指导。**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|随着软件系统的复杂性日益增加，为了确保大规模分布式软件系统的高可用性和可靠性，人工智能运维（AIOps）方法在软件系统故障管理中的应用已十分广泛。然而，这些方法仍面临一些挑战，比如跨平台通用性不足和跨任务灵活性欠缺。幸运的是，大型语言模型（LLMs）的最新进展能有效应对这些挑战，众多研究已着手探索这一领域。但目前尚缺乏一份全面的综述来讨论基于LLM的AIOps与传统AIOps方法之间的差异。因此，本文提供了面向LLM时代的AIOps技术在故障管理领域的综合调查。内容涵盖AIOps故障管理任务的详尽定义、AIOps所需的数据来源，以及应用于AIOps的LLM基础方法。此外，本综述还深入探讨了AIOps子任务、适用于不同AIOps子任务的具体LLM方法，以及该领域面临的挑战与未来发展方向，旨在促进其进一步发展与应用。|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|**动态图中的异常边检测旨在识别与正常模式显著偏离的边，可应用于网络安全、金融交易和AIOps等多个领域。随着时间的推移，异常边的类型不断涌现，而针对每种类型的标记异常样本却十分有限。现有方法要么旨在检测随机插入的边，要么需要大量标记数据进行模型训练，这限制了它们在实际应用中的适用性。本文针对这一问题，通过利用大型语言模型（LLMs）中丰富的知识进行合作，提出了一种名为AnomalyLLM的方法。为了使动态图与LLMs对齐，AnomalyLLM首先预训练了一个动态感知编码器，用于生成边的表示，并利用词嵌入原型重编程边。与编码器相配套，我们设计了一个基于上下文学习的框架，该框架整合了少量标记样本的信息，以实现少样本异常检测。在四个数据集上的实验表明，AnomalyLLM不仅能显著提升少样本异常检测的性能，还能在无需更新模型参数的情况下，对新型异常实现优越的检测效果。**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|我们推出了一款基于机器学习的异常检测产品——AI检测与响应（AIDR），该产品实时监控沃尔玛的业务和系统健康状况。在为期3个月的验证期间，AIDR从超过3000个模型中为25个以上的应用程序、平台和运营团队提供了预测，覆盖了63%的重大事件，并将平均故障发现时间（MTTD）缩短了超过7分钟。与以往的异常检测方法不同，我们的解决方案结合使用了统计学、机器学习和深度学习模型，同时继续融入基于规则的静态阈值，以吸收领域特定知识。为了实现可扩展性和高可用性，不论是单变量还是多变量的机器学习模型，都通过分布式服务进行部署和维护。AIDR具备反馈机制，利用漂移检测算法和客户反馈来评估模型质量，同时还提供自服务接入能力和可定制性。AIDR已成功应用于多个内部团队，相比以往方法实现了更短的故障发现时间和更少的误报。展望未来，我们旨在扩大事件覆盖范围和预防能力，减少噪声，并进一步与根本原因推荐（RCR）集成，以实现端到端的AIDR体验。|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|在云原生技术中，微服务架构日益增长的复杂性给维持系统稳定性和效率带来了重大挑战。为了对告警事件进行根本原因分析（RCA）及解决，我们提出了一种开创性的框架——面向微服务架构的根本原因分析多智能体区块链启发式协作（mABC），旨在革新人工智能运维（AIOps）领域。该框架下，多个基于强大大型语言模型（LLMs）的智能体通过区块链启发式的投票达成最终共识，并遵循智能体工作流规定的标准化流程来处理任务和查询。具体而言，依据智能体工作流，七个专业化的智能体各自根据其专长和内在软件知识，协作构成一个去中心化链条，共同为根本原因分析提供宝贵见解。为了避免LLMs潜在的稳定性问题，并充分利用去中心化结构中固有的透明和平等优势，mABC采纳了受区块链治理原则启发的决策过程，同时考虑每个智能体的贡献指数和专业指数。实验结果表明，在公共基准AIOps挑战数据集和我们创建的火车票数据集上，相比以往的强基线方法，mABC在准确识别根本原因及制定有效解决方案方面展现出更优越的性能。进一步的消融研究强调了mABC中各组成部分的重要性，其中智能体工作流、多智能体机制以及区块链启发式投票对于实现最佳性能至关重要。mABC为微服务架构提供了一个全面自动化的根本原因分析与解决方案，相较于现有基线，在AIOps领域实现了显著提升。|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|**大型语言模型（LLMs）在众多领域推动了新一轮的交互式AI应用浪潮。然而，由于生成模型的自回归特性，有效服务于LLM推理请求极具挑战性，因为它们的执行时间不可预测。现有的LLM服务系统采用先来先服务（FCFS）调度策略，这会遭受队头阻塞问题的影响。为了应对LLM的非确定性本质并实现高效的交互式LLM服务，我们提出了一种推测式最短作业优先（SSJF）调度器，它使用一个轻量级代理模型来预测LLM输出序列的长度。我们的开源SSJF实现无需对内存管理或批处理策略进行修改。在真实世界数据集和生产工作负载跟踪上的评估显示，与FCFS调度器相比，SSJF在无批处理、动态批处理和连续批处理设置下，平均作业完成时间减少了30.5%-39.6%，吞吐量提高了2.2-3.6倍。**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|现代IT系统的管理带来了独特的挑战，要求在处理大量数据流时具备可扩展性、可靠性和效率。传统的依赖手动任务和基于规则方法在应对IT系统产生的大量数据和警报时显得效率低下。为解决这一问题，人工智能操作系统（AIOps）应运而生，它利用机器学习和大数据等高级分析技术来加强事件管理。AIOps能够检测和预测事件、识别根本原因，并自动化执行修复操作，从而提升服务质量并降低运营成本。然而，尽管潜力巨大，AIOps领域仍处于初级阶段，分散于多个行业且缺乏统一的标准规范。目前，研究与产业界的贡献散布各处，缺乏一致的数据管理框架、目标问题定义、实施细节、需求及能力标准。本研究提出了一套AIOps的术语和分类学，旨在建立一个结构化的事件管理流程，并为构建AIOps框架提供指导原则。研究还根据事件管理任务、应用领域、数据来源和技术方法等标准对贡献进行了分类。其目的在于全面回顾AIOps在事件管理中的技术与研究层面，旨在组织知识体系、识别研究空白，并为该领域的未来发展奠定基础。|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|针对移动键盘应用中设备端语言模型训练的最新技术，结合了联邦学习（FL）与差分隐私（DP），通过使用DP-Follow-the-Regularized-Leader（DP-FTRL）算法。实践中采用的DP-FTRL有两种变体，即树聚合和矩阵分解。然而，树聚合在隐私与效用的权衡上表现不佳，而矩阵机制需要通过难以预先准确估计的常数进行昂贵的优化，并且运行时内存成本高。本文将最近引入的缓冲线性Toeplitz（BLT）机制扩展至多参与场景。我们的BLT-DP-FTRL保持了树聚合的易用性优势，同时几乎在实用性和隐私保护方面达到了矩阵分解的水平。我们在StackOverflow数据集上进行了评估，作为可复现的模拟基准，并在生产FL系统的四个设备端语言模型任务中进行了测试。实证结果突显了BLT机制的优势，提升了DP在现实世界场景中的实用性和有效性。|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|工业物联网（IIoT）对数据隐私和网络安全威胁高度敏感。联邦学习（FL）作为解决方案应运而生，旨在保护隐私，使得本地IIoT客户端的数据得以保留在本地，同时协同训练模型以检测网络异常。然而，无论是同步还是异步的FL架构，在处理因数据异质性和资源限制导致的客户端速度不均问题时，都存在局限性。同步架构会受到拖尾效应的影响，而异步方法则遇到通信瓶颈的问题。此外，FL模型还容易受到旨在披露私人训练数据的对抗性推理攻击。为了解决这些挑战，我们提出了一种针对异构IIoT环境中的异常检测、融合了同态加密的缓冲联邦学习（BFL）框架。BFL采用了一种新颖的加权平均时间方法，以缓解拖尾效应和通信瓶颈，通过与基于缓冲区的服务器协作，确保了处理速度各异的客户端之间的公平性。基于两组数据集的性能结果显示，BFL相比于先进的FL方法具有优越性，展现出在提高准确性和收敛速度的同时，增强了隐私保护的能力。|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|联邦学习（FL）是一种有前景的隐私保护分布式学习框架，能够在移动电话、桌面电脑及配备CPU或GPU的设备等各种装置上部署。在基于服务器的联邦学习即服务（FLaaS）场景下，FL使中央服务器能够协调多个设备上的训练过程，无需直接访问本地数据，从而增强隐私和数据安全性。低秩自适应（LoRA）是一种高效微调模型的方法，通过专注于模型参数的低维子空间来实现。与从头开始微调所有参数相比，这种方法显著降低了计算和内存成本。当LoRA与FL结合，尤其是在FLaaS环境中，通过调整局部模型的秩，允许在具有不同计算能力的多样化硬件上灵活且高效地部署。然而，在启用LoRA的FL中，不同的客户端可能会使用不同秩来训练模型，这对服务器端的模型聚合提出了挑战。当前聚合不同秩模型的方法需要对权重进行填充以达到统一形状，这可能损害全局模型的性能。为解决这一问题，我们提出了基于秩的LoRA聚合（RBLA），这是一种针对异构LoRA结构设计的新颖模型聚合方法，旨在保留不同秩模型的关键特征。本文首先分析了当前填充方法在FLaaS环境中重塑模型以进行聚合存在的问题，随后引入了RBLA，该方法能在保持低秩与高秩特征的同时进行聚合。最后，我们通过与前沿方法的对比实验，验证了RBLA的有效性。|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|联邦学习通过消除数据共享的需要，为AI应用带来了革命性的变化。然而，研究表明，在训练过程中仍可提取信息，因此需要额外的隐私保护措施，如差分隐私。为了实现现实世界的联邦学习应用，从性能的公平分配到非歧视性行为，公平性都是必须考虑的因素。特别是在高风险应用领域（如医疗健康），避免重复过去歧视性错误至关重要。近期研究表明，隐私与公平之间存在固有的紧张关系，为此，我们进行了多声部文献回顾，以考察当前在联邦学习中整合隐私与公平的方法。我们的分析揭示了隐私与公平之间的关系被忽视的问题，这对现实世界的应用构成了重大风险。我们强调了探索隐私、公平与性能之间关系的必要性，并倡导创建综合性的联邦学习框架。|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|联邦学习能够在遵守隐私要求的前提下，让多个客户端在服务器的总体规划下协同训练机器学习模型。然而，服务器无法直接监督局部训练过程，这为恶意客户端植入后门提供了可乘之机。现有研究表明，后门攻击会在受感染的模型中激活特定神经元，而这些神经元在处理干净数据时保持休眠状态。基于这一观察，我们提出了一种名为“低激活输入神经元权重更新反转”（FLAIN）的方法来防御联邦学习中的后门攻击。具体而言，在完成全局训练后，我们利用一个辅助数据集来识别低激活输入神经元，并反转与之相关的权重更新。我们逐步提高低激活输入的阈值，并迭代地进行权重更新的反转，直至在辅助数据上的性能下降变得不可接受为止。广泛实验验证了我们的方法能有效降低各种攻击场景下的后门攻击成功率，包括非独立同分布数据或高错分类率（MCR）的情况，同时对干净数据的性能影响保持在最低水平。|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|为保护数据隐私，联邦学习（FL）范式应运而生，其中客户端仅公开模型梯度而非原始数据进行模型训练。为了进一步增强联邦学习中模型梯度的保护，提出了差分隐私联邦学习（DPFL），该方法通过引入差分隐私（DP）噪声来混淆梯度，然后再将其暴露。然而，DPFL中一个基本但常被忽视的问题是客户端隐私需求的异质性，这种需求在不同客户端间可能有显著差异，极大地复杂化了DPFL中的客户端选择问题。换句话说，在选择客户端时，既要考虑数据质量，也要考虑DP噪声的影响。为解决这一问题，我们针对具有异构隐私设置的DPFL进行了收敛性分析，考虑了一般的客户端选择策略、流行的DP机制及凸损失函数。基于收敛性分析，我们将目标设定为最小化DPFL中带有异构隐私设置下损失函数的值，这是一个凸优化问题，可以高效求解。因此，我们提出了DPFL-BCS（有偏客户端选择）算法。广泛的实验结果，包括使用真实数据集及在凸与非凸损失函数下的测试，表明DPFL-BCS能显著提升模型效用，相比当前最优的基线方法有明显优势。|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|随着联网和自动驾驶车辆的普及，控制器区域网络（CAN）总线已成为车内网络通信的主要标准，这得益于其速度和效率。然而，CAN总线缺乏基本的安全措施，如认证和加密，使其极易受到网络攻击。为了确保车内安全，入侵检测系统（IDS）必须能检测已知攻击，并对新的、未见过的攻击提供强大的防御能力，同时保持轻量级以便实际部署。以往的研究要么仅依赖CAN标识符特征，要么使用了传统的机器学习（ML）方法结合手动特征提取。这些方法忽视了其他可被利用的特征，使得系统难以适应新出现的攻击变种，从而影响安全性。本文提出了一种创新的、轻量级的、车载IDS解决方案，该方案利用深度学习（DL）算法来解决这些局限性。所提议的IDS采用多阶段方法：第一阶段使用人工神经网络（ANN）来检测已知攻击，第二阶段则采用长短期记忆（LSTM）自编码器来检测新的、未见过的攻击。  为理解并分析多样的驾驶行为，实时更新模型以涵盖最新的攻击模式，并保护数据隐私，我们提出了一种理论框架，用于在层次化联邦学习（H-FL）环境中部署我们的IDS。实验结果显示，我们的IDS在已知攻击上的F1分数超过0.99，在新型攻击上的F1分数超过0.95，检测率达到99.99%。此外，误报率（FAR）极低，仅为0.016%，有效减少了误报。尽管采用了在识别复杂及零日攻击方面表现出色的深度学习算法，但该IDS仍保持轻量化，确保了其在现实世界中的可部署性。|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|联邦学习（FL）理论上在保护个体客户端数据隐私的同时能够生成高质量的机器学习模型。然而，诸如深度梯度泄露（DLG）等攻击严重质疑了FL的实际应用性。本文通过实证评估了四种防御方法针对DLG的有效性：掩码（Masking）、裁剪（Clipping）、修剪（Pruning）和噪声注入（Noising）。掩码技术，虽然之前仅作为参数传输过程中压缩信息的方法进行研究，但出人意料地展现出相比于其他三种成熟方法更为强大的防御效用。我们的实验分为两部分。首先，我们跨MNIST、CIFAR-10和lfw数据集评估每种方法的最低超参数阈值。接着，我们利用各方法及其最低阈值训练FL客户端，以研究对抗DLG防御与训练性能之间的权衡。结果显示，掩码和裁剪在几乎不影响性能的同时，能有效混淆足够信息以防御DLG攻击。|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|**联邦学习（FL）是一种增强隐私的技术，用于分布式机器学习。通过本地训练模型并聚合更新，联邦能够在不进行集中数据收集的情况下共同学习。FL在医疗、金融和个人计算领域日益受到欢迎。然而，它继承了经典机器学习中的公平性挑战，并由于数据质量差异、客户端参与度、通信限制、聚合方法及底层硬件差异引入了新的挑战。公平性仍然是FL中一个未解决的问题，社区已识别出缺乏简明定义和指标来量化公平性的现状；为应对这一问题，我们提出了联邦公平性分析方法论——一种衡量公平性的方法。我们的公平性定义包括四个概念，并配有新颖的对应指标。这些定义是针对问题症状提出的，并利用了源自可解释AI、合作博弈论和网络工程的技术。  我们在多种实验设置下进行了测试，改变了FL方法、机器学习任务和数据设置。结果表明，统计异质性和客户端参与度会影响公平性，而诸如Ditto和q-FedAvg等注重公平性的方法仅在一定程度上改善了公平性与性能之间的权衡。借助我们的技术，FL从业者能够揭示其系统公平性的前所未有的深入见解，包括不同粒度级别的见解，从而应对FL中的公平性挑战。我们的工作已在https://github.com/oscardilley/federated-fairness开源。**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|分布式太阳能发电系统的快速增长给配电系统规划和调度带来了挑战，主要原因是这类系统背后的太阳能发电难以观测。为了解决集中式机器学习方法在估算用户侧（BTM）太阳能发电量时的数据泄露问题，联邦学习（FL）方法因具备分布式学习能力而受到研究者的关注。然而，传统的联邦学习方法面临着异构性、通信故障以及恶意隐私攻击等多种挑战。针对这些挑战，本研究提出了一种针对异构社区级BTM太阳能发电量的通信鲁棒性和隐私安全性的分布式估计算法。具体而言，本研究采用多任务联邦学习作为主体框架，旨在学习所有社区间的共同特征与独特特性。同时，研究中嵌入了一种更新参数估计算法到多任务联邦学习中，能够自动识别任意两个客户端之间的相似性，并为无法通信的客户端估计更新参数，从而缓解通信故障带来的负面影响。最后，本研究在动态隐私预算分配策略下采用了差分隐私机制，以抵御恶意隐私攻击并提升模型训练效率。案例研究表明，在存在异构性和通信故障的情况下，所提出的算法相比于传统联邦学习和局部化学习方法，展现出更优的估测精度和收敛性能，同时提供了更强的隐私保护。|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240819>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

