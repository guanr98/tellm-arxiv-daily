[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]

## Updated on 2024.08.26
> Usage instructions: [here](./docs/README.md#usage)

<details>
  <summary>Table of Contents</summary>
  <ol>
    <li><a href=#agent>agent</a></li>
    <li><a href=#llm>llm</a></li>
    <li><a href=#wireless-network>Wireless Network</a></li>
    <li><a href=#wireless-communications>Wireless Communications</a></li>
    <li><a href=#wireless-intelligence>Wireless Intelligence</a></li>
    <li><a href=#communication-intelligence>Communication Intelligence</a></li>
    <li><a href=#rag>RAG</a></li>
    <li><a href=#text2sql>text2sql</a></li>
    <li><a href=#aiops>AIOps</a></li>
    <li><a href=#ppc>PPC</a></li>
  </ol>
</details>

## agent

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-22**|**Can LLMs Understand Social Norms in Autonomous Driving Games?**|Boxuan Wang et.al.|[2408.12680](http://arxiv.org/abs/2408.12680)|null|社会规范是指社会中关于可接受行为的共享标准。社会规范的出现促进了代理之间的协调，无需硬性规定，这对于自动驾驶汽车（AVs）在智能交通系统中的大规模部署至关重要。本文探讨了大型语言模型（LLMs）在理解和模拟自动驾驶游戏中的社会规范的应用。我们引入LLMs作为智能代理参与到基于文本提示做决策的自动驾驶游戏中，这些代理被称为基于LLM的代理。我们的框架涉及到基于LLM的代理在多智能体系统（MAS）中进行马尔可夫博弈，使我们能够研究个体代理间社会规范的形成。通过设计提示并利用与环境设置和基于LLM代理观察相关的文本信息的LLMs，我们旨在识别社会规范。借助于由GPT-4.0驱动的OpenAI Chat API，我们开展实验以模拟交互，并在两个驾驶场景：无信号交叉口和高速公路列队中评估基于LLM代理的表现。结果表明，基于LLM的代理能够处理马尔可夫博弈中动态变化的环境，并且在这两个场景中社会规范都在基于LLM的代理之间逐渐形成。在交叉口游戏中，面对可能发生的车辆碰撞时，基于LLM的代理倾向于采取保守的驾驶策略。基于LLM的代理在游戏中的优势在于其强大的操作性和可分析性，这有助于实验设计。|
|**2024-08-22**|**MDD-5k: A New Diagnostic Conversation Dataset for Mental Disorders Synthesized via Neuro-Symbolic LLM Agents**|Congchi Yin et.al.|[2408.12142](http://arxiv.org/abs/2408.12142)|**[link](https://github.com/lemonsis/mdd-5k)**|**临床诊断大多数精神障碍主要依赖于精神科医生与患者之间的对话。构建这类诊断对话数据集对于推动AI心理健康护理领域的发展具有重大意义。然而，由于严格的隐私和伦理考量，直接收集真实诊断场景中的对话近乎不可能。为解决这一问题，我们旨在利用易于获取的匿名患者病例来合成诊断对话。具体而言，我们设计了一种神经符号多智能体框架，利用大型语言模型来合成精神障碍的诊断对话。该框架以患者病例为输入，能够基于单一病例生成多样化的对话。框架基本涉及医生智能体与患者智能体的互动，并通过来自工具智能体的动态诊断树，在符号控制下实现文本生成。通过应用所提出的框架，我们开发了最大的中文精神障碍诊断数据集MDD-5k。该数据集基于与一家先锋精神病院合作清理的1000个真实患者病例构建，包含5000条高质量的长对话及诊断结果作为标签。据我们所知，这也是首个带有标签的中文精神障碍诊断数据集。人类评估显示，提出的MDD-5k数据集成功模拟了精神障碍的人类诊断过程。数据集和代码将在https://github.com/lemonsis/MDD-5k公开访问。**|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|**大型语言模型（LLMs）在视觉与语言导航（VLN）任务中展现出潜力，但当前应用面临挑战。尽管LLMs在一般对话场景中表现出色，它们在专门的导航任务上表现挣扎，相比于专业的VLN模型，其性能次优。我们引入了FLAME（FLAMingo架构的实体代理），一种针对城市VLN任务设计的新型多模态LLM基代理及架构，能高效处理多重观察。我们的方法实施了一个三阶段调整技术，以便有效适应导航任务，包括单感知调整以进行街景描述、多感知调整以实现轨迹概括，以及在VLN数据集上的端到端训练。增强的数据集自动合成。实验结果表明，FLAME相较于现有方法的优越性，在Touchdown数据集上的任务完成率提高了7.3%，超越了最先进方法。此工作彰显了多模态大型语言模型（MLLMs）在复杂导航任务中的潜力，标志着向实用化MLLMs在具身AI中的应用迈进了一步。项目页面：https://flame-sjtu.github.io**|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|由于突发的性能提升，大型语言模型（LLMs）已被用作基于语言的智能体，以执行各种任务并展现出越来越高的自主决策能力。这些自主智能体能够理解高级指令，与环境互动，并利用一系列可用工具执行复杂任务。随着智能体能力的扩展，确保其安全性和可信度变得尤为重要。本研究中，我们引入了Athena框架，该框架利用了言语对比学习的概念，即利用过去安全和不安全的行为轨迹作为上下文（对比）示例，引导智能体在完成指定任务的同时趋向安全操作。此外，框架还融入了一个评判机制，以便在每一步操作中指导智能体避免风险行为。鉴于目前缺乏针对基于LLM智能体安全推理能力的评估基准，我们特别编制了一套包含8个类别、180个场景的80个工具包集合，作为安全评估的基准数据集。我们的实验评估，涵盖了封闭源和开源的LLMs，表明言语对比学习及交互层面的评判机制能显著提高安全执行率。|
|**2024-08-19**|**IDEA: Enhancing the rule learning ability of language agent through Induction, DEuction, and Abduction**|Kaiyu He et.al.|[2408.10455](http://arxiv.org/abs/2408.10455)|null|尽管大型语言模型（LLMs）在演绎和归纳推理方面的评估已经相当全面，但它们在互动环境中进行溯因推理与整体规则学习的能力探索尚不充分。本研究引入了一项名为RULEARN的新基准，专门用于评估LLMs在交互式场景中的规则学习能力。在RULEARN中，代理通过与环境互动收集观察并识别模式，利用这些洞察解决问题。为了进一步提升LLMs在这一基准中的规则学习能力，我们提出了IDEA代理，它融合了归纳、演绎及溯因过程。IDEA代理通过采用一种结构化的推理序列来优化此方法：通过溯因生成假设，借助演绎进行测试，并根据归纳反馈进行精炼。这一序列使代理能够动态建立并应用规则，模拟人类类似的推理过程。我们对五种代表性LLMs的评估显示，虽然这些模型能生成貌似合理的初始假设，但它们在环境中的策略性互动、有效整合反馈以及假设的适应性细化方面往往面临挑战。IDEA代理在RULEARN基准上展示了显著的性能提升，为开发在现实世界场景中能够进行类似人类规则学习的代理提供了宝贵见解。我们将公开代码和数据。|
|**2024-08-20**|**MegaAgent: A Practical Framework for Autonomous Cooperation in Large-Scale LLM Agent Systems**|Qian Wang et.al.|[2408.09955](http://arxiv.org/abs/2408.09955)|null|随着大型语言模型（LLMs）的兴起，基于LLM的多智能体系统（LLM-MA系统）被提出以应对现实任务。然而，这些系统的智能体大多遵循预先定义的标准操作程序（SOPs），在交互过程中保持不变，缺乏自主性和可扩展性。此外，当前解决方案往往忽视了有效智能体协作的必要性。为了解决上述局限性，我们提出了MegaAgent框架，一个专为大规模LLM智能体系统中自主协作设计的实用框架。MegaAgent利用智能体的自主性，根据任务需求动态生成智能体，融入了自动任务划分、系统化规划与监控智能体活动以及管理并发操作等功能。此外，MegaAgent采用层次化结构设计，并利用系统级并行性来增强性能和促进通信。我们通过五子棋游戏开发演示了MegaAgent的有效性，表明其性能超越了流行的LLM-MA系统；以及通过国家政策模拟，展示了其高度自主性及快速扩容至590个智能体的能力，同时确保它们之间的有效协作。我们的结果表明，MegaAgent是首个无预设SOP、具备高效性和高度可扩展性的自主大规模LLM-MA系统，为该领域的进一步研究铺平了道路。我们的代码位于https://anonymous.4open.science/r/MegaAgent-81F3。|
|**2024-08-19**|**GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making**|Arsham Gholamzadeh Khoee et.al.|[2408.09785](http://arxiv.org/abs/2408.09785)|null|在汽车行业中，传统的软件部署决策方法通常依赖于手动分析软件测试的表格数据。这些方法因其劳动密集型的特点，往往导致成本增加和软件发布周期的延迟。大型语言模型（LLMs）为解决这些挑战提供了有前景的方案。然而，它们的应用通常需要多轮人为驱动的提示工程，这限制了它们的实际部署，特别是对于需要可靠且高效结果的工业终端用户而言。在本文中，我们提出了GoNoGo，一个旨在简化汽车软件部署流程的同时满足功能需求和实际工业约束的LLM代理系统。与以往系统不同，GoNoGo特别针对领域特定和风险敏感系统进行了定制。我们利用来自工业实践的零样本和少量样本，对GoNoGo在不同任务难度下的性能进行了评估。结果显示，GoNoGo在使用3个样本的情况下，对于难度达到第2级的任务实现了100%的成功率，并且即使面对更复杂的任务，其表现依然保持在高水平。我们发现，GoNoGo能有效自动化简单任务的决策过程，大幅减少了人工干预的需求。总之，GoNoGo是一个高效且用户友好的基于LLM的解决方案，目前已被我们的工业合作伙伴公司采用，以辅助进行软件发布决策，支持对风险敏感的车辆系统发布流程做出更为明智且及时的决策。|
|**2024-08-18**|**HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agent Tasks with Large Language Model**|Mengkang Hu et.al.|[2408.09559](http://arxiv.org/abs/2408.09559)|**[link](https://github.com/hiagent2024/hiagent)**|**基于大型语言模型（LLM）的智能体在众多领域展现出巨大潜力，它们作为交互系统运作，处理环境观测以生成针对目标任务的可执行动作。这些智能体的有效性在很大程度上取决于其记忆机制，该机制将历史经验记录为动作-观察对的序列。记忆可分为两类：跨试次记忆，横跨多次尝试累积；以及试次内记忆（工作记忆），在单次尝试中累积。尽管大量研究已通过优化跨试次记忆来提升性能，但通过改进工作记忆的利用以增强智能体性能的研究尚不充分。现有方法常常涉及将整个历史动作-观察对直接输入到LLMs中，这在长 horizon 任务中导致了冗余。受人类问题解决策略启发，本论文引入了HiAgent框架，它利用子目标作为记忆块以层次化管理LLM智能体的工作记忆。具体而言，HiAgent引导LLMs在生成可执行动作前先制定子目标，并使LLMs能够主动决定用总结过的观察来替换先前的子目标，仅保留与当前子目标相关的动作-观察对。跨五个长 horizon 任务的实验结果表明，HiAgent成功率提高了两倍，并将所需的平均步数减少了3.8步。此外，我们的分析显示，HiAgent在不同步骤上持续改善性能，彰显了其稳定性和泛化能力。项目页面：https://github.com/HiAgent2024/HiAgent 。**|
|**2024-08-15**|**EmBARDiment: an Embodied AI Agent for Productivity in XR**|Riccardo Bovo et.al.|[2408.08158](http://arxiv.org/abs/2408.08158)|null|XR设备搭载由大型语言模型（LLMs）驱动的聊天机器人，在作为始终在线的代理以实现更高效生产力场景方面具有巨大潜力。然而，基于屏幕的聊天机器人并未充分利用XR环境中可用的全套自然输入方式，包括向内感应的传感器数据，而是过度依赖明确的语音或文本指令，有时会辅以查询中附带的多模态数据。我们提出了一种解决方案，该方案利用注意力框架，从用户行为、眼动追踪以及XR环境中的上下文记忆中隐式提取情境。这最大限度地减少了对人工设计的明确提示的依赖，促进了基于现实情境且直观的交互，为聊天机器人提供了洞察用户意图的途径。用户研究表明，我们的方法能够显著提升XR中与聊天机器人的交互效率，并展现出为未来XR融合型LLM代理设计提供的变革性潜力。|
|**2024-08-15**|**Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework**|Changyu Du et.al.|[2408.08054](http://arxiv.org/abs/2408.08054)|null|在传统的BIM（建筑信息模型）创建过程中，设计者往往需要掌握复杂且繁琐的建模命令，以便在BIM创作工具中实现其设计意图。这种额外的认知负担使得设计过程复杂化，并阻碍了AEC（建筑、工程和施工）行业中BIM及基于模型设计的应用推广。为更直观地表达设计意图，我们提出了Text2BIM框架，这是一个基于大型语言模型（LLM）的多智能体系统，能够根据自然语言指令生成三维建筑模型。该框架协调多个LLM智能体进行协作和推理，将用户的文本输入转化为调用BIM创作工具API的指令性代码，直接在软件中生成带有内部布局、外部围护结构及语义信息的可编辑BIM模型。此外，我们还在智能体工作流程中融入了基于规则的模型检查器，利用预定义的领域知识指导LLM智能体识别并解决生成模型中的问题，从而迭代提升模型质量。通过大量实验，我们对比分析了三种不同LLM在所提框架下的性能。评估结果显示，我们的方法能有效生成高质量、结构合理的建筑模型，这些模型与用户输入的抽象概念保持一致。最后，我们开发了一个交互式软件原型，将此框架集成到BIM创作软件Vectorworks中，通过“聊天式”建模展示了该框架的潜力。|
|**2024-08-13**|**Agent Q: Advanced Reasoning and Learning for Autonomous AI Agents**|Pranav Putta et.al.|[2408.07199](http://arxiv.org/abs/2408.07199)|null|
|**2024-08-13**|**Diversity Empowers Intelligence: Integrating Expertise of Software Engineering Agents**|Kexun Zhang et.al.|[2408.07060](http://arxiv.org/abs/2408.07060)|null|
|**2024-08-12**|**Hierarchical in-Context Reinforcement Learning with Hindsight Modular Reflections for Planning**|Chuanneng Sun et.al.|[2408.06520](http://arxiv.org/abs/2408.06520)|null|
|**2024-08-12**|**Can We Rely on LLM Agents to Draft Long-Horizon Plans? Let's Take TravelPlanner as an Example**|Yanan Chen et.al.|[2408.06318](http://arxiv.org/abs/2408.06318)|null|
|**2024-08-13**|**DataNarrative: Automated Data-Driven Storytelling with Visualizations and Texts**|Mohammed Saidul Islam et.al.|[2408.05346](http://arxiv.org/abs/2408.05346)|null|
|**2024-08-08**|**Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions**|Qingbin Zeng et.al.|[2408.04168](http://arxiv.org/abs/2408.04168)|**[link](https://github.com/hiyouga/llama-factory)**|
|**2024-08-11**|**CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases**|Xiangyan Liu et.al.|[2408.03910](http://arxiv.org/abs/2408.03910)|**[link](https://github.com/modelscope/modelscope-agent)**|
|**2024-08-07**|**Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent**|Yanhu Wang et.al.|[2408.03631](http://arxiv.org/abs/2408.03631)|null|
|**2024-08-05**|**Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information**|Yauwai Yim et.al.|[2408.02559](http://arxiv.org/abs/2408.02559)|null|
|**2024-08-05**|**From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future**|Haolin Jin et.al.|[2408.02479](http://arxiv.org/abs/2408.02479)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## llm

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-23**|**DOMAINEVAL: An Auto-Constructed Benchmark for Multi-Domain Code Generation**|Qiming Zhu et.al.|[2408.13204](http://arxiv.org/abs/2408.13204)|null|代码基准测试，如HumanEval，被广泛用于评估大型语言模型（LLMs）的能力，揭示了它们在编程任务上的优势和劣势。然而，当前的基准测试主要集中在常见的编码任务上（例如，冒泡排序、最大公约数），而对于领域特定的编码任务（如计算、系统、加密）则鲜有涉及。为了填补这一空白，我们提出了一个多领域的代码基准测试DOMAINEVAL，旨在全面评估LLMs的编码能力。我们的流程完全自动化，能够从代码仓库到待研究主题的格式化构建实现自下而上的推送构造。通过使用DOMAINEVAL对12个代表性的LLMs进行评估，我们发现了一些有趣的现象。我们注意到，LLMs通常擅长于计算任务，但在加密和系统编码任务上表现欠佳。某些LLMs之间的性能差距可能高达68.94%（80.94% - 12.0%）。此外，我们还观察到生成更多样本可以提升LLMs的整体性能，但领域偏见甚至可能会加剧。本研究的贡献包括：一个涵盖六个流行领域的代码生成基准数据集DOMAINEVAL、一个用于构建代码基准的全自动化管道，以及基于LLMs在DOMAINEVAL上的表现，识别出它们在代码生成任务中的局限性，为未来的研究改进指明了方向。排行榜可访问https://domaineval.github.io/。|
|**2024-08-23**|**Can LLM be a Good Path Planner based on Prompt Engineering? Mitigating the Hallucination for Path Planning**|Hourui Deng et.al.|[2408.13184](http://arxiv.org/abs/2408.13184)|null|在大型语言模型（LLMs）中，空间推理是实现具身智能的基础。然而，即使在简单的迷宫环境中，LLMs在长期路径规划方面仍面临挑战，这主要受到空间幻觉和由长期推理引起的情境不一致性幻觉的影响。为了解决这一挑战，本研究提出了一种创新模型——空间到关系转换与课程Q学习（S2RCQL）。针对LLMs的空间幻觉问题，我们提出了空间到关系的转化方法，该方法将空间提示转化为实体关系及代表实体关系链的路径，充分利用LLMs在序列思维方面的潜力。基于此，我们设计了一种基于Q学习的路径规划算法来缓解情境不一致性幻觉，从而增强LLMs的推理能力。通过使用状态-动作的Q值作为提示的辅助信息，我们纠正了LLMs的幻觉，引导其学习最优路径。最后，我们提出了一种基于LLMs的反向课程学习技术，进一步减轻情境不一致性幻觉。通过降低任务难度，LLMs能够快速积累成功经验，并利用这些经验解决更复杂的任务。我们在百度自主研发的LLM：ERNIE-Bot 4.0上进行了全面的实验。结果表明，我们的S2RCQL在成功率和最优率上相比先进的提示工程方法取得了23%至40%的提升。|
|**2024-08-23**|**IntelliCare: Improving Healthcare Analysis with Variance-Controlled Patient-Level Knowledge from Large Language Models**|Zhihao Yu et.al.|[2408.13073](http://arxiv.org/abs/2408.13073)|null|在电子健康记录（EHR）数据分析领域，尽管开创性的深度学习方法已取得重大进展，但它们往往难以仅凭有限数据全面捕捉多样化的医疗编码语义。将大型语言模型（LLMs）的外部知识融入其中，为提升医疗保健预测的准确性提供了有前景的途径。然而，LLM分析可能因模糊性问题和一致性问题而表现出显著的变异性，阻碍了它们的有效利用。为应对这些挑战，我们提出了IntelliCare这一创新框架，它利用LLMs提供高质量的患者级外部知识，以增强现有的EHR模型。具体而言，IntelliCare通过识别患者群体并运用与任务相关的统计信息来增强LLM的理解和生成能力，有效缓解了模糊性问题。此外，它还通过混合方法细化LLM衍生的知识，生成多种分析，并利用EHR模型及困惑度指标进行校准。在两个大规模EHR数据集上的三项临床预测任务的实验评估显示，IntelliCare为现有方法带来了显著的性能提升，彰显了其在推进个性化医疗预测和决策支持系统方面的潜力。|
|**2024-08-23**|**Guiding IoT-Based Healthcare Alert Systems with Large Language Models**|Yulan Gao et.al.|[2408.13071](http://arxiv.org/abs/2408.13071)|null|医疗警报系统（HAS）正在经历快速演变，这一发展得益于人工智能（AI）、物联网（IoT）技术的进步以及人们对健康日益增长的关注。尽管取得了显著进展，但一个根本性挑战仍然存在：在资源受限的HAS环境中，如何平衡个性化健康警报的准确性与严格的数据隐私保护。为了解决这一问题，我们引入了一个统一框架LLM-HAS，该框架将大型语言模型（LLM）融入HAS，极大地提高了警报的准确性，确保了用户隐私，并增强了个性化的健康服务，同时改善了用户的主观体验质量（QoE）。我们的创新框架利用混合专家（MoE）方法，结合LLM，分析用户的个性化偏好及从附加文本工作描述中识别出的潜在健康风险。这一分析指导了深度强化学习（DDPG）专家的选择，这些专家负责发出精确的健康警报。此外，LLM-HAS还能处理对话式用户反馈，这不仅使得DDPG得以微调，还加深了用户的参与度，从而提升了健康管理策略的准确性和个性化程度。仿真结果验证了LLM-HAS框架的有效性，突显了其作为利用生成式AI（GAI）提供高度准确和可靠的警报的开创性方法的潜力。|
|**2024-08-23**|**In-Context Learning with Reinforcement Learning for Incomplete Utterance Rewriting**|Haowei Du et.al.|[2408.13028](http://arxiv.org/abs/2408.13028)|null|在大规模语言模型（LLMs）领域，基于上下文的学习（ICL）日益受到关注，其中LLMs仅根据附有少量示例的指令做出预测。针对ICL的现有示例选择方法利用稀疏或密集检索器并展现出有效性能，但这些方法并未利用LLM的直接反馈来训练检索器，所选示例未必能提升LLM的类比能力。为解决这一问题，我们提出了一种针对示例选择的基于策略的强化学习框架（RLS），该框架包含一个语言模型（LM）选择器和一个LLM生成器。LM选择器将候选示例编码为密集表示，并挑选出排名前k的示例加入到演示中供LLM使用。LLM的输出被用来计算奖励和策略梯度，以优化LM选择器。我们在不同数据集上进行了实验，显著超越了现有的示例选择方法。此外，我们的方法在少量样本设置下相较于监督微调（SFT）模型显示出了优势。进一步的实验表明，示例的丰富性与与测试案例的相似性之间的平衡对于LLM的ICL性能至关重要。|
|**2024-08-23**|**Systematic Evaluation of LLM-as-a-Judge in LLM Alignment Tasks: Explainable Metrics and Diverse Prompt Templates**|Hui Wei et.al.|[2408.13006](http://arxiv.org/abs/2408.13006)|null|在对大型语言模型（LLMs）进行对齐的过程中，诸如RLHF和DPO之类的对齐方法正在积极研究中，以使这些模型与人类偏好保持一致。最近，像GPT-4这样的商业大型语言模型已被用来评估和比较不同的LLM对齐方法。由于这些模型在快速反馈和低成本的情况下能有希望地逼近人类偏好，它们充当了人类评价者的替代品，这种方法被称为LLM作为评判者（LLM-as-a-judge）。然而，对其可靠性的担忧逐渐浮现，主要归因于LLM评判者的偏见及决策不一致性。以往的研究努力开发了强大的评估框架来检验LLM评判者的可靠性及其与人类偏好的一致性，但所采用的评估指标往往缺乏足够的可解释性，并且未能解决LLM内部不一致性的问题。此外，现有研究在应用LLM-as-a-judge方法时，未能充分探索不同提示模板的影响，这可能导致在比较不同对齐算法时出现不一致的结果。本工作中，我们通过定义具有更强理论可解释性的评估指标，并拆分出与LLM内部不一致性相关的可靠性指标，系统性地评估了LLM评判者在对齐任务（如摘要生成）中的表现。我们构建了一个框架来评估、比较并可视化LLM评判者的可靠性和与人类评价者的一致性，提供了有助于选择适合对齐任务的LLM评判者的有启发性观察。我们的结果显示，提示模板对LLM评判者的表现有显著影响，并且测试的LLM评判者与人类评价者之间的一致性水平仅处于中等程度。|
|**2024-08-23**|**CRUXEval-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution**|Ruiyang Xu et.al.|[2408.13001](http://arxiv.org/abs/2408.13001)|null|代码基准测试，如HumanEval，被广泛用于评估大型语言模型（LLMs）的编码能力。然而，现有的代码基准测试存在显著的编程语言偏见——超过95%的代码生成基准测试主要以Python为主，使得LLMs在Java、C/C++等其他编程语言中的能力尚不明确。此外，编码任务偏见也是一个关键问题。大多数基准集中于代码生成能力的评估，而针对代码推理（给定输入推理输出；给定输出推理输入）这一重要编码能力的基准测试则相对不足。然而，构建多语言基准测试可能既昂贵又劳动密集型，并且从竞赛网站（如LeetCode）获取的代码在训练过程中容易受到数据污染的问题。为了填补这一空白，我们提出了CRUXEVAL-X，一个包含19种编程语言的多语言代码推理基准。它每种语言至少包含600个主题，总共有19000个内容一致的测试用例。特别是，CRUXEVAL-X的构建流程采用全自动和测试引导的方式，通过迭代生成和基于执行反馈的修复来进行。此外，为了跨越语言障碍（例如，Python/C++中的动态/静态类型系统），我们制定了不同语言对之间的转换规则以促进翻译。我们对24个代表性的LLMs进行的深入评估揭示了语言对之间的相关性。例如，TypeScript和JavaScript显示出显著的正相关性，而Racket与其他语言的相关性较小。更有趣的是，即使是一个仅在Python上训练的模型，在其他语言中最多也能达到34.4%的一次通过率，这揭示了LLMs的跨语言泛化能力。|
|**2024-08-23**|**Open Llama2 Model for the Lithuanian Language**|Artūras Nakvosas et.al.|[2408.12963](http://arxiv.org/abs/2408.12963)|null|在本文中，我们提出并描述了首个针对立陶宛语的开源大语言模型（LLMs）——Llama2，同时发布了配套的问答（Q/A）数据集及流行LLM基准测试的立陶宛语翻译。我们简要回顾了开放区域LLMs，并详细介绍了所提议的LLMs及其训练过程。此外，我们还进行了实证评估，比较了所提LLMs与其他现代开源LLMs的困惑度。通过将所提LLMs置于语言理解任务的基准测试中，我们发现高质量的预训练数据集对于模型在这些基准上高效表现至关重要。所述LLMs的完整实现可在伴随的开源仓库\url{https://huggingface.co/neurotechnology}中获得。|
|**2024-08-23**|**Multimodal Contrastive In-Context Learning**|Yosuke Miyanishi et.al.|[2408.12959](http://arxiv.org/abs/2408.12959)|null|大型语言模型（LLMs）的迅速发展凸显了梯度自由的即时学习（ICL）方法的重要性，但理解其内部工作机制仍具挑战性。本论文提出了一种新颖的多模态对比即时学习框架，旨在加深对LLMs中ICL机制的理解。首先，我们介绍了一种基于对比学习的ICL解释方法，该方法在现实世界场景下运作，关键-值表示的距离被标记为ICL中的区别因素。其次，我们构建了一个分析框架来应对真实世界数据集多模态输入格式中的偏见问题，展示了即使在未见过的格式下，ICL示例也能在基线性能较差的情况下发挥作用。最后，我们提出了一种针对ICL的在线处理方法（以文本为中心的ICL），该方法在识别仇恨性模因这一任务上表现出有效性，传统ICL在此类任务上因资源限制而面临困难。在多模态数据集上的广泛实验表明，我们的方法显著提高了在不同情境下的ICL性能，包括挑战性任务和资源受限环境。此外，它也为理解LLMs中即时学习的机制提供了宝贵见解。我们的研究发现对于开发更可解释、高效和鲁棒的多模态AI系统具有重要意义，特别是在面对挑战性任务和资源有限环境时。|
|**2024-08-23**|**E-code: Mastering Efficient Code Generation through Pretrained Models and Expert Encoder Group**|Yue Pan et.al.|[2408.12948](http://arxiv.org/abs/2408.12948)|null|随着摩尔定律的减弱，软件行业越来越重视寻找持续性能提升的替代方案。近年来，软件性能优化的重要性和研究成果不断增加，特别是大型语言模型（LLMs）推动的进展。然而，传统的性能缺陷修正策略在竞争激烈的代码效率优化层面显现出重大局限性，针对这一主题的研究出乎意料地稀少。目标：本研究旨在填补该领域的研究空白，为遇到的各种挑战提供实际解决方案。具体而言，我们克服了传统性能优化策略的限制，并为竞争性的代码效率优化领域开发了一种定制的语言模型（LM）。方法：我们引入了E-code，一种先进的程序合成LM。受到近期专家LM成功的启发，我们设计了一种创新结构——专家编码器组。该结构利用多个专家编码器来提取针对不同输入类型量身定做的特征。我们在一个竞争性数据集上评估了E-code与其他领先模型的性能，并进行了深入的消融实验。结果：经过系统评估，E-code在代码效率方面实现了54.98%的提升，显著优于其他先进模型。在消融实验中，我们进一步验证了专家编码器组及其他E-code组件的重要性。结论：研究结果表明，专家编码器组能有效处理效率优化任务中的各种输入，极大地提高了模型的性能。|
|**2024-08-22**|**Controllable Text Generation for Large Language Models: A Survey**|Xun Liang et.al.|[2408.12599](http://arxiv.org/abs/2408.12599)|**[link](https://github.com/iaar-shanghai/ctgsurvey)**|
|**2024-08-22**|**RuleAlign: Making Large Language Models Better Physicians with Diagnostic Rule Alignment**|Xiaohan Wang et.al.|[2408.12579](http://arxiv.org/abs/2408.12579)|null|
|**2024-08-22**|**Towards Evaluating and Building Versatile Large Language Models for Medicine**|Chaoyi Wu et.al.|[2408.12547](http://arxiv.org/abs/2408.12547)|**[link](https://github.com/magic-ai4med/meds-ins)**|
|**2024-08-22**|**MEDCO: Medical Education Copilots Based on A Multi-Agent Framework**|Hao Wei et.al.|[2408.12496](http://arxiv.org/abs/2408.12496)|null|
|**2024-08-22**|**GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models**|Kunsheng Tang et.al.|[2408.12494](http://arxiv.org/abs/2408.12494)|**[link](https://github.com/kstanghere/gendercare-ccs24)**|
|**2024-08-22**|**Frame Order Matters: A Temporal Sequence-Aware Model for Few-Shot Action Recognition**|Bozheng Li et.al.|[2408.12475](http://arxiv.org/abs/2408.12475)|null|
|**2024-08-22**|**DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender Systems**|Jiaju Chen et.al.|[2408.12470](http://arxiv.org/abs/2408.12470)|null|
|**2024-08-22**|**Envisioning Class Entity Reasoning by Large Language Models for Few-shot Learning**|Mushui Liu et.al.|[2408.12469](http://arxiv.org/abs/2408.12469)|null|
|**2024-08-22**|**Enhancing Multi-hop Reasoning through Knowledge Erasure in Large Language Model Editing**|Mengqi Zhang et.al.|[2408.12456](http://arxiv.org/abs/2408.12456)|null|
|**2024-08-22**|**A Comparative Analysis of Faithfulness Metrics and Humans in Citation Evaluation**|Weijia Zhang et.al.|[2408.12398](http://arxiv.org/abs/2408.12398)|null|
|**2024-08-21**|**SEA: Supervised Embedding Alignment for Token-Level Visual-Textual Integration in MLLMs**|Yuanyang Yin et.al.|[2408.11813](http://arxiv.org/abs/2408.11813)|null|
|**2024-08-21**|**Story3D-Agent: Exploring 3D Storytelling Visualization with Large Language Models**|Yuzhou Huang et.al.|[2408.11801](http://arxiv.org/abs/2408.11801)|null|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800](http://arxiv.org/abs/2408.11800)|null|
|**2024-08-21**|**EE-MLLM: A Data-Efficient and Compute-Efficient Multimodal Large Language Model**|Feipeng Ma et.al.|[2408.11795](http://arxiv.org/abs/2408.11795)|null|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793](http://arxiv.org/abs/2408.11793)|null|
|**2024-08-21**|**Critique-out-Loud Reward Models**|Zachary Ankner et.al.|[2408.11791](http://arxiv.org/abs/2408.11791)|**[link](https://github.com/zankner/cloud)**|
|**2024-08-21**|**Personality Alignment of Large Language Models**|Minjun Zhu et.al.|[2408.11779](http://arxiv.org/abs/2408.11779)|**[link](https://github.com/zhu-minjun/palign)**|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775](http://arxiv.org/abs/2408.11775)|**[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)**|
|**2024-08-21**|**Against All Odds: Overcoming Typology, Script, and Language Confusion in Multilingual Embedding Inversion Attacks**|Yiyi Chen et.al.|[2408.11749](http://arxiv.org/abs/2408.11749)|**[link](https://github.com/siebeniris/vec2text_exp)**|
|**2024-08-21**|**Mixed Sparsity Training: Achieving 4 $\times$ FLOP Reduction for Transformer Pretraining**|Pihe Hu et.al.|[2408.11746](http://arxiv.org/abs/2408.11746)|null|
|**2024-08-20**|**Revisiting VerilogEval: Newer LLMs, In-Context Learning, and Specification-to-RTL Tasks**|Nathaniel Pinckney et.al.|[2408.11053](http://arxiv.org/abs/2408.11053)|**[link](https://github.com/nvlabs/verilog-eval)**|
|**2024-08-20**|**FLAME: Learning to Navigate with Multimodal LLM in Urban Environments**|Yunzhe Xu et.al.|[2408.11051](http://arxiv.org/abs/2408.11051)|**[link](https://github.com/xyz9911/FLAME)**|
|**2024-08-21**|**MagicDec: Breaking the Latency-Throughput Tradeoff for Long Context Generation with Speculative Decoding**|Jian Chen et.al.|[2408.11049](http://arxiv.org/abs/2408.11049)|**[link](https://github.com/infini-ai-lab/magicdec)**|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|
|**2024-08-20**|**Athena: Safe Autonomous Agents with Verbal Contrastive Learning**|Tanmana Sadhu et.al.|[2408.11021](http://arxiv.org/abs/2408.11021)|null|
|**2024-08-20**|**While GitHub Copilot Excels at Coding, Does It Ensure Responsible Output?**|Wen Cheng et.al.|[2408.11006](http://arxiv.org/abs/2408.11006)|**[link](https://github.com/sensente/security-attacks-on-lccts)**|
|**2024-08-20**|**CTP-LLM: Clinical Trial Phase Transition Prediction Using Large Language Models**|Michael Reinisch et.al.|[2408.10995](http://arxiv.org/abs/2408.10995)|null|
|**2024-08-20**|**Dr.Academy: A Benchmark for Evaluating Questioning Capability in Education for Large Language Models**|Yuyan Chen et.al.|[2408.10947](http://arxiv.org/abs/2408.10947)|null|
|**2024-08-20**|**HiRED: Attention-Guided Token Dropping for Efficient Inference of High-Resolution Vision-Language Models in Resource-Constrained Environments**|Kazi Hasan Ibn Arif et.al.|[2408.10945](http://arxiv.org/abs/2408.10945)|**[link](https://github.com/hasanar1f/hired)**|
|**2024-08-20**|**SysBench: Can Large Language Models Follow System Messages?**|Yanzhao Qin et.al.|[2408.10943](http://arxiv.org/abs/2408.10943)|**[link](https://github.com/pku-baichuan-mlsystemlab/sysbench)**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-20**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Ling He et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-19**|**Edge-Cloud Collaborative Motion Planning for Autonomous Driving with Large Language Models**|Jiao Chen et.al.|[2408.09972](http://arxiv.org/abs/2408.09972)|null|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**Visual Agents as Fast and Slow Thinkers**|Guangyan Sun et.al.|[2408.08862](http://arxiv.org/abs/2408.08862)|null|
|**2024-08-16**|**ECG-Chat: A Large ECG-Language Model for Cardiac Disease Diagnosis**|Yubao Zhao et.al.|[2408.08849](http://arxiv.org/abs/2408.08849)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-05-16**|**When LLMs step into the 3D World: A Survey and Meta-Analysis of 3D Tasks via Multi-modal Large Language Models**|Xianzheng Ma et.al.|[2405.10255](http://arxiv.org/abs/2405.10255)|**[link](https://github.com/activevisionlab/awesome-llm-3d)**|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## Wireless Network

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Optimizing UAV Trajectory for Emergency Response Operations under Real 3D Environments: Integrating Priority Levels and LoS Constraints**|Mohammad Taghi Dabiri et.al.|[2408.07589](http://arxiv.org/abs/2408.07589)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## Wireless Communications

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Intra-symbol Differential Amplitude Shift Keying-aided Blind Detector for Ambient Backscatter Communication Systems**|Shuaijun Ma et.al.|[2408.08833](http://arxiv.org/abs/2408.08833)|null|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**Xpikeformer: Hybrid Analog-Digital Hardware Acceleration for Spiking Transformers**|Zihang Song et.al.|[2408.08794](http://arxiv.org/abs/2408.08794)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## Wireless Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-19**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-15**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-15**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-15**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## Communication Intelligence

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**On the Parameter Selection of Phase-transmittance Radial Basis Function Neural Networks for Communication Systems**|Jonathan A. Soares et.al.|[2408.07692](http://arxiv.org/abs/2408.07692)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-04-02**|**LLM-ABR: Designing Adaptive Bitrate Algorithms via Large Language Models**|Zhiyuan He et.al.|[2404.01617](http://arxiv.org/abs/2404.01617)|null|我们介绍了LLM-ABR系统，这是首个利用大型语言模型（LLMs）的生成能力来自行设计适应性比特率（ABR）算法的系统，旨在满足多样的网络特性需求。LLM-ABR在强化学习框架内运作，使LLMs能够设计出如状态表示和神经网络架构等关键组件。我们针对宽带、卫星、4G及5G等多种网络环境对LLM-ABR进行了评估。结果显示，LLM-ABR持续超越默认的ABR算法性能。|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## RAG

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-22**|**Graph Retrieval Augmented Trustworthiness Reasoning**|Ying Zhu et.al.|[2408.12333](http://arxiv.org/abs/2408.12333)|**[link](https://github.com/EvoNexusX/Graph-Retrieval-Augmented-Trustworthiness-Reasoning)**|**在信息不完全的多人游戏中，信任推理至关重要，它使代理能够识别潜在的盟友和对手，从而加强推理和决策过程。传统方法依赖于预训练模型，需要大量的领域特定数据及可观的奖励反馈，且其缺乏实时适应性限制了在动态环境中的有效性。本文引入了图检索增强推理（GRATR）框架，利用检索增强生成（RAG）技术来加强代理的信任推理能力。GRATR构建了一个动态的信任图，实时更新包含证据信息，并检索相关信任数据以增强大型语言模型（LLMs）的推理能力。我们通过在多人游戏“狼人杀”上的实验验证了我们的方法，将GRATR与基线LLM以及配备了原生RAG和重排RAG的LLM进行对比。结果显示，GRATR在胜率上超过基线方法30%以上，展现出更优越的推理性能。此外，GRATR有效缓解了LLM的幻觉问题，如身份遗忘和目标遗忘，并且通过使用信任图，使得推理过程更加透明和可追溯。**|
|**2024-08-22**|**LLMs are not Zero-Shot Reasoners for Biomedical Information Extraction**|Aishik Nagar et.al.|[2408.12249](http://arxiv.org/abs/2408.12249)|null|大型语言模型（LLMs）在医疗领域的应用日益增多，它们在问答和文档摘要等任务上已达到领域专家的性能水平。尽管在这些任务上取得了成功，LLMs在传统生物医学领域所追求的任务，如结构化信息提取上的表现仍不明确。为了缩小这一差距，本文系统性地评估了LLMs在医疗分类和命名实体识别（NER）任务中的性能。我们的目标是剖析不同因素对性能的贡献，特别是LLMs的任务知识与推理能力、其（参数化的）领域知识以及外部知识附加的影响。因此，我们采用了多种开放的LLMs——包括BioMistral和Llama-2模型——在一个多样化的生物医学数据集上进行评估，使用了标准提示、Chain-of-Thought (CoT)和自我一致性推理方法，以及结合PubMed和Wikipedia文献的检索增强生成（RAG）。出乎意料的是，我们的结果显示，标准提示法在两项任务中持续优于更复杂的技巧，这揭示了当前CoT、自我一致性和RAG在生物医学领域应用的局限性。研究发现表明，为知识密集型或推理密集型任务开发的先进提示方法，如CoT或RAG，并不易于移植到需要精确结构化输出的生物医学任务中。这强调了为了提升LLMs在实际生物医学应用中的性能，需更有效地整合外部知识和推理机制的必要性。|
|**2024-08-22**|**Evidence-backed Fact Checking using RAG and Few-Shot In-Context Learning with LLMs**|Ronit Singhal et.al.|[2408.12060](http://arxiv.org/abs/2408.12060)|null|在社交媒体上错误信息的广泛传播背景下，对网络言论进行事实核查变得至关重要。手动验证每条言论极为困难，突显出自动化事实核查系统的需求。本文介绍了一个旨在解决该问题的系统。我们利用Averitec数据集来评估声明的真实性。除了真实性预测外，我们的系统还提供支持证据，这些证据从数据集中提取而来。我们开发了一个检索与生成（RAG）流程，从知识库中抽取与声明相关的证据句子，然后将这些句子与声明一起输入大型语言模型（LLM）进行分类。同时，我们也评估了多种LLM的少量样本在上下文学习（ICL）中的能力。我们的系统实现了0.33的'Averitec'评分，相较于基线有22%的绝对提升。所有代码将在https://github.com/ronit-singhal/evidence-backed-fact-checking-using-rag-and-few-shot-in-context-learning-with-llms 公开源码。|
|**2024-08-21**|**RAG-Optimized Tibetan Tourism LLMs: Enhancing Accuracy and Personalization**|Jinhu Qi et.al.|[2408.12003](http://arxiv.org/abs/2408.12003)|null|随着现代社会经济的发展，旅游已成为满足人们精神需求的重要方式，为旅游业带来了发展机遇。然而，现有的大型语言模型（LLMs）在个性化推荐能力方面面临挑战，并且在内容生成时有时会产生虚假现象。本研究针对西藏旅游LLMs提出了一种基于检索增强生成（RAG）技术的优化方案。通过构建旅游景点数据库并利用向量化技术处理数据，显著提高了检索准确性。RAG技术的应用有效解决了内容生成中的虚假问题。优化后的模型在内容生成的流畅性、准确性和相关性方面表现出显著提升。该研究展示了RAG技术在文化旅游信息标准化及数据分析方面的潜力，为智能文化旅游服务系统的发展提供了理论与技术支持。|
|**2024-08-23**|**Ancient Wisdom, Modern Tools: Exploring Retrieval-Augmented LLMs for Ancient Indian Philosophy**|Priyanka Mandikal et.al.|[2408.11903](http://arxiv.org/abs/2408.11903)|**[link](https://github.com/priyankamandikal/vedantany-10m)**|**大型语言模型（LLMs）已经彻底改变了信息检索和知识传播的格局。然而，在特定领域应用时，由于事实错误和虚构现象的出现，特别是在长尾知识分布中，它们的应用常受到阻碍。我们探索了在专业领域长篇问答（LFQA）中使用检索增强生成（RAG）模型的潜力。我们提出了VedantaNY-10M数据集，该数据集从关于古印度哲学“Advaita Vedanta”的大量公开论述中精心整理而成。我们开发并基准测试了一个RAG模型，与标准非RAG LLM相比，特别关注于转录、检索和生成性能。计算语言学家和领域专家的人工评估显示，RAG模型在产生事实准确且内容全面、虚构较少的回答方面显著优于标准模型。此外，强调独特低频词汇的关键词混合检索器进一步提升了结果。我们的研究为现代大型语言模型与古老知识体系的有效整合提供了洞见。项目页面含数据集和代码：https://sites.google.com/view/vedantany-10m**|
|**2024-08-21**|**PermitQA: A Benchmark for Retrieval Augmented Generation in Wind Siting and Permitting domain**|Rounak Meyur et.al.|[2408.11800](http://arxiv.org/abs/2408.11800)|null|在自然语言处理（NLP）与文本生成领域日新月异的发展中，检索增强生成（RAG）的出现为通过利用从用户指定数据库中检索到的信息来提升生成文本的质量与可靠性提供了一条富有前景的道路。为了评估和比较不同RAG配置在检索器与生成器方面的性能，基准测试至关重要，它能提供关于其有效性的洞见，以及针对特定领域及应用的可扩展性和适用性。本文提出了一套综合框架，用于生成领域相关的RAG基准。该框架基于自动问答生成，并采用人类（领域专家）与大型语言模型（LLM）协同的方式。作为案例研究，我们通过引入PermitQA演示了该框架，这是首个针对风力选址与许可领域的基准，包含多份与风能项目环境影响相关的科学文献/报告。我们的框架系统地使用多样化的指标和不同复杂度级别的多种问题类型来评估RAG的表现。同时，我们也展示了不同模型在该基准上的表现情况。|
|**2024-08-21**|**Leveraging Chemistry Foundation Models to Facilitate Structure Focused Retrieval Augmented Generation in Multi-Agent Workflows for Catalyst and Materials Design**|Nathaniel H. Park et.al.|[2408.11793](http://arxiv.org/abs/2408.11793)|null|分子性质预测与通过深度学习模型进行的生成设计已成为研究热点，因其有望加速新型高性能材料的开发。近期，大型语言模型（LLMs）及由LLM驱动的代理系统的发展显著增强了这些工作流程，使得预训练模型能够在更复杂的科研任务中进行预测。尽管成效显著，但在面向材料设计任务的信息检索中，代理系统仍有很大的改进空间。此外，利用预测性深度学习模型的潜在表示以促进跨模态检索增强生成，并在代理系统中实现任务特定的材料设计，这一替代用途尚未得到探索。本文展示大型预训练化学基础模型可作为基础，用于实现从小分子、复杂聚合物材料到反应的化学信息语义检索。同时，我们展示了化学基础模型与图像模型（如OpenCLIP）的结合使用，促进了跨多表征数据领域的前所未有的查询与信息检索能力。最后，我们展示了这些系统在多智能体系统中的集成，以支持基于结构和拓扑的自然语言查询及复杂研究任务中的信息检索。|
|**2024-08-21**|**Leveraging Fine-Tuned Retrieval-Augmented Generation with Long-Context Support: For 3GPP Standards**|Omar Erak et.al.|[2408.11775](http://arxiv.org/abs/2408.11775)|**[link](https://github.com/Nouf-Alabbasi/oKUmura_AI_Telecom_challenge)**|**最近的研究表明，大型语言模型（LLMs）在处理电信技术标准方面存在困难。我们提出了一种基于Phi-2小型语言模型（SLM）的微调检索增强生成（RAG）系统，用作通信网络的智囊。所开发的系统利用前瞻性的语义分块来自适应地根据嵌入相似性确定解析断点，从而有效地处理多样化的文档格式。针对技术标准中多类相似上下文的挑战，我们采用了一种重新排序算法来优先考虑最相关的检索到的片段。认识到Phi-2小模型上下文窗口的局限性，我们实施了一项名为SelfExtend的最新技术，在推理过程中扩展上下文窗口，这不仅提升了性能，还能适应更广泛的用户查询和从普通客户到专业技术人员的设计需求。在微调过程中，我们使用了低秩适应（LoRA）技术以提高训练期间的计算效率，并允许在小数据集上进行有效微调。我们的综合实验显示，在电信领域相对于现有问答方法有显著改进，达到了超越更大语言模型（如GPT-4，其大小约为Phi-2的880倍）的性能水平。本工作为利用SLM处理通信网络提供了一个新颖的方法，实现了效率与性能的平衡。此研究可作为迈向网络代理语言模型基础的重要一步。**|
|**2024-08-23**|**Xinyu: An Efficient LLM-based System for Commentary Generation**|Yiquan Wu et.al.|[2408.11609](http://arxiv.org/abs/2408.11609)|null|评论为读者提供了深入理解事件的途径，通过展示多样的观点和证据。然而，撰写评论是一项耗时的任务，即便是对于熟练的评论员也是如此。大型语言模型（LLMs）简化了自然语言生成的过程，但它们在评论生成中的直接应用仍面临挑战，这是由于任务的独特要求所致。这些要求可以分为两个层面：1）基本要求，包括构建结构良好、逻辑连贯的叙述；2）高级要求，涉及生成高质量的论点并提供有说服力的证据。在本文中，我们介绍了Xinyu，一个高效的基于LLM的系统，旨在辅助创建中文评论。为了满足基本要求，我们将生成过程分解为顺序步骤，针对每个步骤提出有针对性的策略并采用监督式微调（SFT）。为了解决高级要求，我们提出了一个论点排序模型来优化论点，并建立了包含最新事件和经典文献的综合证据数据库，利用检索增强生成（RAG）技术加强证据的支撑力度。为了更公正地评估生成的评论，我们对应两层要求引入了一个全面的评估指标，该指标从五个不同角度审视评论生成。实验结果证实了我们所提系统的有效性。在实际应用场景中，我们还观察到评论员的工作效率显著提升，平均创作一篇评论的时间从4小时缩短至20分钟。重要的是，这一效率的提升并未牺牲评论的质量。|
|**2024-08-23**|**A Quick, trustworthy spectral detection Q&A system based on the SDAAP Dataset and large language model**|Jiheng Liang et.al.|[2408.11557](http://arxiv.org/abs/2408.11557)|**[link](https://github.com/0217ljh/QA_System_For_Spectral_Analysis_With_SDAAP_Dataset)**|**大型语言模型（LLM）在广泛的自然语言处理（NLP）任务中展示了显著的成功，并已在自然科学等众多领域引入了创新方法。研究者旨在利用LLM实施自动化、并发的知识驱动过程，以替代传统的手动、重复及劳动密集型工作。在光谱分析与检测领域，研究人员迫切需要自主获取关于不同研究对象的关联知识，这包括实验与分析中采用的光谱学技术和化学计量学方法。然而，尽管光谱检测被公认为一种有效的分析手段，其基础知识的检索过程仍然既耗时又重复。  针对这一挑战，我们首先推出了光谱检测与分析文献（SDAAP）数据集，这是首个面向光谱分析与检测的开源文本知识数据集，包含了注解过的文献资料及相应的知识指导信息。随后，我们设计了一种基于SDAAP数据集的自动化问答框架，该框架能通过提取输入中的实体作为检索参数，检索相关知识并生成高质量的回答。值得注意的是，在此框架内，LLM仅作为一种工具提供泛化能力，而RAG技术则用于精确捕捉知识来源。这一方法不仅提升了生成回答的专业性，还确保了知识的可追溯性。实验结果表明，相比于基线，我们的框架生成了具有更高专业可信度的回答。**|
|**2024-08-21**|**RAGLAB: A Modular and Research-Oriented Unified Framework for Retrieval-Augmented Generation**|Xuanwang Zhang et.al.|[2408.11381](http://arxiv.org/abs/2408.11381)|**[link](https://github.com/fate-ubw/raglab)**|
|**2024-08-20**|**Reading with Intent**|Benjamin Reichman et.al.|[2408.11189](http://arxiv.org/abs/2408.11189)|null|
|**2024-08-20**|**Reconciling Methodological Paradigms: Employing Large Language Models as Novice Qualitative Research Assistants in Talent Management Research**|Sreyoshi Bhaduri et.al.|[2408.11043](http://arxiv.org/abs/2408.11043)|null|
|**2024-08-19**|**Enhanced document retrieval with topic embeddings**|Kavsar Huseynova et.al.|[2408.10435](http://arxiv.org/abs/2408.10435)|null|
|**2024-08-19**|**LegalBench-RAG: A Benchmark for Retrieval-Augmented Generation in the Legal Domain**|Nicholas Pipitone et.al.|[2408.10343](http://arxiv.org/abs/2408.10343)|**[link](https://github.com/zeroentropy-cc/legalbenchrag)**|
|**2024-08-19**|**Demystifying the Communication Characteristics for Distributed Transformer Models**|Quentin Anthony et.al.|[2408.10197](http://arxiv.org/abs/2408.10197)|null|
|**2024-08-19**|**Customizing Language Models with Instance-wise LoRA for Sequential Recommendation**|Xiaoyu Kong et.al.|[2408.10159](http://arxiv.org/abs/2408.10159)|null|
|**2024-08-19**|**Multilingual Needle in a Haystack: Investigating Long-Context Behavior of Multilingual Large Language Models**|Amey Hengle et.al.|[2408.10151](http://arxiv.org/abs/2408.10151)|**[link](https://github.com/AmeyHengle/multilingual-needle-in-a-haystack)**|
|**2024-08-19**|**Instruction Finetuning for Leaderboard Generation from Empirical AI Research**|Salomon Kabongo et.al.|[2408.10141](http://arxiv.org/abs/2408.10141)|null|
|**2024-08-19**|**Molecular Graph Representation Learning Integrating Large Language Models with Domain-specific Small Models**|Tianyu Zhang et.al.|[2408.10124](http://arxiv.org/abs/2408.10124)|**[link](https://github.com/zhangtia16/molgraph-lardo)**|
|**2024-08-19**|**ARMADA: Attribute-Based Multimodal Data Augmentation**|Xiaomeng Jin et.al.|[2408.10086](http://arxiv.org/abs/2408.10086)|null|
|**2024-08-19**|**Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory**|Haoran Li et.al.|[2408.10053](http://arxiv.org/abs/2408.10053)|null|
|**2024-08-19**|**MSDiagnosis: An EMR-based Dataset for Clinical Multi-Step Diagnosis**|Ruihui Hou et.al.|[2408.10039](http://arxiv.org/abs/2408.10039)|null|
|**2024-08-19**|**TBA: Faster Large Language Model Training Using SSD-Based Activation Offloading**|Kun Wu et.al.|[2408.10013](http://arxiv.org/abs/2408.10013)|null|
|**2024-08-19**|**Application of Large Language Models in Automated Question Generation: A Case Study on ChatGLM's Structured Questions for National Teacher Certification Exams**|Yanxin Chen et.al.|[2408.09982](http://arxiv.org/abs/2408.09982)|null|
|**2024-08-20**|**Carbon Footprint Accounting Driven by Large Language Models and Retrieval-augmented Generation**|Haijin Wang et.al.|[2408.09713](http://arxiv.org/abs/2408.09713)|null|
|**2024-08-17**|**Developing a Llama-Based Chatbot for CI/CD Question Answering: A Case Study at Ericsson**|Daksh Chaudhary et.al.|[2408.09277](http://arxiv.org/abs/2408.09277)|null|
|**2024-08-17**|**TC-RAG:Turing-Complete RAG's Case study on Medical LLM Systems**|Xinke Jiang et.al.|[2408.09199](http://arxiv.org/abs/2408.09199)|null|
|**2024-08-16**|**A Primer on Generative AI for Telecom: From Theory to Practice**|Xingqin Lin et.al.|[2408.09031](http://arxiv.org/abs/2408.09031)|null|
|**2024-08-16**|**Meta Knowledge for Retrieval Augmented Large Language Models**|Laurent Mombaerts et.al.|[2408.09017](http://arxiv.org/abs/2408.09017)|null|
|**2024-08-16**|**PEDAL: Enhancing Greedy Decoding with Large Language Models using Diverse Exemplars**|Sumanth Prabhu et.al.|[2408.08869](http://arxiv.org/abs/2408.08869)|null|
|**2024-08-16**|**PsychoLex: Unveiling the Psychological Mind of Large Language Models**|Mohammad Amin Abbasi et.al.|[2408.08848](http://arxiv.org/abs/2408.08848)|null|
|**2024-08-16**|**FLEXTAF: Enhancing Table Reasoning with Flexible Tabular Formats**|Xuanliang Zhang et.al.|[2408.08841](http://arxiv.org/abs/2408.08841)|**[link](https://github.com/zhxlia/FLEXTAF)**|
|**2024-08-16**|**Artificial Intelligence and Strategic Decision-Making: Evidence from Entrepreneurs and Investors**|Felipe A. Csaszar et.al.|[2408.08811](http://arxiv.org/abs/2408.08811)|null|
|**2024-08-16**|**Constructing Domain-Specific Evaluation Sets for LLM-as-a-judge**|Ravi Raju et.al.|[2408.08808](http://arxiv.org/abs/2408.08808)|null|
|**2024-08-16**|**EmoDynamiX: Emotional Support Dialogue Strategy Prediction by Modelling MiXed Emotions and Discourse Dynamics**|Chenwei Wan et.al.|[2408.08782](http://arxiv.org/abs/2408.08782)|**[link](https://github.com/cw-wan/EmoDynamiX-v2)**|
|**2024-08-16**|**Evaluating the Evaluator: Measuring LLMs' Adherence to Task Evaluation Instructions**|Bhuvanashree Murugadoss et.al.|[2408.08781](http://arxiv.org/abs/2408.08781)|null|
|**2024-08-16**|**Large Language Models Might Not Care What You Are Saying: Prompt Format Beats Descriptions**|Chenming Tang et.al.|[2408.08780](http://arxiv.org/abs/2408.08780)|null|
|**2024-08-16**|**DAC: Decomposed Automation Correction for Text-to-SQL**|Dingzirui Wang et.al.|[2408.08779](http://arxiv.org/abs/2408.08779)|**[link](https://github.com/zirui-HIT/DAC)**|
|**2024-08-16**|**Lower Layer Matters: Alleviating Hallucination via Multi-Layer Fusion Contrastive Decoding with Truthfulness Refocused**|Dingwei Chen et.al.|[2408.08769](http://arxiv.org/abs/2408.08769)|null|
|**2024-08-16**|**Extracting polygonal footprints in off-nadir images with Segment Anything Model**|Kai Li et.al.|[2408.08645](http://arxiv.org/abs/2408.08645)|null|
|**2024-08-16**|**CommunityKG-RAG: Leveraging Community Structures in Knowledge Graphs for Advanced Retrieval-Augmented Generation in Fact-Checking**|Rong-Ching Chang et.al.|[2408.08535](http://arxiv.org/abs/2408.08535)|null|
|**2024-08-16**|**MuRAR: A Simple and Effective Multimodal Retrieval and Answer Refinement Framework for Multimodal Question Answering**|Zhengyuan Zhu et.al.|[2408.08521](http://arxiv.org/abs/2408.08521)|null|
|**2024-08-15**|**W-RAG: Weakly Supervised Dense Retrieval in RAG for Open-domain Question Answering**|Jinming Nian et.al.|[2408.08444](http://arxiv.org/abs/2408.08444)|**[link](https://github.com/jmnian/weak_label_for_rag)**|
|**2024-08-15**|**Assessing and Enhancing Large Language Models in Rare Disease Question-answering**|Guanchu Wang et.al.|[2408.08422](http://arxiv.org/abs/2408.08422)|null|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-16**|**Covert Bias: The Severity of Social Views' Unalignment in Language Models Towards Implicit and Explicit Opinion**|Abeer Aldayel et.al.|[2408.08212](http://arxiv.org/abs/2408.08212)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**LLM4DSR: Leveraing Large Language Model for Denoising Sequential Recommendation**|Bohao Wang et.al.|[2408.08208](http://arxiv.org/abs/2408.08208)|null|
|**2024-08-15**|**Scaling Up Natural Language Understanding for Multi-Robots Through the Lens of Hierarchy**|Shaojun Xu et.al.|[2408.08188](http://arxiv.org/abs/2408.08188)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**New Curriculum, New Chance -- Retrieval Augmented Generation for Lesson Planning in Ugandan Secondary Schools. Prototype Quality Evaluation**|Simon Kloker et.al.|[2408.07542](http://arxiv.org/abs/2408.07542)|null|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## text2sql

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-08-09**|**A Survey of NL2SQL with Large Language Models: Where are we, and where are we going?**|Xinyu Liu et.al.|[2408.05109](http://arxiv.org/abs/2408.05109)|**[link](https://github.com/hkustdial/nl2sql_handbook)**|**翻译用户的自然语言查询（NL）为SQL查询（即NL2SQL）可以显著降低访问关系型数据库的障碍，并支持多种商业应用。随着大型语言模型（LLMs）的出现，NL2SQL的性能得到了极大提升。本调查提供了一个全面回顾，涵盖了在LLMs驱动下NL2SQL技术的整个生命周期，从以下四个方面进行探讨：(1) 模型：解决NL的模糊性和规范不足问题的NL2SQL翻译技术，以及如何恰当地将NL与数据库模式和实例映射；(2) 数据：从训练数据的收集、因训练数据稀缺而进行的数据合成，到NL2SQL基准测试集的建立；(3) 评估：采用不同指标和粒度从多个角度评估NL2SQL方法；及(4) 错误分析：分析NL2SQL错误以找到根本原因，并指导NL2SQL模型的进一步发展。此外，我们还为开发NL2SQL解决方案提供了一套实用指南。最后，我们讨论了在LLMs时代NL2SQL面临的科研挑战和开放性问题。**|
|**2024-07-21**|**Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned**|Yuan Liao et.al.|[2407.21040](http://arxiv.org/abs/2407.21040)|null|尽管自然语言到SQL（NL2SQL）领域在将自然语言指令转换为可执行的SQL脚本以进行数据查询和处理方面取得了显著进展，但实现数据科学管道的全自动化——包括数据查询、分析、可视化和报告——仍是一个复杂挑战。本研究介绍了一种先进的、行业级系统SageCopilot，它通过集成大型语言模型（LLMs）、自主代理（AutoAgents）和语言用户界面（LUIs）来自动化数据科学管道。具体而言，SageCopilot采用了一种双阶段设计：在线阶段利用情境学习（ICL）精炼用户输入为可执行脚本并运行这些脚本以生成结果报告与可视化；离线阶段则准备ICL在线阶段所需演示。该系统采用了诸如Chain-of-Thought和提示调整等前沿策略进行增强，以提升性能。通过严格的测试和与基于提示的解决方案的对比分析，SageCopilot已被实证验证在生成或执行脚本以及提供带有可视化的结果方面能实现端到端的卓越性能，这一过程得到了实际数据集的支持。我们的深度消融研究突显了SageCopilot所采用的各种组件和策略对端到端数据科学正确性贡献的个体价值。|
|**2024-06-12**|**DeTriever: Decoder-representation-based Retriever for Improving NL2SQL In-Context Learning**|Yuxi Feng et.al.|[2406.07913](http://arxiv.org/abs/2406.07913)|null|在情境学习（In-Context Learning, ICL）已被证明能有效提升大型语言模型（Large Language Models, LLMs）在各类复杂任务上的表现，特别是在将自然语言问题转换为结构化查询语言（NL2SQL）方面，如何选取最具效益的演示示例仍是一个未解决的研究问题。以往的工作往往采用现成的编码器来动态检索示例，但外部检索器与LLMs之间的表征能力存在固有差异。此外，优化示例选择并非易事，因为缺少直接方法在不进行配对推理的情况下评估示例的相对益处。针对这些不足，我们提出了DeTriever，一种新颖的演示检索框架，该框架学习LLM隐藏状态的加权组合，其中蕴含了丰富的语义信息。为了训练模型，我们提出了一种代理评分，根据输出查询间的相似性来估计示例的相对益处。在两个流行的NL2SQL基准测试上的实验表明，我们的方法在一次性NL2SQL任务上显著优于当前最优基线。|
|**2024-07-27**|**The Dawn of Natural Language to SQL: Are We Fully Ready?**|Boyan Li et.al.|[2406.01265](http://arxiv.org/abs/2406.01265)|**[link](https://github.com/hkustdial/nl2sql_survey)**|**将用户的自然语言问题转换为SQL查询（即NL2SQL）极大地降低了访问关系型数据库的门槛。大型语言模型的出现为NL2SQL任务引入了一个新的范式，显著增强了其能力。然而，这引发了一个关键问题：我们是否已经做好了在生产环境中部署NL2SQL模型的准备？为解答这一问题，我们提出了一种多角度NL2SQL评估框架NL2SQL360，旨在帮助研究人员设计和测试新的NL2SQL方法。通过NL2SQL360，我们在不同的应用情景下（例如，不同的数据领域和SQL特性）对领先的NL2SQL方法进行了详尽的比较，为根据特定需求选择最合适的NL2SQL方法提供了宝贵见解。此外，我们还探索了NL2SQL的设计空间，利用NL2SQL360自动化识别针对用户特定需求的最优NL2SQL解决方案。具体而言，NL2SQL360通过执行准确率指标，在Spider数据集下识别出了一种有效的NL2SQL方法——SuperSQL。值得注意的是，SuperSQL在Spider和BIRD测试集上分别达到了87%和62.66%的执行准确率，展现出竞争优势。**|
|**2024-05-01**|**ChatBI: Towards Natural Language to Complex Business Intelligence SQL**|Jinqing Lian et.al.|[2405.00527](http://arxiv.org/abs/2405.00527)|null|自然语言到SQL（NL2SQL）技术使得不熟悉数据库的非专业用户能够利用SQL进行数据分析。将自然语言转换为商业智能（NL2BI）是NL2SQL在实际生产系统中的一个流行且实用的应用场景。与NL2SQL相比，NL2BI引入了更多挑战。本文提出了一项综合且高效的解决方案ChatBI，用于应对NL2BI任务。首先，我们分析了交互模式这一关键模块，该模块在NL2SQL与NL2BI的应用中存在差异，并设计了一个更小、成本更低的模型以适应这种交互模式。在BI场景中，表格包含大量列，导致依赖大型语言模型（LLMs）进行模式链接的现有NL2SQL方法因令牌限制而难以进行。BI场景中更高比例的列义模糊性也加剧了模式链接的难度。ChatBI结合了数据库领域现有的视图技术，首先将模式链接问题分解为单视图选择问题，然后使用更小、成本更低的机器学习模型从大幅减少的列数中挑选出单个视图。该单视图的列作为所需列输入到LLM中进行模式链接。最后，ChatBI提出了一种与现有流程不同的分阶段处理流程，这使得ChatBI能更准确地生成包含复杂语义和比较关系的SQL。我们已在百度的数据平台上部署了ChatBI，并将其整合进多条产品线中，进行了大规模生产任务评估。所获得的结果彰显了其在实用性、通用性和效率方面的优越性。同时，在我们的实际BI场景数据表和查询下，与当前主流NL2SQL技术相比，它也取得了最佳效果。|
|**2024-03-29**|**PURPLE: Making a Large Language Model a Better SQL Writer**|Tonghui Ren et.al.|[2403.20014](http://arxiv.org/abs/2403.20014)|null|大型语言模型（LLM）技术在自然语言到SQL（NL2SQL）转换中扮演着日益重要的角色。通过大量语料库训练的LLMs具有强大的自然语言理解能力和基本的SQL生成能力，无需针对NL2SQL任务进行额外调整。现有的基于LLMs的NL2SQL方法试图通过加强LLMs来改进转换过程，重点在于增强对用户意图的理解。然而，LLMs有时会因为缺乏组织复杂逻辑运算符组合的知识而无法生成恰当的SQL。一种有前景的方法是向LLMs输入示例，这些示例包含了来自不同数据库的已知NL2SQL转换。LLMs能够从输入的示例中学习如何为当前任务组织逻辑运算符组合。在本文中，我们提出了PURPLE（利用预训练模型检索提示以逻辑增强），该方法通过检索包含所需逻辑运算符组合的示例来改善NL2SQL任务的准确性，从而指导LLMs生成更佳的SQL转换。PURPLE在流行的NL2SQL基准Spider的验证集上达到了80.5%的精确集合匹配准确率和87.8%的执行匹配准确率，树立了新的状态-of-the-art性能标准。PURPLE在不同的基准测试、预算限制及多种LLMs上保持了高准确度，展现出其鲁棒性和成本效益。|
|**2024-03-24**|**SQL-Encoder: Improving NL2SQL In-Context Learning Through a Context-Aware Encoder**|Mohammadreza Pourreza et.al.|[2403.16204](http://arxiv.org/abs/2403.16204)|null|检测查询间的结构相似性对于在情境学习模型中选取实例至关重要。然而，仅基于查询的自然语言表达而不考虑SQL查询来评估结构相似性是一项重大挑战。本文探讨了这一相似度指标的重要性，并提出了一种模型来准确估计它。为此，我们利用了一个包含17万对问题的精心构建的数据集来训练相似度预测模型。全面的评估表明，所提出的模型能有效地捕捉问题间的结构相似性，这从Kendall-Tau距离和precision@k指标的提升中得到证明。尤其值得注意的是，我们的模型超越了来自OpenAI和Cohere的强大竞争性嵌入模型。此外，与这些竞争模型相比，我们提出的编码器在1-shot情境学习场景下，提高了NL2SQL模型的下游性能：GPT-3.5-turbo提升了1-2%，CodeLlama-7B提升了4-8%，CodeLlama-13B提升了2-3%。|
|**2024-06-02**|**PET-SQL: A Prompt-Enhanced Two-Round Refinement of Text-to-SQL with Cross-consistency**|Zhishuai Li et.al.|[2403.09732](http://arxiv.org/abs/2403.09732)|**[link](https://github.com/zhshlii/petsql)**|**近期的文本到SQL（Text2SQL）技术进步着重于利用大型语言模型（LLM）的上下文学习能力，取得了显著成果。然而，这些方法在处理冗长的数据库信息和复杂用户意图时面临挑战。本文提出了一种两阶段框架，旨在提升当前基于LLM的自然语言至SQL系统的性能。首先，我们引入一种新颖的提示表示方式，称为参考增强表示，该表示融合了模式信息及从表格中随机抽取的单元格值，用以指导LLM生成SQL查询。接着，在第一阶段，通过检索问题-SQL对作为少量示例演示，引导LLM生成初步SQL（PreSQL）。随后，解析PreSQL中提及的实体以进行模式链接，此步骤能有效浓缩有用信息。进入第二阶段，利用链接后的模式，我们简化提示中的模式信息，并指示LLM输出最终SQL。最后，作为后处理优化模块，我们建议采用跨LM的一致性而非单一LM内部的自一致性作为评估标准。我们的方法在Spider基准测试上达到了新的最佳水平，执行准确率达到87.6%。**|
|**2024-02-28**|**Aligning Large Language Models to a Domain-specific Graph Database**|Yuanyuan Liang et.al.|[2402.16567](http://arxiv.org/abs/2402.16567)|null|图数据库（Graph DB）在金融、社交网络和医疗等多个领域有着广泛应用。然而，将自然语言（NL）转化为图查询语言（GQL），即NL2GQL任务，由于其固有的复杂性和专业性，面临着较大挑战。尽管一些方法尝试利用大型语言模型（LLMs）来解决类似的任务，如将文本转换为SQL（text2SQL），但在特定领域进行NL2GQL任务时，由于缺乏领域特定的NL-GQL数据对，使得在LLMs与图数据库之间建立有效对应变得尤为困难。针对这一挑战，我们提出了一种明确的处理流程。具体而言，我们使用ChatGPT根据给定的图数据库自我指导生成NL-GQL数据对。随后，利用这些创建的数据对LLMs进行微调，从而实现LLMs与图数据库之间的良好匹配。此外，在推断阶段，我们设计了一种方法，该方法能够从查询的自然语言中提取相关模式作为输入上下文，以此来引导LLMs更准确地生成GQL。我们在两个构建于金融和医疗领域的图数据库——FinGQL和MediGQL上评估了我们的方法。实验结果显示，相较于一系列基线方法，我们的方法显著提高了性能，分别在精确匹配（EM）指标上提升了5.90和6.36绝对百分点，在 existence（EX）指标上提高了6.00和7.09绝对百分点。|
|**2024-08-06**|**Intent-Based Access Control: Using LLMs to Intelligently Manage Access Control**|Pranav Subramaniam et.al.|[2402.07332](http://arxiv.org/abs/2402.07332)|null|在每个企业数据库中，管理员必须定义访问控制策略，以规定哪些用户可以访问哪些资产。访问控制跨越两个领域：策略（组织级原则，定义谁应具有访问权限）和流程（数据库级原语，实际实施策略）。评估和执行流程对策略的合规性是一项手动且临时的任务。本文介绍了一种名为“面向数据库的意图型访问控制”（Intent-Based Access Control for Databases, 简称IBAC-DB）的新访问控制范式。在IBAC-DB中，访问控制策略通过一种新颖格式——自然语言访问控制矩阵（Natural Language Access Control Matrix, NLACM）得以更精确地表达。数据库访问控制原语随后自动生成自这些NLACM。这些原语可用于生成新的数据库配置或评估现有配置。本文提出了一种IBAC-DB接口的参考架构、一个针对PostgreSQL的初始实现（我们称之为LLM4AC），以及初步的基准测试，用以评估此类系统的准确性和覆盖范围。我们进一步描述了如何扩展LLM4AC以处理其他类型的数据库部署需求，包括时间约束和角色层次结构。我们提出了RHieSys，这是一种针对特定需求扩展LLM4AC的方法，以及DePLOI，这是一种通用的LLM4AC扩展方法。我们发现所选实现LLM4AC极大地超越了其他基线，在我们的初始Dr. Spider基准测试中达到了高准确率和F1分数。在所有系统上，我们发现在扩展的基准测试中整体表现优异，这些测试包括需要外部知识的最先进的NL2SQL数据，以及来自Amazon Access数据集的真实世界角色层次结构。|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## AIOps

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-15**|**Can Large Language Models Understand Symbolic Graphics Programs?**|Zeju Qiu et.al.|[2408.08313](http://arxiv.org/abs/2408.08313)|null|
|**2024-08-15**|**ScalingFilter: Assessing Data Quality through Inverse Utilization of Scaling Laws**|Ruihang Li et.al.|[2408.08310](http://arxiv.org/abs/2408.08310)|null|
|**2024-08-15**|**Benchmarking the Capabilities of Large Language Models in Transportation System Engineering: Accuracy, Consistency, and Reasoning Behaviors**|Usman Syed et.al.|[2408.08302](http://arxiv.org/abs/2408.08302)|null|
|**2024-08-15**|**HELP: Hierarchical Embeddings-based Log Parsing**|Andy Xu et.al.|[2408.08300](http://arxiv.org/abs/2408.08300)|null|
|**2024-08-15**|**The ShareLM Collection and Plugin: Contributing Human-Model Chats for the Benefit of the Community**|Shachar Don-Yehiya et.al.|[2408.08291](http://arxiv.org/abs/2408.08291)|null|
|**2024-08-15**|**Autonomous Behavior Planning For Humanoid Loco-manipulation Through Grounded Language Model**|Jin Wang et.al.|[2408.08282](http://arxiv.org/abs/2408.08282)|null|
|**2024-08-15**|**BAM! Just Like That: Simple and Efficient Parameter Upcycling for Mixture of Experts**|Qizhen Zhang et.al.|[2408.08274](http://arxiv.org/abs/2408.08274)|null|
|**2024-08-15**|**DaRec: A Disentangled Alignment Framework for Large Language Model and Recommender System**|Xihong Yang et.al.|[2408.08231](http://arxiv.org/abs/2408.08231)|null|
|**2024-08-15**|**RED-CT: A Systems Design Methodology for Using LLM-labeled Data to Train and Deploy Edge Classifiers for Computational Social Science**|David Farr et.al.|[2408.08217](http://arxiv.org/abs/2408.08217)|null|
|**2024-08-15**|**Does Reasoning Emerge? Examining the Probabilities of Causation in Large Language Models**|Javier González et.al.|[2408.08210](http://arxiv.org/abs/2408.08210)|null|
|**2024-08-15**|**System States Forecasting of Microservices with Dynamic Spatio-Temporal Data**|Yifei Xu et.al.|[2408.07894](http://arxiv.org/abs/2408.07894)|null|
|**2024-08-14**|**The Death of Schema Linking? Text-to-SQL in the Age of Well-Reasoned Language Models**|Karime Maamari et.al.|[2408.07702](http://arxiv.org/abs/2408.07702)|null|
|**2024-08-14**|**Model Merging in LLMs, MLLMs, and Beyond: Methods, Theories, Applications and Opportunities**|Enneng Yang et.al.|[2408.07666](http://arxiv.org/abs/2408.07666)|**[link](https://github.com/ennengyang/awesome-model-merging-methods-theories-applications)**|
|**2024-08-14**|**Spoken Stereoset: On Evaluating Social Bias Toward Speaker in Speech Large Language Models**|Yi-Cheng Lin et.al.|[2408.07665](http://arxiv.org/abs/2408.07665)|**[link](https://github.com/dlion168/spoken_stereoset)**|
|**2024-08-14**|**Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining of Probability Distributions**|Quan Liu et.al.|[2408.07663](http://arxiv.org/abs/2408.07663)|**[link](https://github.com/gigabaozi/aed)**|
|**2024-08-14**|**WeKnow-RAG: An Adaptive Approach for Retrieval-Augmented Generation Integrating Web Search and Knowledge Graphs**|Weijian Xie et.al.|[2408.07611](http://arxiv.org/abs/2408.07611)|null|
|**2024-08-14**|**Transformers and Large Language Models for Efficient Intrusion Detection Systems: A Comprehensive Survey**|Hamza Kheddar et.al.|[2408.07583](http://arxiv.org/abs/2408.07583)|null|
|**2024-08-14**|**MathScape: Evaluating MLLMs in multimodal Math Scenarios through a Hierarchical Benchmark**|Minxuan Zhou et.al.|[2408.07543](http://arxiv.org/abs/2408.07543)|**[link](https://github.com/PKU-Baichuan-MLSystemLab/MathScape)**|
|**2024-08-14**|**Usefulness of data flow diagrams and large language models for security threat validation: a registered report**|Winnie Bahati Mbaka et.al.|[2408.07537](http://arxiv.org/abs/2408.07537)|null|
|**2024-08-14**|**Development of a Multi-Agent Clinical Decision Support System for Korean Triage and Acuity Scale (KTAS)-Based Triage and Treatment Planning in Emergency Departments**|Seungjun Han et.al.|[2408.07531](http://arxiv.org/abs/2408.07531)|null|
|**2024-08-14**|**Large Language Models Know What Makes Exemplary Contexts**|Quanyu Long et.al.|[2408.07505](http://arxiv.org/abs/2408.07505)|null|
|**2024-07-09**|**A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management**|Yongqian Sun et.al.|[2407.14532](http://arxiv.org/abs/2407.14532)|**[link](https://github.com/microservo/hot-plugging)**|
|**2024-07-31**|**Building AI Agents for Autonomous Clouds: Challenges and Design Principles**|Manish Shetty et.al.|[2407.12165](http://arxiv.org/abs/2407.12165)|null|
|**2024-07-02**|**LogEval: A Comprehensive Benchmark Suite for Large Language Models In Log Analysis**|Tianyu Cui et.al.|[2407.01896](http://arxiv.org/abs/2407.01896)|**[link](https://github.com/LinDuoming/LogEval)**|
|**2024-06-24**|**A Survey of AIOps for Failure Management in the Era of Large Language Models**|Lingzhe Zhang et.al.|[2406.11213](http://arxiv.org/abs/2406.11213)|null|
|**2024-05-13**|**AnomalyLLM: Few-shot Anomaly Edge Detection for Dynamic Graphs using Large Language Models**|Shuo Liu et.al.|[2405.07626](http://arxiv.org/abs/2405.07626)|**[link](https://github.com/anomalyllm/anomalyllm)**|
|**2024-04-24**|**Anomaly Detection for Incident Response at Scale**|Hanzhang Wang et.al.|[2404.16887](http://arxiv.org/abs/2404.16887)|null|
|**2024-05-03**|**mABC: multi-Agent Blockchain-Inspired Collaboration for root cause analysis in micro-services architecture**|Wei Zhang et.al.|[2404.12135](http://arxiv.org/abs/2404.12135)|null|
|**2024-04-12**|**Efficient Interactive LLM Serving with Proxy Model-based Sequence Length Prediction**|Haoran Qiu et.al.|[2404.08509](http://arxiv.org/abs/2404.08509)|**[link](https://github.com/james-qiuhaoran/llm-serving-with-proxy-models)**|
|**2024-04-01**|**AIOps Solutions for Incident Management: Technical Guidelines and A Comprehensive Literature Review**|Youcef Remil et.al.|[2404.01363](http://arxiv.org/abs/2404.01363)|null|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

## PPC

|Publish Date|Title|Authors|PDF|Code|Abstract|
|---|---|---|---|---|---|
|**2024-08-23**|**Social Welfare Maximization for Federated Learning with Network Effects**|Xiang Li et.al.|[2408.13223](http://arxiv.org/abs/2408.13223)|null|合理的机制设计能帮助联邦学习（FL）通过协调自利的客户端行为，在学习过程中达到良好的社会福利。然而，现有的机制忽略了客户端参与的网络效应，导致激励不充分和社会福利次优。本文旨在填补这一空白，通过探究联邦学习中激励机制设计中的网络效应。我们建立了一个理论模型来分析FL模型性能，并量化网络效应对异构客户端参与的影响。我们的分析揭示了FL中网络效应的非单调性。为了利用这些效应，我们提出一个模型交易与共享（MTS）框架，允许客户端通过参与或购买来获取FL模型。针对异构客户端的战略行为，我们进一步设计了一种社会效率最优的模型交易与共享（SEMTS）机制。我们的机制仅通过客户支付即可实现社会福利最大化，无需额外的激励成本。在联邦学习硬件原型上的实验结果显示，与现有机制相比，社会福利提高了高达148.86%。|
|**2024-08-23**|**Improving the Classification Effect of Clinical Images of Diseases for Multi-Source Privacy Protection**|Tian Bowen et.al.|[2408.13038](http://arxiv.org/abs/2408.13038)|null|在医疗领域，隐私数据保护对数据共享构成了挑战，限制了跨医院整合数据以训练高精度辅助诊断模型的能力。传统的集中式训练方法因违反隐私保护原则而难以应用。联邦学习作为一种分布式机器学习框架，有助于解决这一问题，但它要求多家医院同时参与训练，这在实际操作中很难实现。为应对这些挑战，我们提出了一种基于数据向量的医学隐私数据训练框架。该框架允许每家医院在其私人数据上对预训练模型进行微调，计算数据向量（代表解决方案空间中模型参数优化方向），并将这些向量相加起来生成综合权重，以此来集成多家医院的模型信息。这种方法在不交换私人数据或要求同步训练的情况下提升了模型性能。实验结果表明，该方法有效利用了分散的私人数据资源，同时保护了患者隐私。采用此方法训练的辅助诊断模型显著优于单一医院独立训练的模型，为解决医疗数据隐私保护与模型训练之间的冲突提供了新视角，推动了医疗智能化的发展。|
|**2024-08-23**|**A Web-Based Solution for Federated Learning with LLM-Based Automation**|Chamith Mawela et.al.|[2408.13010](http://arxiv.org/abs/2408.13010)|null|联邦学习（FL）作为一种在分布式设备间进行协作式机器学习的有前景方法，其应用受到构建可靠通信架构复杂性及需要机器学习与网络编程双重专业技能的限制。本文提出了一种综合解决方案，旨在简化FL任务的编排并融入意图驱动自动化技术。我们开发了一个用户友好的网络应用程序，支持联邦平均（FedAvg）算法，使用户能够通过直观界面配置参数。后端解决方案高效管理参数服务器与边缘节点间的通信，并实现了模型压缩与调度算法以优化FL性能。此外，我们探索了在FL中使用细调语言模型（LLM）实现意图驱动自动化的可能性，该模型基于特定领域数据集训练，使得用户能够通过高级指令执行FL任务。观察结果显示，基于LLM的自动化解决方案在达到与标准网页版解决方案相当的测试准确率的同时，能将传输字节减少高达64%，CPU时间减少最多46%。此外，我们利用神经架构搜索（NAS）和超参数优化（HPO）结合LLM进一步提升性能，发现这一方法能使所执行FL任务的测试准确率提高10%-20%。|
|**2024-08-23**|**Enhancing Vehicle Environmental Awareness via Federated Learning and Automatic Labeling**|Chih-Yu Lin et.al.|[2408.12769](http://arxiv.org/abs/2408.12769)|null|车辆环境感知对于提升道路安全至关重要。通过多种传感器与车车间通信，车辆能收集大量数据。然而，要使这些数据发挥作用，必须有效地整合传感器数据。本文聚焦于图像数据与车车间通信数据的融合，特别是旨在解决一个称为车辆识别问题的挑战，即在图像中定位发送信息的车辆位置。我们采用监督学习模型来应对车辆识别问题，但面临两个实际难题：首先，驾驶员通常不愿分享涉及隐私的图像数据；其次，驾驶员很少参与数据标注工作。针对这些挑战，本文提出一个综合解决方案，结合使用联邦学习、自动标注技术以及上述监督学习模型，以解决车辆识别问题。我们通过实验验证了所提方法的可行性。|
|**2024-08-22**|**Tackling Data Heterogeneity in Federated Learning via Loss Decomposition**|Shuang Zeng et.al.|[2408.12300](http://arxiv.org/abs/2408.12300)|**[link](https://github.com/zeng-shuang/fedld)**|**联邦学习（FL）作为一种新兴的协作式且隐私保护的机器学习方法，允许大规模医疗数据保留在各个客户端本地，正日益受到关注。然而，客户端间的数据异质性问题常导致局部模型分歧，进而影响全局模型的最优性。为缓解数据异质性对FL性能的影响，我们首先通过将全局损失分解为三部分：局部损失、分布偏移损失和聚合损失，来分析FL训练如何影响FL性能。值得注意的是，现有的基于本地训练的FL方法主要致力于减少分布偏移损失，而全局聚合为基础的FL方法则提出更佳的聚合策略以降低聚合损失。尽管如此，目前在文献中综合考虑同时减少这三项损失的全面努力仍较为有限，导致在处理数据异质性挑战时性能不尽如人意。为填补这一空白，我们提出了一种基于全局损失分解的新FL方法，名为FedLD，旨在联合减少这三项损失。FedLD采用局部训练中的边界控制正则化来减少分布偏移损失，并利用主梯度的服务器聚合策略来降低聚合损失。尤其在不同数据异质性程度下，我们的策略在视网膜与胸腔X光分类任务上相比其他FL算法展现出更优且更稳健的性能。我们的代码可于\href{https://github.com/Zeng-Shuang/FedLD}{https://github.com/Zeng-Shuang/FedLD}获取。**|
|**2024-08-22**|**Weight Scope Alignment: A Frustratingly Easy Method for Model Merging**|Yichu Xu et.al.|[2408.12237](http://arxiv.org/abs/2408.12237)|null|在某些注重模型效率与鲁棒性的应用中，模型融合已成为一项基本操作。训练过程中的随机性或非独立同分布（Non-I.I.D）数据为基于平均的模型融合带来了巨大挑战。以往的研究主要聚焦于元素级的正则化或神经网络权重的排列以增强模型融合效果，却忽视了模型间权重范围的变化，而这一变化对融合效果有着重要影响。本文揭示了不同训练条件下权重范围的变化情况，及其对模型合并影响的深入理解。可喜的是，每层参数基本上遵循高斯分布特性，这为我们提出一种新颖且简便的正则化方法——权重范围对齐（Weight Scope Alignment, WSA）提供了灵感。该方法包含两个关键环节：1) 利用目标权重范围引导模型训练过程，确保后续模型融合时权重范围的匹配；2) 将两个或多个模型的权重范围融合为统一范围，以支持多阶段的模型融合。我们还将WSA正则化扩展到了模式连接性和联邦学习两个不同的应用场景中。丰富的实验研究证实了我们方法的有效性。|
|**2024-08-22**|**Empowering Over-the-Air Personalized Federated Learning via RIS**|Wei Shi et.al.|[2408.12162](http://arxiv.org/abs/2408.12162)|null|空中计算（AirComp）技术将模拟通信与面向任务的计算相结合，成为无线网络中通信高效联邦学习（FL）的关键使能技术。然而，单一全局共识模型的AirComp支持FL（AirFL）未能解决实际FL场景中因本地数据集非独立同分布而导致的数据异质性问题。本文引入了可重构智能表面（RIS）技术，以实现高效的个性化AirFL，缓解数据异质性问题。首先，我们利用RIS的相位偏移配置，在个性化AirFL框架中实现了跨不同簇的统计干扰消除。接着，我们从一阶和二阶矩的角度出发，提出了两种涉及功率控制和去噪因子设计的个性化聚合方案，以增强FL的收敛性能。数值结果验证了所提方案相比现有基线的优越性能。|
|**2024-08-22**|**Understanding Data Reconstruction Leakage in Federated Learning from a Theoretical Perspective**|Zifan Wang et.al.|[2408.12119](http://arxiv.org/abs/2408.12119)|null|联邦学习（FL）是一种新兴的协作学习范式，旨在保护数据隐私。然而，近期研究表明FL算法易受到严重的数据重建攻击。遗憾的是，现有研究缺乏关于设备数据可被重建程度的理论基础，并且由于这些攻击性能不稳定，其有效性难以进行公平比较。为解决这一不足，我们提出一个理论框架来理解针对FL的数据重建攻击。该框架涵盖对数据重建误差的界限分析，攻击的误差界限反映了其固有的攻击效能。在此框架下，我们可以从理论上比较现有攻击的有效性。例如，我们在多个数据集上的结果验证了iDLG攻击在本质上优于DLG攻击。|
|**2024-08-21**|**Federated Diabetes Prediction in Canadian Adults Using Real-world Cross-Province Primary Care Data**|Guojun Tang et.al.|[2408.12029](http://arxiv.org/abs/2408.12029)|null|电子健康记录（EHR）的集成与机器学习的应用为提升数据驱动型糖尿病预测的准确性和可获取性提供了契机。特别是，开发数据驱动的机器学习模型能够实现对高风险糖尿病患者的早期识别，可能进而促使更有效的治疗策略及降低医疗成本。然而，监管限制为构建集中式预测模型设置了障碍。本文针对这一挑战，引入了联邦学习方法，该方法在不进行集中式数据存储和处理的情况下整合预测模型，从而避免了隐私问题。这是首次将联邦学习应用于加拿大实际临床数据集中的糖尿病预测，这些数据集从加拿大初级保健监测网络（CPCSSN）提取，且未涉及跨省患者数据共享。我们通过下采样技术解决了类别不平衡问题，并比较了联邦学习性能与基于省份及集中式模型的性能。实验结果表明，联邦多层感知器（MLP）模型展现出与集中式方法训练的模型相当或更高的性能。然而，联邦逻辑回归模型的表现不如其集中式对应模型。|
|**2024-08-21**|**RFID based Health Adherence Medicine Case Using Fair Federated Learning**|Ali Kamrani khodaei et.al.|[2408.11782](http://arxiv.org/abs/2408.11782)|**[link](https://github.com/MibclAric/Smart-Pill-Case)**|**药物依从性的缺乏显著降低了治疗效果，然而在患者中这一问题仍然普遍存在。非依从性与不良后果相关联，包括增加死亡和住院的风险。尽管存在多种方法帮助患者跟踪药物服用计划，如智能给药系统（IDAS）和智能泡罩包装，但这些工具在商业可行性上常面临挑战。基于物联网中剂量测量与信息通讯的原理，我们引入了智能药盒——一种利用RFID进行数据记录及NFC进行数据提取的智能健康依从性工具。该系统集成了负载传感器以实现精确剂量测量，并配备有Android应用程序来监控药物摄入、提供建议及发出警告。  为了增强智能药盒的有效性和个性化程度，我们提议融入联邦学习机制。联邦学习使得智能药盒能够从多个用户的药物依从性模式中学习，同时不侵犯个人隐私。通过在从各个智能药盒收集的分散数据上训练机器学习模型，系统能持续改进其推荐和警告，适应用户的多样需求和行为模式。这一方法不仅增强了工具支持药物依从性的能力，还确保了敏感用户数据的安全与私密性。**|
|**2024-08-21**|**FedGS: Federated Gradient Scaling for Heterogeneous Medical Image Segmentation**|Philip Schutte et.al.|[2408.11701](http://arxiv.org/abs/2408.11701)|**[link](https://github.com/trustworthy-ai-uu-nki/federated-learning-disentanglement)**|
|**2024-08-21**|**Technical Report: Coopetition in Heterogeneous Cross-Silo Federated Learning**|Chao Huang et.al.|[2408.11355](http://arxiv.org/abs/2408.11355)|null|
|**2024-08-21**|**FedMoE: Personalized Federated Learning via Heterogeneous Mixture of Experts**|Hanzi Mei et.al.|[2408.11304](http://arxiv.org/abs/2408.11304)|null|
|**2024-08-21**|**The Key of Parameter Skew in Federated Learning**|Sifan Wang et.al.|[2408.11278](http://arxiv.org/abs/2408.11278)|null|
|**2024-08-20**|**NeuLite: Memory-Efficient Federated Learning via Elastic Progressive Training**|Yebo Wu et.al.|[2408.10826](http://arxiv.org/abs/2408.10826)|null|
|**2024-08-20**|**Security Assessment of Hierarchical Federated Deep Learning**|D Alqattan et.al.|[2408.10752](http://arxiv.org/abs/2408.10752)|null|
|**2024-08-20**|**Federated Clustering: An Unsupervised Cluster-Wise Training for Decentralized Data Distributions**|Mirko Nardi et.al.|[2408.10664](http://arxiv.org/abs/2408.10664)|null|
|**2024-08-19**|**Differentially Private Stochastic Gradient Descent with Fixed-Size Minibatches: Tighter RDP Guarantees with or without Replacement**|Jeremiah Birrell et.al.|[2408.10456](http://arxiv.org/abs/2408.10456)|**[link](https://github.com/star-ailab/FSRDP)**|
|**2024-08-19**|**Federated Learning of Large ASR Models in the Real World**|Yonghui Xiao et.al.|[2408.10443](http://arxiv.org/abs/2408.10443)|null|
|**2024-08-19**|**Federated Frank-Wolfe Algorithm**|Ali Dadras et.al.|[2408.10090](http://arxiv.org/abs/2408.10090)|**[link](https://github.com/sourasb05/Federated-Frank-Wolfe)**|
|**2024-08-19**|**Towards Robust Federated Image Classification: An Empirical Study of Weight Selection Strategies in Manufacturing**|Vinit Hegiste et.al.|[2408.10024](http://arxiv.org/abs/2408.10024)|null|
|**2024-08-19**|**Sequential Federated Learning in Hierarchical Architecture on Non-IID Datasets**|Xingrun Yan et.al.|[2408.09762](http://arxiv.org/abs/2408.09762)|null|
|**2024-08-18**|**Addressing Heterogeneity in Federated Learning: Challenges and Solutions for a Shared Production Environment**|Tatjana Legler et.al.|[2408.09556](http://arxiv.org/abs/2408.09556)|null|
|**2024-08-20**|**Seamless Integration: Sampling Strategies in Federated Learning Systems**|Tatjana Legler et.al.|[2408.09545](http://arxiv.org/abs/2408.09545)|null|
|**2024-08-18**|**Byzantine-resilient Federated Learning Employing Normalized Gradients on Non-IID Datasets**|Shiyuan Zuo et.al.|[2408.09539](http://arxiv.org/abs/2408.09539)|null|
|**2024-08-18**|**Orchestrating Federated Learning in Space-Air-Ground Integrated Networks: Adaptive Data Offloading and Seamless Handover**|Dong-Jun Han et.al.|[2408.09522](http://arxiv.org/abs/2408.09522)|null|
|**2024-08-18**|**Mitigating Noise Detriment in Differentially Private Federated Learning with Model Pre-training**|Huitong Jin et.al.|[2408.09478](http://arxiv.org/abs/2408.09478)|null|
|**2024-08-18**|**Federated Graph Learning with Structure Proxy Alignment**|Xingbo Fu et.al.|[2408.09393](http://arxiv.org/abs/2408.09393)|**[link](https://github.com/xbfu/fedspray)**|
|**2024-08-17**|**FEDMEKI: A Benchmark for Scaling Medical Foundation Models via Federated Knowledge Injection**|Jiaqi Wang et.al.|[2408.09227](http://arxiv.org/abs/2408.09227)|**[link](https://github.com/psudslab/FEDMEKI)**|
|**2024-08-16**|**A Hassle-free Algorithm for Private Learning in Practice: Don't Use Tree Aggregation, Use BLTs**|H. Brendan McMahan et.al.|[2408.08868](http://arxiv.org/abs/2408.08868)|null|
|**2024-08-16**|**A Novel Buffered Federated Learning Framework for Privacy-Driven Anomaly Detection in IIoT**|Samira Kamali Poorazad et.al.|[2408.08722](http://arxiv.org/abs/2408.08722)|null|
|**2024-08-16**|**RBLA: Rank-Based-LoRA-Aggregation for Fine-tuning Heterogeneous Models in FLaaS**|Shuaijun Chen et.al.|[2408.08699](http://arxiv.org/abs/2408.08699)|null|
|**2024-08-16**|**A Multivocal Literature Review on Privacy and Fairness in Federated Learning**|Beatrice Balbierer et.al.|[2408.08666](http://arxiv.org/abs/2408.08666)|null|
|**2024-08-16**|**Mitigating Backdoor Attacks in Federated Learning via Flipping Weight Updates of Low-Activation Input Neurons**|Binbin Ding et.al.|[2408.08655](http://arxiv.org/abs/2408.08655)|null|
|**2024-08-16**|**The Power of Bias: Optimizing Client Selection in Federated Learning with Heterogeneous Differential Privacy**|Jiating Ma et.al.|[2408.08642](http://arxiv.org/abs/2408.08642)|null|
|**2024-08-15**|**A Robust Multi-Stage Intrusion Detection System for In-Vehicle Network Security using Hierarchical Federated Learning**|Muzun Althunayyan et.al.|[2408.08433](http://arxiv.org/abs/2408.08433)|null|
|**2024-08-15**|**Random Gradient Masking as a Defensive Measure to Deep Leakage in Federated Learning**|Joon Kim et.al.|[2408.08430](http://arxiv.org/abs/2408.08430)|null|
|**2024-08-15**|**Federated Fairness Analytics: Quantifying Fairness in Federated Learning**|Oscar Dilley et.al.|[2408.08214](http://arxiv.org/abs/2408.08214)|**[link](https://github.com/oscardilley/federated-fairness)**|
|**2024-08-15**|**Communication-robust and Privacy-safe Distributed Estimation for Heterogeneous Community-level Behind-the-meter Solar Power Generation**|Jinglei Feng et.al.|[2408.08107](http://arxiv.org/abs/2408.08107)|null|
|**2024-08-15**|**Addressing Skewed Heterogeneity via Federated Prototype Rectification with Personalization**|Shunxin Guo et.al.|[2408.07966](http://arxiv.org/abs/2408.07966)|null|
|**2024-08-14**|**Enhancing Equitable Access to AI in Housing and Homelessness System of Care through Federated Learning**|Musa Taib et.al.|[2408.07845](http://arxiv.org/abs/2408.07845)|null|
|**2024-08-14**|**FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher**|Alessio Mora et.al.|[2408.07587](http://arxiv.org/abs/2408.07587)|null|
|**2024-08-13**|**FedMADE: Robust Federated Learning for Intrusion Detection in IoT Networks Using a Dynamic Aggregation Method**|Shihua Sun et.al.|[2408.07152](http://arxiv.org/abs/2408.07152)|null|
|**2024-08-12**|**OFL-W3: A One-shot Federated Learning System on Web 3.0**|Linshan Jiang et.al.|[2408.07096](http://arxiv.org/abs/2408.07096)|null|
|**2024-08-13**|**Heterogeneity: An Open Challenge for Federated On-board Machine Learning**|Maria Hartmann et.al.|[2408.06903](http://arxiv.org/abs/2408.06903)|null|
|**2024-08-13**|**Voltran: Unlocking Trust and Confidentiality in Decentralized Federated Learning Aggregation**|Hao Wang et.al.|[2408.06885](http://arxiv.org/abs/2408.06885)|null|
|**2024-08-13**|**Prioritizing Modalities: Flexible Importance Scheduling in Federated Multimodal Learning**|Jieming Bian et.al.|[2408.06549](http://arxiv.org/abs/2408.06549)|null|
|**2024-08-14**|**Decentralized Health Intelligence Network (DHIN)**|Abraham Nash et.al.|[2408.06240](http://arxiv.org/abs/2408.06240)|null|
|**2024-08-12**|**Lancelot: Towards Efficient and Privacy-Preserving Byzantine-Robust Federated Learning within Fully Homomorphic Encryption**|Siyang Jiang et.al.|[2408.06197](http://arxiv.org/abs/2408.06197)|null|
|**2024-08-12**|**Centralized and Federated Heart Disease Classification Models Using UCI Dataset and their Shapley-value Based Interpretability**|Mario Padilla Rodriguez et.al.|[2408.06183](http://arxiv.org/abs/2408.06183)|**[link](https://github.com/padillma1/heart-disease-classification-on-uci-dataset-and-shapley-interpretability-analysis)**|
|**2024-08-12**|**Understanding Byzantine Robustness in Federated Learning with A Black-box Server**|Fangyuan Zhao et.al.|[2408.06042](http://arxiv.org/abs/2408.06042)|**[link](https://github.com/alibaba/federatedscope)**|

<p align=right>(<a href=#updated-on-20240826>back to top</a>)</p>

[contributors-shield]: https://img.shields.io/github/contributors/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[contributors-url]: https://github.com/Vincentqyw/cv-arxiv-daily/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[forks-url]: https://github.com/Vincentqyw/cv-arxiv-daily/network/members
[stars-shield]: https://img.shields.io/github/stars/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[stars-url]: https://github.com/Vincentqyw/cv-arxiv-daily/stargazers
[issues-shield]: https://img.shields.io/github/issues/Vincentqyw/cv-arxiv-daily.svg?style=for-the-badge
[issues-url]: https://github.com/Vincentqyw/cv-arxiv-daily/issues

